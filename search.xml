<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[图床失效了？也许你应该试试这个工具]]></title>
    <url>%2F2019%2F05%2F08%2Ftools%2Fblog-toolbox%2F</url>
    <content type="text"><![CDATA[前言经过几个小伙伴的提醒，发现个人博客中的许多图片都裂了无法访问；原因就不多说，既然出现问题就得要解决。 原本我的处理方式非常简单粗暴：找到原有的图片重新下载下来上传到新的可用图床再把图片地址替换。 这样搞了一两篇之后我就绝望了。。。 之前为了代码能在公众号里也有好的阅读体验，所以能截图的我绝不贴代码，导致一篇文章多的得有十几张图片。 好在哪位大佬说过“以人肉XX为耻”，这种重复劳动力完全可自动化；于是便有了本次的这个工具。 它可以一行命令把你所有 Markdown 写的内容中的图片全部替换为新的图床。 运行效果如下： 使用可以直接在这个地址下载 jar 包运行：https://github.com/crossoverJie/blog.toolbox/releases/download/v0.0.1/blog.toolbox-0.0.1-SNAPSHOT.jar 当然也可以下载源码编译运行： 123git clone https://github.com/crossoverJie/blog.toolboxmvn clean packagejava -jar nows-0.0.1-SNAPSHOT.jar --app.downLoad.path=/xx/img /xx/xx/path 100 看运行方式也知道，其实就是用 SpringBoot 写了一个工具用于批量下载文中出现的图片同时上传后完成替换。 其中 app.downLoad.path 是用于将下载的图片保存到本地磁盘的目录。 /xx/xx/path 则是扫描 .md 文件的目录，会递归扫描所有出所有文件。 100 则是需要替换文件的数量，默认是按照文件修改时间排序。 如果自己的图片较多的话还是有几个坑需要注意下。 线程数量默认是启动了两个线程去遍历文件、上传下载图片、更新文本等内容，其中的网络 IO 其实挺耗时的，所以其实可以适当的多开些线程来提高任务的执行效率。 但线程过多也许会触发图床的保护机制，同时也和自己电脑配置有关，这个得结合实际情况考虑了。 所以可以通过 --app.thread=6 这样的参数来调整线程数量。 图床限制这个是图片过多一定是大概率出现的，上传请求的频次过高很容易被限流封 IP。 1&#123;"code":"error","msg":"Upload file count limit. Time left 1027 second."&#125; 目前来看是封 IP 居多，所以可以通过走代理、换网络的方式来解决。 当然如果是自搭图床可以无视。 重试由于我使用的是免费图床，上传过程中偶尔也会出现上传失败的情况，因此默认是有 5 次重试机制的；如果五次都失败了那么大概率是 IP 被封了。 即便是 ip 被封后只要换了新的 ip 重新执行程序它会自动过滤掉已经替换的图片，不会再做无用功，这点可以放心。 图片保存 默认情况下,下载的图片会保存在本地，我也建议借此机会自己本地都缓存一份，同时名字还和文中的名字一样，避免今后图床彻底挂掉后连恢复的机会都没有。 总结这个程序的代码就没怎么讲了，确实也挺简单，感兴趣的可以自己下来看看。 目前功能也很单一，自用完全够了；看后续大家是否还有其他需求再逐渐完善吧，比如： 图床上传失败自动切换到可用图床。 整体处理效率提升。 任务执行过程中更好的进度展现等。 再次贴一下源码地址： https://github.com/crossoverJie/blog.toolbox 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>策略模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[『并发包入坑指北』之向大佬汇报任务]]></title>
    <url>%2F2019%2F04%2F28%2Fconcurrent%2FCountDownLatch%2F</url>
    <content type="text"><![CDATA[前言在面试过程中聊到并发相关的内容时，不少面试官都喜欢问这类问题： 当 N 个线程同时完成某项任务时，如何知道他们都已经执行完毕了。 这也是本次讨论的话题之一，所以本篇为『并发包入坑指北』的第二篇；来聊聊常见的并发工具。 自己实现其实这类问题的核心论点都是：如何在一个线程中得知其他线程是否执行完毕。 假设现在有 3 个线程在运行，需要在主线程中得知他们的运行结果；可以分为以下几步： 定义一个计数器为 3。 每个线程完成任务后计数减一。 一旦计数器减为 0 则通知等待的线程。 所以也很容易想到可以利用等待通知机制来实现，和上文的『并发包入坑指北』之阻塞队列的类似。 按照这个思路自定义了一个 MultipleThreadCountDownKit 工具，构造函数如下： 考虑到并发的前提，这个计数器自然需要保证线程安全，所以采用了 AtomicInteger。 所以在初始化时需要根据线程数量来构建对象。 计数器减一当其中一个业务线程完成后需要将这个计数器减一，直到减为0为止。 123456789101112131415161718192021/** * 线程完成后计数 -1 */public void countDown()&#123; if (counter.get() &lt;= 0)&#123; return; &#125; int count = this.counter.decrementAndGet(); if (count &lt; 0)&#123; throw new RuntimeException("concurrent error") ; &#125; if (count == 0)&#123; synchronized (notify)&#123; notify.notify(); &#125; &#125;&#125; 利用 counter.decrementAndGet() 来保证多线程的原子性，当减为 0 时则利用等待通知机制来 notify 其他线程。 等待所有线程完成而需要知道业务线程执行完毕的其他线程则需要在未完成之前一直处于等待状态，直到上文提到的在计数器变为 0 时得到通知。 12345678910111213141516/** * 等待所有的线程完成 * @throws InterruptedException */public void await() throws InterruptedException &#123; synchronized (notify)&#123; while (counter.get() &gt; 0)&#123; notify.wait(); &#125; if (notifyListen != null)&#123; notifyListen.notifyListen(); &#125; &#125;&#125; 原理也很简单，一旦计数器还存在时则会利用 notify 对象进行等待，直到被业务线程唤醒。 同时这里新增了一个通知接口可以自定义实现唤醒后的一些业务逻辑，后文会做演示。 并发测试主要就是这两个函数，下面来做一个演示。 初始化了三个计数器的并发工具 MultipleThreadCountDownKit 创建了三个线程分别执行业务逻辑，完毕后执行 countDown()。 线程 3 休眠了 2s 用于模拟业务耗时。 主线程执行 await() 等待他们三个线程执行完毕。 通过执行结果可以看出主线程会等待最后一个线程完成后才会退出；从而达到了主线程等待其余线程的效果。 12MultipleThreadCountDownKit multipleThreadKit = new MultipleThreadCountDownKit(3);multipleThreadKit.setNotify(() -&gt; LOGGER.info("三个线程完成了任务")); 也可以在初始化的时候指定一个回调接口，用于接收业务线程执行完毕后的通知。 当然和在主线程中执行这段逻辑效果是一样的（和执行 await() 方法处于同一个线程）。 CountDownLatch当然我们自己实现的代码没有经过大量生产环境的验证，所以主要的目的还是尝试窥探官方的实现原理。 所以我们现在来看看 juc 下的 CountDownLatch 是如何实现的。 通过构造函数会发现有一个 内部类 Sync，他是继承于 AbstractQueuedSynchronizer ；这是 Java 并发包中的基础框架，都可以单独拿来讲了，所以这次重点不是它，今后我们再着重介绍。 这里就可以把他简单理解为提供了和上文类似的一个计数器及线程通知工具就行了。 countDown其实他的核心逻辑和我们自己实现的区别不大。 1234567891011public void countDown() &#123; sync.releaseShared(1);&#125;public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 利用这个内部类的 releaseShared 方法，我们可以理解为他想要将计数器减一。 看到这里有没有似曾相识的感觉。 没错，在 JDK1.7 中的 AtomicInteger 自减就是这样实现的（利用 CAS 保证了线程安全）。 只是一旦计数器减为 0 时则会执行 doReleaseShared 唤醒其他的线程。 这里我们只需要关心红框部分（其他的暂时不用关心，这里涉及到了 AQS 中的队列相关），最终会调用 LockSupport.unpark 来唤醒线程；就相当于上文调用 object.notify()。 所以其实本质上还是相同的。 await其中的 await() 也是借用 Sync 对象的方法实现的。 12345678910111213141516public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); //判断计数器是否还未完成 if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; 一旦还存在未完成的线程时，则会调用 doAcquireSharedInterruptibly 进入阻塞状态。 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 同样的由于这也是 AQS 中的方法，我们只需要关心红框部分；其实最终就是调用了 LockSupport.park 方法，也就相当于执行了 object.wait() 。 所有的业务线程执行完毕后会在计数器减为 0 时调用 LockSupport.unpark 来唤醒线程。 等待线程一旦计数器 &gt; 0 时则会利用 LockSupport.park 来等待唤醒。 这样整个流程也就串起来了，它的使用方法也和上文的类似。 就不做过多介绍了。 实际案例同样的来看一个实际案例。 在上一篇《一次分表踩坑实践的探讨》提到了对于全表扫描的情况下，需要利用多线程来提高查询效率。 比如我们这里分为了 64 张表，计划利用 8 个线程来分别处理这些表的数据，伪代码如下： 12345678910111213141516CountDownLatch count = new CountDownLatch(64);ConcurrentHashMap total = new ConcurrentHashMap();for(Integer i=0;i&lt;=63;i++)&#123; executor.execute(new Runnable()&#123; @Override public void run()&#123; List value = queryTable(i); total.put(value,NULL); count.countDown(); &#125; &#125;) ; &#125;count.await();System.out.println("查询完毕"); 这样就可以实现所有数据都查询完毕后再做统一汇总；代码挺简单，也好理解（当然也可以使用线程池的 API）。 总结CountDownLatch 算是 juc 中一个高频使用的工具，学会和理解他的使用会帮助我们更容易编写并发应用。 文中涉及到的源码： https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/concurrent/communication/MultipleThreadCountDownKit.java 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
        <tag>CountDownLatch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VLOG-008:Basketball Day One]]></title>
    <url>%2F2019%2F04%2F21%2Fvlog%2FBasketball%20Day%20one%2F</url>
    <content type="text"><![CDATA[周末轻松一下。]]></content>
      <categories>
        <category>VLOG</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一次分表踩坑实践的探讨]]></title>
    <url>%2F2019%2F04%2F16%2Fframework-design%2Fsharding-db%2F</url>
    <content type="text"><![CDATA[前言之前不少人问我“能否分享一些分库分表相关的实践”，其实不是我不分享，而是真的经验不多🤣；和大部分人一样都是停留在理论阶段。 不过这次多少有些可以说道了。 先谈谈背景，我们生产数据库随着业务发展量也逐渐起来；好几张单表已经突破亿级数据，并且保持每天 200+W 的数据量增加。 而我们有些业务需要进行关联查询、或者是报表统计；在这样的背景下大表的问题更加突出（比如一个查询功能需要跑好几分钟）。 可能很多人会说：为啥单表都过亿了才想方案解决？其实不是不想，而是由于历史原因加上错误预估了数据增长才导致这个局面。总之原因比较复杂，也不是本次讨论的重点。 临时方案由于需求紧、人手缺的情况下，整个处理的过程分为几个阶段。 第一阶段应该是去年底，当时运维反应 MySQL 所在的主机内存占用很高，整体负载也居高不下，导致整个 MySQL 的吞吐量明显降低（写入、查询数据都明显减慢）。 为此我们找出了数据量最大的几张表，发现大部分数据量在7/8000W 左右，少数的已经突破一亿。 通过业务层面进行分析发现，这些数据多数都是用户产生的一些日志型数据，而且这些数据在业务上并不是强相关的，甚至两三个月前的数据其实已经不需要实时查询了。 因为接近年底，尽可能的不想去动应用，考虑是否可以在运维层面缓解压力；主要的目的就是把单表的数据量降低。 原本是想把两个月之前的数据直接迁移出来放到备份表中，但在准备实施的过程中发现一个大坑。 表中没有一个可以排序的索引，导致我们无法快速的筛选出一部分数据！这真是一个深坑，为后面的一些优化埋了个地雷；即便是加索引也需要花几个小时（具体多久没敢在生产测试）。 如果我们强行按照时间进行筛选，可能查询出 4000W 的数据就得花上好几个小时；这显然是行不通的。 于是我们便想到了一个大胆的想法：这部分数据是否可以直接不要了？ 这可能是最有效及最快的方式了，和产品沟通后得知这部分数据真的只是日志型的数据，即便是报表出不来今后补上也是可以的。 于是我们就简单粗暴的做了以下事情： 修改原有表的表名，比如加上(_190416bak)。 再新建一张和原有表名称相同的表。 这样新的数据就写到了新表，同时业务上也是使用的这个数据量较小的新表。 虽说过程不太优雅，但至少是解决了问题同时也给我们做技术改造预留了时间。 分表方案之前的方案虽说可以缓解压力，但不能根本解决问题。 有些业务必须得查询之前的数据，导致之前那招行不通了，所以正好我们就借助这个机会把表分了。 我相信大部分人虽说没有做过实际做过分表，但也见过猪跑；网上一搜各种方案层出不穷。 我认为最重要的一点是要结合实际业务找出需要 sharding 的字段，同时还有上线阶段的数据迁移也非常重要。 时间可能大家都会说用 hash 的方式分配得最均匀，但我认为这还是需要使用历史数据的场景才用哈希分表。 而对于不需要历史数据的场景，比如业务上只查询近三个月的数据。 这类需求完成可以采取时间分表，按照月份进行划分，这样改动简单，同时对历史数据也比较好迁移。 于是我们首先将这类需求的表筛选出来，按照月份进行拆分，只是在查询的时候拼接好表名即可；也比较好理解。 哈希刚才也提到了：需要根据业务需求进行分表策略。 而一旦所有的数据都有可能查询时，按照时间分表也就行不通了。（也能做，只是如果不是按照时间进行查询时需要遍历所有的表） 因此我们计划采用 hash 的方式分表，这算是业界比较主流的方式就不再赘述。 采用哈希时需要将 sharding 字段选好，由于我们的业务比较单纯；是一个物联网应用，所有的数据都包含有物联网设备的唯一标识（IMEI），并且这个字段天然的就保持了唯一性；大多数的业务也都是根据这个字段来的，所以它非常适合来做这个 sharding 字段。 在做分表之前也调研过 MyCAT 及 sharding-jdbc(现已升级为 shardingsphere)，最终考虑到对开发的友好性及不增加运维复杂度还是决定在 jdbc 层 sharding 的方式。 但由于历史原因我们并不太好集成 sharding-jdbc，但基于 sharding 的特点自己实现了一个分表策略。 这个简单也好理解： 123int index = hash(sharding字段) % 分表数量 ;select xx from 'busy_'+index where sharding字段 = xxx; 其实就是算出了表名，然后路由过去查询即可。 只是我们实现的非常简单：修改了所有的底层查询方法，每个方法都里都做了这样的一个判断。 并没有像 sharding-jdbc 一样，代理了数据库的查询方法；其中还要做 SQL解析--&gt;SQL路由--&gt;执行SQL--&gt;合并结果 这一系列的流程。 如果自己再做一遍无异于重新造了一个轮子，并且并不专业，只是在现有的技术条件下选择了一个快速实现达成效果的方法。 不过这个过程中我们节省了将 sharding 字段哈希的过程，因为每一个 IMEI 号其实都是一个唯一的整型，直接用它做 mod 运算即可。 还有一个是需要一个统一的组件生成规则，分表后不能再依赖于单表的字段自增了；方法还是挺多的： 比如时间戳+随机数可满足大部分业务。 UUID，生成简单，但没法做排序。 雪花算法统一生成主键ID。 大家可以根据自己的实际情况做选择。 业务调整因为我们并没有使用第三方的 sharding-jdbc 组件，所有没有办法做到对代码的低侵入性；每个涉及到分表的业务代码都需要做底层方法的改造（也就是路由到正确的表）。 考虑到后续业务的发展，我们决定将拆分的表分为 64 张；加上后续引入大数据平台足以应对几年的数据增长。 这里还有个小细节需要注意：分表的数量需要为 2∧N 次方，因为在取模的这种分表方式下，即便是今后再需要分表影响的数据也会尽量的小。 再修改时只能将表名称进行全局搜索，然后加以修改，同时根据修改的方法倒推到表现的业务并记录下来，方便后续回归测试。 当然无法避免查询时利用非 sharding 字段导致的全表扫描，这是所有分片后都会遇到的问题。 因此我们在修改分表方法的底层查询时同时也会查看是否有走分片字段，如果不是，那是否可以调整业务。 比如对于一个上亿的数据是否还有必要存在按照分页查询、日期查询？这样的业务是否真的具有意义？ 我们尽可能的引导产品按照这样的方式来设计产品或者做出调整。 但对于报表这类的需求确实也没办法，比如统计表中某种类型的数据；这种我们也可以利用多线程的方式去并行查询然后汇总统计来提高查询效率。 有时也有一些另类场景： 比如一个千万表中有某一特殊类型的数据只占了很小一部分，比如说几千上万条。 这时页面上需要对它进行分页查询是比较正常的（比如某种投诉消息，客户需要一条一条的单独处理），但如果我们按照 IMEI 号或者是主键进行分片后再分页查询那就比较蛋疼了。 所以这类型的数据建议单独新建一张表来维护，不要和其他数据混合在一起，这样不管是做分页还是 like 都比较简单和独立。 验证代码改完，开发也单测完成后怎么来验证分表的业务是否正常也比较麻烦。 一个是测试麻烦，再一个是万一哪里改漏了还是查询的原表，但这样在测试环境并不会有异常，一旦上线产生了生产数据到新的 64 张表后想要再修复就比较麻烦了。 所以我们取了个巧，直接将原表的表名修改，比如加一个后缀；这样在测试过程中观察前后台有无报错就比较容易提前发现这个问题。 上线流程测试验收通过后只是分表这个需求的80%，剩下如何上线也是比较头疼。 一旦应用上线后所有的查询、写入、删除都会先走路由然后到达新表；而老数据在原表里是不会发生改变的。 数据迁移所以我们上线前的第一步自然是需要将原有的数据进行迁移，迁移的目的是要分片到新的 64 张表中，这样才会对原有的业务无影响。 因此我们需要额外准备一个程序，它需要将老表里的数据按照分片规则复制到新表中； 在我们这个场景下，生产数据有些已经上亿了，这个迁移过程我们在测试环境模拟发现耗时是非常久的。而且我们老表中对于 create_time 这样用于筛选数据的字段没有索引（以前的技术债），所以查询起来就更加慢了。 最后没办法，我们只能和产品协商告知用户对于之前产生的数据短期可能会查询不到，这个时间最坏可能会持续几天（我们只能在凌晨迁移，白天会影响到数据库负载）。 总结这便是我们这次的分表实践，虽说不少过程都不优雅，但受限于条件也只能折中处理。 但我们后续的计划是，修改我们底层的数据连接（目前是自己封装的一个 jar 包，导致集成 sharding-jdbc 比较麻烦）最终逐渐迁移到 sharding-jdbc . 最后得出了几个结论： 一个好的产品规划非常有必要，可以在合理的时间对数据处理（不管是分表还是切入归档）。 每张表都需要一个可以用于排序查询的字段（自增ID、创建时间），整个过程由于没有这个字段导致耽搁了很长时间。 分表字段需要谨慎，要全盘的考虑业务情况，尽量避免出现查询扫表的情况。 最后欢迎留言讨论。 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>db</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[『并发包入坑指北』之阻塞队列]]></title>
    <url>%2F2019%2F04%2F09%2Fconcurrent%2FArrayBlockingQueue%2F</url>
    <content type="text"><![CDATA[前言较长一段时间以来我都发现不少开发者对 jdk 中的 J.U.C（java.util.concurrent）也就是 Java 并发包的使用甚少，更别谈对它的理解了；但这却也是我们进阶的必备关卡。 之前或多或少也分享过相关内容，但都不成体系；于是便想整理一套与并发包相关的系列文章。 其中的内容主要包含以下几个部分： 根据定义自己实现一个并发工具。 JDK 的标准实现。 实践案例。 基于这三点我相信大家对这部分内容不至于一问三不知。 既然开了一个新坑，就不想做的太差；所以我打算将这个列表下的大部分类都讲到。 所以本次重点讨论 ArrayBlockingQueue。 自己实现在自己实现之前先搞清楚阻塞队列的几个特点： 基本队列特性：先进先出。 写入队列空间不可用时会阻塞。 获取队列数据时当队列为空时将阻塞。 实现队列的方式多种，总的来说就是数组和链表；其实我们只需要搞清楚其中一个即可，不同的特性主要表现为数组和链表的区别。 这里的 ArrayBlockingQueue 看名字很明显是由数组实现。 我们先根据它这三个特性尝试自己实现试试。 初始化队列我这里自定义了一个类：ArrayQueue，它的构造函数如下： 123public ArrayQueue(int size) &#123; items = new Object[size];&#125; 很明显这里的 items 就是存放数据的数组；在初始化时需要根据大小创建数组。 写入队列写入队列比较简单，只需要依次把数据存放到这个数组中即可，如下图： 但还是有几个需要注意的点： 队列满的时候，写入的线程需要被阻塞。 写入过队列的数量大于队列大小时需要从第一个下标开始写。 先看第一个队列满的时候，写入的线程需要被阻塞，先来考虑下如何才能使一个线程被阻塞，看起来的表象线程卡住啥事也做不了。 有几种方案可以实现这个效果: Thread.sleep(timeout)线程休眠。 object.wait() 让线程进入 waiting 状态。 当然还有一些 join、LockSupport.part 等不在本次的讨论范围。 阻塞队列还有一个非常重要的特性是：当队列空间可用时（取出队列），写入线程需要被唤醒让数据可以写入进去。 所以很明显Thread.sleep(timeout)不合适，它在到达超时时间之后便会继续运行；达不到空间可用时才唤醒继续运行这个特点。 其实这样的一个特点很容易让我们想到 Java 的等待通知机制来实现线程间通信；更多线程见通信的方案可以参考这里：深入理解线程通信 所以我这里的做法是，一旦队列满时就将写入线程调用 object.wait() 进入 waiting 状态，直到空间可用时再进行唤醒。 123456789/** * 队列满时的阻塞锁 */private Object full = new Object();/** * 队列空时的阻塞锁 */private Object empty = new Object(); 所以这里声明了两个对象用于队列满、空情况下的互相通知作用。 在写入数据成功后需要使用 empty.notify()，这样的目的是当获取队列为空时，一旦写入数据成功就可以把消费队列的线程唤醒。 这里的 wait 和 notify 操作都需要对各自的对象使用 synchronized 方法块，这是因为 wait 和 notify 都需要获取到各自的锁。 消费队列上文也提到了：当队列为空时，获取队列的线程需要被阻塞，直到队列中有数据时才被唤醒。 代码和写入的非常类似，也很好理解；只是这里的等待、唤醒恰好是相反的，通过下面这张图可以很好理解： 总的来说就是： 写入队列满时会阻塞直到获取线程消费了队列数据后唤醒写入线程。 消费队列空时会阻塞直到写入线程写入了队列数据后唤醒消费线程。 测试先来一个基本的测试：单线程的写入和消费。 12343123123412345 通过结果来看没什么问题。 当写入的数据超过队列的大小时，就只能消费之后才能接着写入。 123452019-04-09 16:24:41.040 [Thread-0] INFO c.c.concurrent.ArrayQueueTest - [Thread-0]1232019-04-09 16:24:41.040 [main] INFO c.c.concurrent.ArrayQueueTest - size=32019-04-09 16:24:41.047 [main] INFO c.c.concurrent.ArrayQueueTest - 12342019-04-09 16:24:41.048 [main] INFO c.c.concurrent.ArrayQueueTest - 123452019-04-09 16:24:41.048 [main] INFO c.c.concurrent.ArrayQueueTest - 123456 从运行结果也能看出只有当消费数据后才能接着往队列里写入数据。 而当没有消费时，再往队列里写数据则会导致写入线程被阻塞。 并发测试 三个线程并发写入300条数据，其中一个线程消费一条。 12=====0299 最终的队列大小为 299，可见线程也是安全的。 由于不管是写入还是获取方法里的操作都需要获取锁才能操作，所以整个队列是线程安全的。 ArrayBlockingQueue下面来看看 JDK 标准的 ArrayBlockingQueue 的实现，有了上面的基础会更好理解。 初始化队列 看似要复杂些，但其实逐步拆分后也很好理解： 第一步其实和我们自己写的一样，初始化一个队列大小的数组。 第二步初始化了一个重入锁，这里其实就和我们之前使用的 synchronized 作用一致的； 只是这里在初始化重入锁的时候默认是非公平锁，当然也可以指定为 true 使用公平锁；这样就会按照队列的顺序进行写入和消费。 更多关于 ReentrantLock 的使用和原理请参考这里：ReentrantLock 实现原理 三四两步则是创建了 notEmpty notFull 这两个条件，他的作用于用法和之前使用的 object.wait/notify 类似。 这就是整个初始化的内容，其实和我们自己实现的非常类似。 写入队列 其实会发现阻塞写入的原理都是差不多的，只是这里使用的是 Lock 来显式获取和释放锁。 同时其中的 notFull.await();notEmpty.signal(); 和我们之前使用的 object.wait/notify 的用法和作用也是一样的。 当然它还是实现了超时阻塞的 API。 也是比较简单，使用了一个具有超时时间的等待方法。 消费队列再看消费队列： 也是差不多的，一看就懂。 而其中的超时 API 也是使用了 notEmpty.awaitNanos(nanos) 来实现超时返回的，就不具体说了。 实际案例说了这么多，来看一个队列的实际案例吧。 背景是这样的： 有一个定时任务会按照一定的间隔时间从数据库中读取一批数据，需要对这些数据做校验同时调用一个远程接口。 简单的做法就是由这个定时任务的线程去完成读取数据、消息校验、调用接口等整个全流程；但这样会有一个问题： 假设调用外部接口出现了异常、网络不稳导致耗时增加就会造成整个任务的效率降低，因为他都是串行会互相影响。 所以我们改进了方案： 其实就是一个典型的生产者消费者模型： 生产线程从数据库中读取消息丢到队列里。 消费线程从队列里获取数据做业务逻辑。 这样两个线程就可以通过这个队列来进行解耦，互相不影响，同时这个队列也能起到缓冲的作用。 但在使用过程中也有一些小细节值得注意。 因为这个外部接口是支持批量执行的，所以在消费线程取出数据后会在内存中做一个累加，一旦达到阈值或者是累计了一个时间段便将这批累计的数据处理掉。 但由于开发者的大意，在消费的时候使用的是 queue.take() 这个阻塞的 API；正常运行没啥问题。 可一旦原始的数据源，也就是 DB 中没数据了，导致队列里的数据也被消费完后这个消费线程便会被阻塞。 这样上一轮积累在内存中的数据便一直没机会使用，直到数据源又有数据了，一旦中间间隔较长时便可能会导致严重的业务异常。 所以我们最好是使用 queue.poll(timeout) 这样带超时时间的 api，除非业务上有明确的要求需要阻塞。 这个习惯同样适用于其他场景，比如调用 http、rpc 接口等都需要设置合理的超时时间。 总结关于 ArrayBlockingQueue 的相关分享便到此结束，接着会继续更新其他并发容器及并发工具。 对本文有任何相关问题都可以留言讨论。 本文涉及到的所有源码： https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/concurrent/ArrayQueue.java 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
        <tag>ArrayBlockingQueue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VLOG-007:一个程序员的周末（中）]]></title>
    <url>%2F2019%2F03%2F30%2Fvlog%2FChinese-coder-weekends-02%2F</url>
    <content type="text"><![CDATA[承接上期《VLOG-006:一个程序员的周末（上）》 本次是周末日常的中篇，也是我每周做的最频繁的一件事情【陪女朋友逛街】。 导致的结果是我已经清楚的知道所在商圈里大部分门店里的休息位置。 哪里坐着舒服、哪里的信号比较好、哪家店逛不久会马上走，所以最好是不要坐下。 可谓是“旱的旱死，涝的涝死” 正片开始]]></content>
      <categories>
        <category>VLOG</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[线程池中你不容错过的一些细节]]></title>
    <url>%2F2019%2F03%2F26%2Ftroubleshoot%2Fthread-gone2%2F</url>
    <content type="text"><![CDATA[背景上周分享了一篇《一个线程罢工的诡异事件》，最近也在公司内部分享了这个案例。 无独有偶，在内部分享的时候也有小伙伴问了之前分享时所提出的一类问题： 这其实是一类共性问题，我认为主要还是两个原因： 我自己确实也没讲清楚，之前画的那张图还需要再完善，有些误导。 第二还是大家对线程池的理解不够深刻，比如今天要探讨的内容。 线程池的工作原理首先还是来复习下线程池的基本原理。 我认为线程池它就是一个调度任务的工具。 众所周知在初始化线程池会给定线程池的大小，假设现在我们有 1000 个线程任务需要运行，而线程池的大小为 10~20，在真正运行任务的过程中他肯定不会创建这1000个线程同时运行，而是充分利用线程池里这 10~20 个线程来调度这1000个任务。 而这里的 10~20 个线程最后会由线程池封装为 ThreadPoolExecutor.Worker 对象，而这个 Worker 是实现了 Runnable 接口的，所以他自己本身就是一个线程。 深入分析 这里我们来做一个模拟，创建了一个核心线程、最大线程数、阻塞队列都为2的线程池。 这里假设线程池已经完成了预热，也就是线程池内部已经创建好了两个线程 Worker。 当我们往一个线程池丢一个任务会发生什么事呢？ 第一步是生产者，也就是任务提供者他执行了一个 execute() 方法，本质上就是往这个内部队列里放了一个任务。 之前已经创建好了的 Worker 线程会执行一个 while 循环 —&gt; 不停的从这个内部队列里获取任务。(这一步是竞争的关系，都会抢着从队列里获取任务，由这个队列内部实现了线程安全。) 获取得到一个任务后，其实也就是拿到了一个 Runnable 对象(也就是 execute(Runnable task) 这里所提交的任务)，接着执行这个 Runnable 的 run() 方法，而不是 start()，这点需要注意后文分析原因。 结合源码来看： 从图中其实就对应了刚才提到的二三两步： while 循环，从 getTask() 方法中一直不停的获取任务。 拿到任务后，执行它的 run() 方法。 这样一个线程就调度完毕，然后再次进入循环从队列里取任务并不断的进行调度。 再次解释之前的问题接下来回顾一下我们上一篇文章所提到的，导致一个线程没有运行的根本原因是： 在单个线程的线程池中一但抛出了未被捕获的异常时，线程池会回收当前的线程并创建一个新的 Worker；它也会一直不断的从队列里获取任务来执行，但由于这是一个消费线程，根本没有生产者往里边丢任务，所以它会一直 waiting 在从队列里获取任务处，所以也就造成了线上的队列没有消费，业务线程池没有执行的问题。 结合之前的那张图来看： 这里大家问的最多的一个点是，为什么会没有是根本没有生产者往里边丢任务，图中不是明明画的有一个 product 嘛？ 这里确实是有些不太清楚，再次强调一次： 图中的 product 是往内部队列里写消息的生产者，并不是往这个 Consumer 所在的线程池中写任务的生产者。 因为即便 Consumer 是一个单线程的线程池，它依然具有一个常规线程池所具备的所有条件： Worker 调度线程，也就是线程池运行的线程；虽然只有一个。 内部的阻塞队列；虽然长度只有1。 再次结合图来看： 所以之前提到的【没有生产者往里边丢任务】是指右图放大后的那一块，也就是内部队列并没有其他线程往里边丢任务执行 execute() 方法。 而一旦发生未捕获的异常后，Worker1 被回收，顺带的它所调度的线程 task1（这个task1 也就是在执行一个 while 循环消费左图中的那个队列） 也会被回收掉。 新创建的 Worker2 会取代 Worker1 继续执行 while 循环从内部队列里获取任务，但此时这个队列就一直会是空的，所以也就是处于 Waiting 状态。 我觉得这波解释应该还是讲清楚了，欢迎还没搞明白的朋友留言讨论。 为什是 run() 而不是 start()问题搞清楚后来想想为什么线程池在调度的时候执行的是 Runnable 的 run() 方法，而不是 start() 方法呢？ 我相信大部分没有看过源码的同学心中第一个印象就应该是执行的 start() 方法； 因为不管是学校老师，还是网上大牛讲的都是只有执行了start() 方法后操作系统才会给我们创建一个独立的线程来运行，而 run() 方法只是一个普通的方法调用。 而在线程池这个场景中却恰好就是要利用它只是一个普通方法调用。 回到我在文初中所提到的：我认为线程池它就是一个调度任务的工具。 假设这里是调用的 Runnable 的 start 方法，那会发生什么事情。 如果我们往一个核心、最大线程数为 2 的线程池里丢了 1000 个任务，那么它会额外的创建 1000 个线程，同时每个任务都是异步执行的，一下子就执行完毕了。 从而没法做到由这两个 Worker 线程来调度这 1000 个任务，而只有当做一个同步阻塞的 run() 方法调用时才能满足这个要求。 这事也让我发现一个奇特的现象：就是网上几乎没人讲过为什么在线程池里是 run 而不是 start，不知道是大家都觉得这是基操还是没人仔细考虑过。 总结针对之前线上事故的总结上次已经写得差不多了，感兴趣的可以翻回去看看。 这次呢可能更多是我自己的总结，比如写一篇技术博客时如果大部分人对某一个知识点讨论的比较热烈时，那一定是作者要么讲错了，要么没讲清楚。 这点确实是要把自己作为一个读者的角度来看，不然很容易出现之前的一些误解。 在这之外呢，我觉得对于线程池把这两篇都看完同时也理解后对于大家理解线程池，利用线程池完成工作也是有很大好处的。 如果有在面试中加分的记得回来点赞、分享啊。 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>问题排查</category>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VLOG-006:一个程序员的周末（上）]]></title>
    <url>%2F2019%2F03%2F21%2Fvlog%2FChinese-coder-weekends-01%2F</url>
    <content type="text"><![CDATA[上次发了一个《VLOG-004：国产程序员的一天》评论和播放量都还不错，这次趁热打铁更新了周末业余生活是怎么样的。 在这个视频中你将看到： 作为一个居家好男人是如何体现自我价值的？ 我是如何产出一份技术博客？ 女朋友不在家如何正规消遣时间？ 如何撸得代码、下得厨房讨女朋友开心？ 正片开始 这个视频是上部分，主要记录的是在家里的生活。 起床可能是由于平时早起习惯了，我居然快改掉了多年懒床的毛病，近期周末都是8、9点的样子就会起床。 起床后磨蹭半天一不小心就到了饭点，由于女朋友上早班一个人的话就点了外卖。 吃饭的同时会看看一部下饭神剧《武林外传》。 家务开始洗衣服，洗衣服的同时需要收衣服、叠衣服从而实现个人价值。 周报 准备开始写周报，结果一不小心沉浸于电视。。。 2个小时后周报完成。 PPT 完成下周技术分享的 PPT，但受限于设计细胞整个 PPT 将比较难看。 技术博客 开始写一篇技术博客，分享了我个人的一些习惯： 先在本子上打好提纲。 加上一个二次元配图。 写博客时需要注意的点。 消遣 玩 switch ，买游戏花的钱已经都可以再买一个 switch 了，果真是买游戏送主机；主要玩： 马里奥赛车8 喷射乌贼娘 塞尔达传说 任天堂明星大乱斗 晚饭 作为王刚师傅的在线弟子，深的宽油真传，必将料理出感动人心的美味；本次为大家带来的是口味猪肝。 全程高能，请大家饭前观看（吃完饭后会忍不住想吃）。 END看到这里想必你已经对开始的几个问题有了答案了吧，来核对下我的标准答案吧。 作为一个居家好男人是如何体现自我价值的？—-&gt;你的价值就是洗碗、洗衣服收拾家务。 我是如何产出一份技术博客？—-&gt;提前构思目录、文章配图。 女朋友不在家如何正规消遣时间？—-&gt;必须是 switch 啊，不然你以为是啥。。 如何撸得代码、下得厨房讨女朋友开心？—-&gt;看 20 遍王刚师傅的视频自学成才。 下一期将会为大家带来室外篇，作为一个大学毕业到现在成功长膘 20 斤的篮球爱好者，如何科学运动长肉，你值得期待🤫。]]></content>
      <categories>
        <category>VLOG</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一个线程罢工的诡异事件]]></title>
    <url>%2F2019%2F03%2F12%2Ftroubleshoot%2Fthread-gone%2F</url>
    <content type="text"><![CDATA[背景事情（事故）是这样的，突然收到报警，线上某个应用里业务逻辑没有执行，导致的结果是数据库里的某些数据没有更新。 虽然是前人写的代码，但作为 Bug maker&amp;killer 只能咬着牙上了。 因为之前没有接触过出问题这块的逻辑，所以简单理了下如图： 有一个生产线程一直源源不断的往队列写数据。 消费线程也一直不停的取出数据后写入后续的业务线程池。 业务线程池里的线程会对每个任务进行入库操作。 整个过程还是比较清晰的，就是一个典型的生产者消费者模型。 尝试定位接下来便是尝试定位这个问题，首先例行检查了以下几项： 是否内存有内存溢出？ 应用 GC 是否有异常？ 通过日志以及监控发现以上两项都是正常的。 紧接着便 dump 了线程快照查看业务线程池中的线程都在干啥。 结果发现所有业务线程池都处于 waiting 状态，队列也是空的。 同时生产者使用的队列却已经满了，没有任何消费迹象。 结合上面的流程图不难发现应该是消费队列的 Consumer 出问题了，导致上游的队列不能消费，下有的业务线程池没事可做。 review 代码于是查看了消费代码的业务逻辑，同时也发现消费线程是一个单线程。 结合之前的线程快照，我发现这个消费线程也是处于 waiting 状态，和后面的业务线程池一模一样。 他做的事情基本上就是对消息解析，之后丢到后面的业务线程池中，没有发现什么特别的地方。 但是由于里面的分支特别多（switch case），看着有点头疼；所以我与写这个业务代码的同学沟通后他告诉我确实也只是入口处解析了一下数据，后续所有的业务逻辑都是丢到线程池中处理的，于是我便带着这个前提去排查了（埋下了伏笔）。 因为这里消费的队列其实是一个 disruptor 队列；它和我们常用的 BlockQueue 不太一样，不是由开发者自定义一个消费逻辑进行处理的；而是在初始化队列时直接丢一个线程池进去，它会在内部使用这个线程池进行消费，同时回调一个方法，在这个方法里我们写自己的消费逻辑。 所以对于开发者而言，这个消费逻辑其实是一个黑盒。 于是在我反复 review 了消费代码中的数据解析逻辑发现不太可能出现问题后，便开始疯狂怀疑是不是 disruptor 自身的问题导致这个消费线程罢工了。 再翻了一阵 disruptor 的源码后依旧没发现什么问题后我咨询对 disruptor 较熟的@咖啡拿铁，在他的帮助下在本地模拟出来和生产一样的情况。 本地模拟 本地也是创建了一个单线程的线程池，分别执行了两个任务。 第一个任务没啥好说的，就是简单的打印。 第二个任务会对一个数进行累加，加到 10 之后就抛出一个未捕获的异常。 接着我们来运行一下。 发现当任务中抛出一个没有捕获的异常时，线程池中的线程就会处于 waiting 状态，同时所有的堆栈都和生产相符。 细心的朋友会发现正常运行的线程名称和异常后处于 waiting 状态的线程名称是不一样的，这个后续分析。 解决问题 当加入异常捕获后又如何呢？ 程序肯定会正常运行。 同时会发现所有的任务都是由一个线程完成的。 虽说就是加了一行代码，但我们还是要搞清楚这里面的门门道道。 源码分析于是只有直接 debug 线程池的源码最快了； 通过刚才的异常堆栈我们进入到 ThreadPoolExecutor.java:1142 处。 发现线程池已经帮我们做了异常捕获，但依然会往上抛。 在 finally 块中会执行 processWorkerExit(w, completedAbruptly) 方法。 看过之前《如何优雅的使用和理解线程池》的朋友应该还会有印象。 线程池中的任务都会被包装为一个内部 Worker 对象执行。 processWorkerExit 可以简单的理解为是把当前运行的线程销毁（workers.remove(w)）、同时新增（addWorker()）一个 Worker 对象接着处理； 就像是哪个零件坏掉后重新换了一个新的接着工作，但是旧零件负责的任务就没有了。 接下来看看 addWorker() 做了什么事情： 只看这次比较关心的部分；添加成功后会直接执行他的 start() 的方法。 由于 Worker 实现了 Runnable 接口，所以本质上就是调用了 runWorker() 方法。 在 runWorker() 其实就是上文 ThreadPoolExecutor 抛出异常时的那个方法。 它会从队列里一直不停的获取待执行的任务，也就是 getTask()；在 getTask 也能看出它会一直从内置的队列取出任务。 而一旦队列是空的，它就会 waiting 在 workQueue.take()，也就是我们从堆栈中发现的 1067 行代码。 线程名字的变化 上文还提到了异常后的线程名称发生了改变，其实在 addWorker() 方法中可以看到 new Worker()时就会重新命名线程的名称，默认就是把后缀的计数+1。 这样一切都能解释得通了，真相只有一个： 在单个线程的线程池中一但抛出了未被捕获的异常时，线程池会回收当前的线程并创建一个新的 Worker；它也会一直不断的从队列里获取任务来执行，但由于这是一个消费线程，根本没有生产者往里边丢任务，所以它会一直 waiting 在从队列里获取任务处，所以也就造成了线上的队列没有消费，业务线程池没有执行的问题。 总结所以之后线上的那个问题加上异常捕获之后也变得正常了，但我还是有点纳闷的是： 既然后续所有的任务都是在线程池中执行的，也就是纯异步了，那即便是出现异常也不会抛到消费线程中啊。 这不是把我之前储备的知识点推翻了嘛？不信邪！之后我让运维给了加上异常捕获后的线上错误日志。 结果发现在上文提到的众多 switch case 中，最后一个竟然是直接操作的数据库，导致一个非空字段报错了🤬！！ 这事也给我个教训，还是得眼见为实啊。 虽然这个问题改动很小解决了，但复盘整个过程还是有许多需要改进的： 消费队列的线程名称竟然和业务线程的前缀一样，导致我光找它就花了许多时间，命名必须得调整。 开发规范，防御式编程大家需要养成习惯。 未知的技术栈需要谨慎，比如 disruptor，之前的团队应该只是看了个高性能的介绍就直接使用，并没有深究其原理；导致出现问题后对它拿不准。 实例代码： https://github.com/crossoverJie/JCSprout/blob/master/src/main/java/com/crossoverjie/thread/ThreadExceptionTest.java 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>问题排查</category>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>concurrent</tag>
        <tag>disruptor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一致性 Hash 算法的实际应用]]></title>
    <url>%2F2019%2F03%2F01%2Falgorithm%2Fconsistent-hash%2F</url>
    <content type="text"><![CDATA[前言记得一年前分享过一篇《一致性 Hash 算法分析》，当时只是分析了这个算法的实现原理、解决了什么问题等。 但没有实际实现一个这样的算法，毕竟要加深印象还得自己撸一遍，于是本次就当前的一个路由需求来着手实现一次。 背景看过《为自己搭建一个分布式 IM(即时通讯) 系统》的朋友应该对其中的登录逻辑有所印象。 先给新来的朋友简单介绍下 cim 是干啥的： 其中有一个场景是在客户端登录成功后需要从可用的服务端列表中选择一台服务节点返回给客户端使用。 而这个选择的过程就是一个负载策略的过程；第一版本做的比较简单，默认只支持轮询的方式。 虽然够用，但不够优雅😏。 因此我的规划是内置多种路由策略供使用者根据自己的场景选择，同时提供简单的 API 供用户自定义自己的路由策略。 先来看看一致性 Hash 算法的一些特点： 构造一个 0 ~ 2^32-1 大小的环。 服务节点经过 hash 之后将自身存放到环中的下标中。 客户端根据自身的某些数据 hash 之后也定位到这个环中。 通过顺时针找到离他最近的一个节点，也就是这次路由的服务节点。 考虑到服务节点的个数以及 hash 算法的问题导致环中的数据分布不均匀时引入了虚拟节点。 自定义有序 Map根据这些客观条件我们很容易想到通过自定义一个有序数组来模拟这个环。 这样我们的流程如下： 初始化一个长度为 N 的数组。 将服务节点通过 hash 算法得到的正整数，同时将节点自身的数据（hashcode、ip、端口等）存放在这里。 完成节点存放后将整个数组进行排序（排序算法有多种）。 客户端获取路由节点时，将自身进行 hash 也得到一个正整数； 遍历这个数组直到找到一个数据大于等于当前客户端的 hash 值，就将当前节点作为该客户端所路由的节点。 如果没有发现比客户端大的数据就返回第一个节点（满足环的特性）。 先不考虑排序所消耗的时间，单看这个路由的时间复杂度： 最好是第一次就找到，时间复杂度为O(1)。 最差为遍历完数组后才找到，时间复杂度为O(N)。 理论讲完了来看看具体实践。 我自定义了一个类：SortArrayMap 他的使用方法及结果如下： 可见最终会按照 key 的大小进行排序，同时传入 hashcode = 101 时会按照顺时针找到 hashcode = 1000 这个节点进行返回。 下面来看看具体的实现。 成员变量和构造函数如下： 其中最核心的就是一个 Node 数组，用它来存放服务节点的 hashcode 以及 value 值。 其中的内部类 Node 结构如下： 写入数据的方法如下： 相信看过 ArrayList 的源码应该有印象，这里的写入逻辑和它很像。 写入之前判断是否需要扩容，如果需要则复制原来大小的 1.5 倍数组来存放数据。 之后就写入数组，同时数组大小 +1。 但是存放时是按照写入顺序存放的，遍历时自然不会有序；因此提供了一个 Sort 方法，可以把其中的数据按照 key 其实也就是 hashcode 进行排序。 排序也比较简单，使用了 Arrays 这个数组工具进行排序，它其实是使用了一个 TimSort 的排序算法，效率还是比较高的。 最后则需要按照一致性 Hash 的标准顺时针查找对应的节点： 代码还是比较简单清晰的；遍历数组如果找到比当前 key 大的就返回，没有查到就取第一个。 这样就基本实现了一致性 Hash 的要求。 ps:这里并不包含具体的 hash 方法以及虚拟节点等功能（具体实现请看下文），这个可以由使用者来定，SortArrayMap 可作为一个底层的数据结构，提供有序 Map 的能力，使用场景也不局限于一致性 Hash 算法中。 TreeMap 实现SortArrayMap 虽说是实现了一致性 hash 的功能，但效率还不够高，主要体现在 sort 排序处。 下图是目前主流排序算法的时间复杂度： 最好的也就是 O(N) 了。 这里完全可以换一个思路，不用对数据进行排序；而是在写入的时候就排好顺序，只是这样会降低写入的效率。 比如二叉查找树，这样的数据结构 jdk 里有现成的实现；比如 TreeMap 就是使用红黑树来实现的，默认情况下它会对 key 进行自然排序。 来看看使用 TreeMap 如何来达到同样的效果。运行结果： 1127.0.0.1000 效果和上文使用 SortArrayMap 是一致的。 只使用了 TreeMap 的一些 API： 写入数据候，TreeMap 可以保证 key 的自然排序。 tailMap 可以获取比当前 key 大的部分数据。 当这个方法有数据返回时取第一个就是顺时针中的第一个节点了。 如果没有返回那就直接取整个 Map 的第一个节点，同样也实现了环形结构。 ps:这里同样也没有 hash 方法以及虚拟节点（具体实现请看下文），因为 TreeMap 和 SortArrayMap 一样都是作为基础数据结构来使用的。 性能对比为了方便大家选择哪一个数据结构，我用 TreeMap 和 SortArrayMap 分别写入了一百万条数据来对比。 先是 SortArrayMap： 耗时 2237 毫秒。 TreeMap： 耗时 1316毫秒。 结果是快了将近一倍，所以还是推荐使用 TreeMap 来进行实现，毕竟它不需要额外的排序损耗。 cim 中的实际应用下面来看看在 cim 这个应用中是如何具体使用的，其中也包括上文提到的虚拟节点以及 hash 算法。 模板方法在应用的时候考虑到就算是一致性 hash 算法都有多种实现，为了方便其使用者扩展自己的一致性 hash 算法因此我定义了一个抽象类；其中定义了一些模板方法，这样大家只需要在子类中进行不同的实现即可完成自己的算法。 AbstractConsistentHash，这个抽象类的主要方法如下： add 方法自然是写入数据的。 sort 方法用于排序，但子类也不一定需要重写，比如 TreeMap 这样自带排序的容器就不用。 getFirstNodeValue 获取节点。 process 则是面向客户端的，最终只需要调用这个方法即可返回一个节点。 下面我们来看看利用 SortArrayMap 以及 AbstractConsistentHash 是如何实现的。 就是实现了几个抽象方法，逻辑和上文是一样的，只是抽取到了不同的方法中。 只是在 add 方法中新增了几个虚拟节点，相信大家也看得明白。 把虚拟节点的控制放到子类而没有放到抽象类中也是为了灵活性考虑，可能不同的实现对虚拟节点的数量要求也不一样，所以不如自定义的好。 但是 hash 方法确是放到了抽象类中，子类不用重写；因为这是一个基本功能，只需要有一个公共算法可以保证他散列地足够均匀即可。 因此在 AbstractConsistentHash 中定义了 hash 方法。 这里的算法摘抄自 xxl_job，网上也有其他不同的实现，比如 FNV1_32_HASH 等；实现不同但是目的都一样。 这样对于使用者来说就非常简单了： 他只需要构建一个服务列表，然后把当前的客户端信息传入 process 方法中即可获得一个一致性 hash 算法的返回。 同样的对于想通过 TreeMap 来实现也是一样的套路： 他这里不需要重写 sort 方法，因为自身写入时已经排好序了。 而在使用时对于客户端来说只需求修改一个实现类，其他的啥都不用改就可以了。 运行的效果也是一样的。 这样大家想自定义自己的算法时只需要继承 AbstractConsistentHash 重写相关方法即可，客户端代码无须改动。 路由算法扩展性但其实对于 cim 来说真正的扩展性是对路由算法来说的，比如它需要支持轮询、hash、一致性hash、随机、LRU等。 只是一致性 hash 也有多种实现，他们的关系就如下图： 应用还需要满足对这一类路由策略的灵活支持，比如我也想自定义一个随机的策略。 因此定义了一个接口：RouteHandle 12345678910public interface RouteHandle &#123; /** * 再一批服务器里进行路由 * @param values * @param key * @return */ String routeServer(List&lt;String&gt; values,String key) ;&#125; 其中只有一个方法，也就是路由方法；入参分别是服务列表以及客户端信息即可。 而对于一致性 hash 算法来说也是只需要实现这个接口，同时在这个接口中选择使用 SortArrayMapConsistentHash 还是 TreeMapConsistentHash 即可。 这里还有一个 setHash 的方法，入参是 AbstractConsistentHash；这就是用于客户端指定需要使用具体的那种数据结构。 而对于之前就存在的轮询策略来说也是同样的实现 RouteHandle 接口。 这里我只是把之前的代码搬过来了而已。 接下来看看客户端到底是如何使用以及如何选择使用哪种算法。 为了使客户端代码几乎不动，我将这个选择的过程放入了配置文件。 如果想使用原有的轮询策略，就配置实现了 RouteHandle 接口的轮询策略的全限定名。 如果想使用一致性 hash 的策略，也只需要配置实现了 RouteHandle 接口的一致性 hash 算法的全限定名。 当然目前的一致性 hash 也有多种实现，所以一旦配置为一致性 hash 后就需要再加一个配置用于决定使用 SortArrayMapConsistentHash 还是 TreeMapConsistentHash 或是自定义的其他方案。 同样的也是需要配置继承了 AbstractConsistentHash 的全限定名。 不管这里的策略如何改变，在使用处依然保持不变。 只需要注入 RouteHandle，调用它的 routeServer 方法。 123@Autowiredprivate RouteHandle routeHandle ;String server = routeHandle.routeServer(serverCache.getAll(),String.valueOf(loginReqVO.getUserId())); 既然使用了注入，那其实这个策略切换的过程就在创建 RouteHandle bean 的时候完成的。 也比较简单，需要读取之前的配置文件来动态生成具体的实现类，主要是利用反射完成的。 这样处理之后就比较灵活了，比如想新建一个随机的路由策略也是同样的套路；到时候只需要修改配置即可。 感兴趣的朋友也可提交 PR 来新增更多的路由策略。 总结希望看到这里的朋友能对这个算法有所理解，同时对一些设计模式在实际的使用也能有所帮助。 相信在金三银四的面试过程中还是能让面试官眼前一亮的，毕竟根据我这段时间的面试过程来看听过这个名词的都在少数😂（可能也是和候选人都在 1~3 年这个层级有关）。 以上所有源码： https://github.com/crossoverJie/cim 如果本文对你有所帮助还请不吝转发。]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[VLOG-004：国产程序员的一天]]></title>
    <url>%2F2019%2F02%2F20%2Fvlog%2FChinese-coder-daily%2F</url>
    <content type="text"><![CDATA[VLOG 近些年非常流行，最近这段时间我也拍了一些来记录生活。 之前一直想记录自己上班生活的一天；至于为什么标题要加上一个国产两字，是因为之前看到一位国外女程序媛的一天（视频链接见底部），这次是想让大家看看在天朝国情下的反差。 a day in the life of a software engineer:https://www.youtube.com/watch?v=rqX8PFcOpxA 正片开始 08:00 起床洗漱。 8:20 出门到轻轨站。 8:30 到达轻轨站。 9:00 到达公司开始干活。 10:00 一个电话远程面试。 11:00 一个电话远程面试。 中间有一段对自己这些天来面试经历的一些分享，视频加快了但是重点内容都打有字幕。 12:00 午饭时间。 15:00 部门内部会议到 16 点。 17:00 一个电话远程面试。 19:00 有时间做自己的撸码工作。 20:00 准备回家。 22:00 接女朋友下班。 00:30 完成一个算法，收工睡觉。 下一次录工作 VLOG 应该是等我当老板咯，希望别是有生之年系列。。。]]></content>
      <categories>
        <category>VLOG</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[利用策略模式优化过多 if else 代码]]></title>
    <url>%2F2019%2F01%2F30%2Fjava-senior%2Fdesign-if-else%2F</url>
    <content type="text"><![CDATA[前言不出意外，这应该是年前最后一次分享，本次来一点实际开发中会用到的小技巧。 比如平时大家是否都会写类似这样的代码： 123456789if(a)&#123; //dosomething&#125;else if(b)&#123; //doshomething&#125;else if(c)&#123; //doshomething&#125; else&#123; ////doshomething&#125; 条件少还好，一旦 else if 过多这里的逻辑将会比较混乱，并很容易出错。 比如这样： 摘自 cim 中的一个客户端命令的判断条件。 刚开始条件较少，也就没管那么多直接写的；现在功能多了导致每次新增一个 else 条件我都得仔细核对，生怕影响之前的逻辑。 这次终于忍无可忍就把他重构了，重构之后这里的结构如下： 最后直接变为两行代码，简洁了许多。 而之前所有的实现逻辑都单独抽取到其他实现类中。 这样每当我需要新增一个 else 逻辑，只需要新增一个类实现同一个接口便可完成。每个处理逻辑都互相独立互不干扰。 实现 按照目前的实现画了一个草图。 整体思路如下： 定义一个 InnerCommand 接口，其中有一个 process 函数交给具体的业务实现。 根据自己的业务，会有多个类实现 InnerCommand 接口；这些实现类都会注册到 Spring Bean 容器中供之后使用。 通过客户端输入命令，从 Spring Bean 容器中获取一个 InnerCommand 实例。 执行最终的 process 函数。 主要想实现的目的就是不在有多个判断条件，只需要根据当前客户端的状态动态的获取 InnerCommand 实例。 从源码上来看最主要的就是 InnerCommandContext 类，他会根据当前客户端命令动态获取 InnerCommand 实例。 第一步是获取所有的 InnerCommand 实例列表。 根据客户端输入的命令从第一步的实例列表中获取类类型。 根据类类型从 Spring 容器中获取具体实例对象。 因此首先第一步需要维护各个命令所对应的类类型。 所以在之前的枚举中就维护了命令和类类型的关系，只需要知道命令就能知道他的类类型。 这样才能满足只需要两行代码就能替换以前复杂的 if else，同时也能灵活扩展。 12InnerCommand instance = innerCommandContext.getInstance(msg);instance.process(msg) ; 总结当然还可以做的更灵活一些，比如都不需要显式的维护命令和类类型的对应关系。 只需要在应用启动时扫描所有实现了 InnerCommand 接口的类即可，在 cicada 中有类似实现，感兴趣的可以自行查看。 这样一些小技巧希望对你有所帮助。 以上所有源码可以在这里查看： https://github.com/crossoverJie/cim 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>Java 进阶</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>策略模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[长连接的心跳及重连设计]]></title>
    <url>%2F2019%2F01%2F23%2Fnetty%2Fcim03-heartbeat%2F</url>
    <content type="text"><![CDATA[前言说道“心跳”这个词大家都不陌生，当然不是指男女之间的心跳，而是和长连接相关的。 顾名思义就是证明是否还活着的依据。 什么场景下需要心跳呢？ 目前我们接触到的大多是一些基于长连接的应用需要心跳来“保活”。 由于在长连接的场景下，客户端和服务端并不是一直处于通信状态，如果双方长期没有沟通则双方都不清楚对方目前的状态；所以需要发送一段很小的报文告诉对方“我还活着”。 同时还有另外几个目的： 服务端检测到某个客户端迟迟没有心跳过来可以主动关闭通道，让它下线。 客户端检测到某个服务端迟迟没有响应心跳也能重连获取一个新的连接。 正好借着在 cim有这样两个需求来聊一聊。 心跳实现方式心跳其实有两种实现方式： TCP 协议实现（keepalive 机制）。 应用层自己实现。 由于 TCP 协议过于底层，对于开发者来说维护性、灵活度都比较差同时还依赖于操作系统。 所以我们这里所讨论的都是应用层的实现。 如上图所示，在应用层通常是由客户端发送一个心跳包 ping 到服务端，服务端收到后响应一个 pong 表明双方都活得好好的。 一旦其中一端延迟 N 个时间窗口没有收到消息则进行不同的处理。 客户端自动重连先拿客户端来说吧，每隔一段时间客户端向服务端发送一个心跳包，同时收到服务端的响应。 常规的实现应当是： 开启一个定时任务，定期发送心跳包。 收到服务端响应后更新本地时间。 再有一个定时任务定期检测这个“本地时间”是否超过阈值。 超过后则认为服务端出现故障，需要重连。 这样确实也能实现心跳，但并不友好。 在正常的客户端和服务端通信的情况下，定时任务依然会发送心跳包；这样就显得没有意义，有些多余。 所以理想的情况应当是客户端收到的写消息空闲时才发送这个心跳包去确认服务端是否健在。 好消息是 Netty 已经为我们考虑到了这点，自带了一个开箱即用的 IdleStateHandler 专门用于心跳处理。 来看看 cim 中的实现： 在 pipeline 中加入了一个 10秒没有收到写消息的 IdleStateHandler，到时他会回调 ChannelInboundHandler 中的 userEventTriggered 方法。 所以一旦写超时就立马向服务端发送一个心跳（做的更完善应当在心跳发送失败后有一定的重试次数）； 这样也就只有在空闲时候才会发送心跳包。 但一旦间隔许久没有收到服务端响应进行重连的逻辑应当写在哪里呢？ 先来看这个示例： 当收到服务端响应的 pong 消息时，就在当前 Channel 上记录一个时间，也就是说后续可以在定时任务中取出这个时间和当前时间的差额来判断是否超过阈值。 超过则重连。 同时在每次心跳时候都用当前时间和之前服务端响应绑定到 Channel 上的时间相减判断是否需要重连即可。 也就是 heartBeatHandler.process(ctx); 的执行逻辑。 伪代码如下： 123456789101112@Overridepublic void process(ChannelHandlerContext ctx) throws Exception &#123; long heartBeatTime = appConfiguration.getHeartBeatTime() * 1000; Long lastReadTime = NettyAttrUtil.getReaderTime(ctx.channel()); long now = System.currentTimeMillis(); if (lastReadTime != null &amp;&amp; now - lastReadTime &gt; heartBeatTime)&#123; reconnect(); &#125;&#125; IdleStateHandler 误区一切看起来也没毛病，但实际上却没有这样实现重连逻辑。 最主要的问题还是对 IdleStateHandler 理解有误。 我们假设下面的场景： 客户端通过登录连上了服务端并保持长连接，一切正常的情况下双方各发心跳包保持连接。 这时服务端突入出现 down 机，那么理想情况下应当是客户端迟迟没有收到服务端的响应从而 userEventTriggered 执行定时任务。 判断当前时间 - UpdateWriteTime &gt; 阈值 时进行重连。 但却事与愿违，并不会执行 2、3两步。 因为一旦服务端 down 机、或者是与客户端的网络断开则会回调客户端的 channelInactive 事件。 IdleStateHandler 作为一个 ChannelInbound 也重写了 channelInactive() 方法。 这里的 destroy() 方法会把之前开启的定时任务都给取消掉。 所以就不会再有任何的定时任务执行了，也就不会有机会执行这个重连业务。 靠谱实现因此我们得有一个单独的线程来判断是否需要重连，不依赖于 IdleStateHandler。 于是 cim 在客户端感知到网络断开时就会开启一个定时任务： 之所以不在客户端启动就开启，是为了节省一点线程消耗。网络问题虽然不可避免，但在需要的时候开启更能节省资源。 在这个任务重其实就是执行了重连，限于篇幅具体代码就不贴了，感兴趣的可以自行查阅。 同时来验证一下效果。 启动两个服务端，再启动客户端连接上一台并保持长连接。这时突然手动关闭一台服务，客户端可以自动重连到可用的那台服务节点。 启动客户端后服务端也能收到正常的 ping 消息。 利用 :info 命令查看当前客户端的链接状态发现连的是 9000端口。 :info 是一个新增命令，可以查看一些客户端信息。 这时我关掉连接上的这台节点。 1kill -9 2142 这时客户端会自动重连到可用的那台节点。这个节点也收到了上线日志以及心跳包。 服务端自动剔除离线客户端现在来看看服务端，它要实现的效果就是延迟 N 秒没有收到客户端的 ping 包则认为客户端下线了，在 cim 的场景下就需要把他踢掉置于离线状态。 消息发送误区这里依然有一个误区，在调用 ctx.writeAndFlush() 发送消息获取回调时。 其中是 isSuccess 并不能作为消息发送成功与否的标准。 也就是说即便是客户端直接断网，服务端这里发送消息后拿到的 success 依旧是 true。 这是因为这里的 success 只是告知我们消息写入了 TCP 缓冲区成功了而已。 和我之前有着一样错误理解的不在少数，这是 Netty 官方给的回复。 相关 issue： https://github.com/netty/netty/issues/4915 同时感谢 95老徐以及闪电侠的一起排查。 所以我们不能依据此来关闭客户端的连接，而是要像上文一样判断 Channel 上绑定的时间与当前时间只差是否超过了阈值。 以上则是 cim 服务端的实现，逻辑和开头说的一致，也和 Dubbo 的心跳机制有些类似。 于是来做个试验：正常通信的客户端和服务端，当我把客户端直接断网时，服务端会自动剔除客户端。 总结这样就实现了文初的两个要求。 服务端检测到某个客户端迟迟没有心跳过来可以主动关闭通道，让它下线。 客户端检测到某个服务端迟迟没有响应心跳也能重连获取一个新的连接。 同时也踩了两个误区，坑一个人踩就可以了，希望看过本文的都有所收获避免踩坑。 本文所有相关代码都在此处，感兴趣的可以自行查看： https://github.com/crossoverJie/cim 如果本文对你有所帮助还请不吝转发。]]></content>
      <categories>
        <category>Netty</category>
        <category>cim</category>
      </categories>
      <tags>
        <tag>Heartbeat</tag>
        <tag>IM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为自己搭建一个分布式 IM 系统二【从查找算法聊起】]]></title>
    <url>%2F2019%2F01%2F14%2Fnetty%2Fcim02-v1.0.1%2F</url>
    <content type="text"><![CDATA[前言 最近这段时间确实有点忙，这篇的目录还是在飞机上敲出来了的。 言归正传，上周更新了 cim 第一版：为自己搭建一个分布式 IM(即时通讯) 系统；没想到反响热烈，最高时上了 GitHub Trending Java 版块的首位，一天收到了 300+ 的 star。 现在总共也有 1.3K+ 的 star，有几十个朋友参加了测试，非常感谢大家的支持。 在这过程中也收到一些 bug 反馈，feature 建议；因此这段时间我把一些影响较大的 bug 以及需求比较迫切的 feature 调整了，本次更新的 v1.0.1 版本： 客户端超时自动下线。 新增 AI 模式。 聊天记录查询。 在线用户前缀模糊匹配。 下面谈下几个比较重点的功能。 客户端超时自动下线 这个功能涉及到客户端和服务端的心跳设计，比较有意思，也踩了几个坑；所以准备留到下次单独来聊。 AI 模式大家应该还记得这个之前刷爆朋友圈的 估值两个一个亿的 AI 核心代码。 和我这里的场景再合适不过了。 于是我新增了一个命令用于一键开启 AI 模式，使用情况大概如下。 欢迎大家更新源码体验，融资的请私聊我🤣。 聊天记录聊天记录也是一个比较迫切的功能。 使用命令 :q 关键字 即可查询与个人相关的聊天记录。 这个功能其实比较简单，只需要在消息发送及接收消息时保存即可。 但要考虑的一点是，这个保存消息是 IO 操作，不可避免的会有耗时；需要尽量避免对消息发送、接收产生影响。 异步写入消息因此我把消息写入的过程异步完成，可以不影响真正的业务。 实现起来也挺简单，就是一个典型的生产者消费者模式。 主线程收到消息之后直接写入队列，另外再有一个线程一直源源不断的从队列中取出数据后保存聊天记录。 大概的代码如下： 写入消息的同时会把消费消息的线程打开： 而最终存放消息记录的策略，考虑后还是以最简单的方式存放在客户端，可以降低复杂度。 简单来说就是根据当前日期+用户名写入到磁盘里。 当客户端关闭时利用线程中断的方式停止了消费队列的线程。 这点的设计其实和 logback 写日志的方式比较类似，感兴趣的可以去翻翻 logback 的源码，更加详细。 回调接口至于收到其他客户端发来的消息时则是利用之前预留的消息回调接口来写入日志。 收到消息后会执行自定义的回调接口。 于是在这个回调方法中实现写入逻辑即可，当后续还有其他的消息处理逻辑时也能在这里直接添加。 当处理逻辑增多时最好是改为责任链模式，更加清晰易维护。 查找算法接下来是本文着重要讨论的一个查找算法，准确的说是一个前缀模糊匹配的算法。 实现的效果如下： 使用命令 :qu prefix 可以按照前缀的方式搜索用户信息。 当然在命令行中其实意义不大，但是在移动端中确是比较有用的。类似于微信按照用户名匹配： 因为后期打算出一个移动端 APP，所以就先把这个功能实现了。 从效果也看得出来：就是按照输入的前缀匹配字符串（目前只支持英文）。 在没有任何限制的条件下最快、最简单的实现方式可以直接把所有的字符串存放在一个容器中 （List、Set），查询时则挨个遍历；利用 String.startsWith(&quot;prefix&quot;) 进行匹配。 但这样会有几个问题： 存储资源比较浪费，不管是 list 还是 Set 都会有额外的损耗。 查询效率较低，需要遍历集合后再遍历字符串的 char 数组（String.startsWith 的实现方式）。 字典树基于以上的问题我们可以考虑下： 假设我需要存放 java,javascript,jsp,php 这些字符串时在 ArrayList 中会怎么存放？ 很明显，会是这样完整的存放在一个数组中；同时这个数组还可能存在浪费，没有全部使用完。 但其实仔细观察这些数据会发现有一些共同特点，比如 java,javascript 有共同的前缀 java;和 jsp 有共同的前缀 j。 那是否可以把这些前缀利用起来呢？这样就可以少存储一份。 比如写入 java,javascript 这两个字符串时存放的结构如下： 当再存入一个 jsp 时： 最后再存入 jsf 时： 相信大家应该已经看明白了，按照这样的存储方式可以节省很多内存，同时查询效率也比较高。 比如查询以 jav 开头的数据，只需要从头结点 j 开始往下查询，最后会查询到 ava 以及 script 这两个个结点，所以整个查询路径所经历的字符拼起来就是查询到的结果java+javascript。 如果以 b 开头进行查询，那第一步就会直接返回，这样比在 list 中的效率高很多。 但这个图还不完善，因为不知道查询到啥时候算是匹配到了一个之前写入的字符串。 比如在上图中怎么知道 j+ava 是一个我们之前写入的 java 这个字符呢。 因此我们需要对这种是一个完整字符串的数据打上一个标记： 比如这样，我们将 ava、script、p、f 这几个节点都换一个颜色表示。表明查询到这个字符时就算是匹配到了一个结果。 而查到 s 这个字符颜色不对，代表还需要继续往下查。 比如输入关键字 js 进行匹配时，当它的查询路径走到 s 这里时判断到 s 的颜色不对，所以不会把 js 作为一个匹配结果。而是继续往下查，发现有两个子节点 p、f 颜色都正确，于是把查询的路径 jsp 和 jsf 都作为一个匹配结果。 而只输入 j，则会把下面所有有色的字符拼起来作为结果集合。 这其实就一个典型的字典树。 具体实现下面则是具体的代码实现，其实算法不像是实现一个业务功能这样好用文字分析；具体还是看源码多调试就明白了。 谈下几个重点的地方吧： 字典树的节点实现，其中的 isEnd 相当于图中的上色。 利用一个 Node[] children 来存放子节点。 为了可以区分大小写查询，所以子节点的长度相当于是 26*2。 写入数据 这里以一个单测为例，写入了三个字符串，那最终形成的数据结构如下： 图中有与上图有几点不同： 每个节点都是一个字符，这样树的高度最高为52。 每个节点的子节点都是长度为 52 的数组；所以可以利用数组的下标表示他代表的字符值。比如 0 就是大 A,26 则是小 a，以此类推。 有点类似于之前提到的布隆过滤器，可以节省内存。 debug 时也能看出符合上图的数据结构： 所以真正的写入步骤如下： 把字符串拆分为 char 数组，并判断大小写计算它所存放在数组中的位置 index。 将当前节点的子节点数组的 index 处新增一个节点。 如果是最后一个字符就将新增的节点置为最后一个节点，也就是上文的改变节点颜色。 最后将当前节点指向下一个节点方便继续写入。 查询总的来说要麻烦一些，其实就是对树进行深度遍历；最终的思想看图就能明白。 所以在 cim 中进行模糊匹配时就用到了这个结构。 字典树的源码在此处： https://github.com/crossoverJie/cim/blob/master/cim-common/src/main/java/com/crossoverjie/cim/common/data/construct/TrieTree.java 其实利用这个结构还能实现判断某个前缀的单词是否在某堆数据里、某个前缀的单词出现的次数等。 总结目前 cim 还在火热内测中（虽然群里只有20几人）,感兴趣的朋友可以私聊我拉你入伙☺️ 再没有新的 BUG 产生前会着重把这些功能完成了，不出意外下周更新 cim 的心跳重连等机制。 完整源码： https://github.com/crossoverJie/cim 如果这篇对你有所帮助还请不吝转发。]]></content>
      <categories>
        <category>Netty</category>
        <category>cim</category>
      </categories>
      <tags>
        <tag>IM</tag>
        <tag>TrieTree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为自己搭建一个分布式 IM(即时通讯) 系统]]></title>
    <url>%2F2019%2F01%2F02%2Fnetty%2Fcim01-started%2F</url>
    <content type="text"><![CDATA[前言大家新年快乐！ 新的一年第一篇技术文章希望开个好头，所以元旦三天我也没怎么闲着，希望给大家带来一篇比较感兴趣的干货内容。 老读者应该还记得我在去年国庆节前分享过一篇《设计一个百万级的消息推送系统》；虽然我在文中有贴一些伪代码，依然有些朋友希望能直接分享一些可以运行的源码；这么久了是时候把坑填上了。 本文较长，高能预警；带好瓜子板凳。 于是在之前的基础上我完善了一些内容，先来看看这个项目的介绍吧： CIM(CROSS-IM) 一款面向开发者的 IM(即时通讯)系统；同时提供了一些组件帮助开发者构建一款属于自己可水平扩展的 IM 。 借助 CIM 你可以实现以下需求： IM 即时通讯系统。 适用于 APP 的消息推送中间件。 IOT 海量连接场景中的消息透传中间件。 完整源码托管在 GitHub : https://github.com/crossoverJie/cim 演示本次主要涉及到 IM 即时通讯，所以特地录了两段视频演示（群聊、私聊）。 点击下方链接可以查看视频版 Demo。 YouTube Bilibili 群聊 私聊 群聊 私聊 也在公网部署了一套演示环境，想要试一试的可以联系我加入内测群获取账号一起尬聊😋。 架构设计下面来看看具体的架构设计。 CIM 中的各个组件均采用 SpringBoot 构建。 采用 Netty + Google Protocol Buffer 构建底层通信。 Redis 存放各个客户端的路由信息、账号信息、在线状态等。 Zookeeper 用于 IM-server 服务的注册与发现。 整体主要由以下模块组成： cim-serverIM 服务端；用于接收 client 连接、消息透传、消息推送等功能。 支持集群部署。 cim-forward-route消息路由服务器；用于处理消息路由、消息转发、用户登录、用户下线以及一些运营工具（获取在线用户数等）。 cim-clientIM 客户端；给用户使用的消息终端，一个命令即可启动并向其他人发起通讯（群聊、私聊）；同时内置了一些常用命令方便使用。 流程图整体的流程也比较简单，流程图如下： 客户端向 route 发起登录。 登录成功从 Zookeeper 中选择可用 IM-server 返回给客户端，并保存登录、路由信息到 Redis。 客户端向 IM-server 发起长连接，成功后保持心跳。 客户端下线时通过 route 清除状态信息。 所以当我们自己部署时需要以下步骤： 搭建基础中间件 Redis、Zookeeper。 部署 cim-server，这是真正的 IM 服务器，为了满足性能需求所以支持水平扩展，只需要注册到同一个 Zookeeper 即可。 部署 cim-forward-route，这是路由服务器，所有的消息都需要经过它。由于它是无状态的，所以也可以利用 Nginx 代理提高可用性。 cim-client 真正面向用户的客户端；启动之后会自动连接 IM 服务器便可以在控制台收发消息了。 更多使用介绍可以参考快速启动。 详细设计接下来重点看看具体的实现，比如群聊、私聊消息如何流转；IM 服务端负载均衡；服务如何注册发现等等。 IM 服务端先来看看服务端；主要是实现客户端上下线、消息下发等功能。 首先是服务启动： 由于是在 SpringBoot 中搭建的，所以在应用启动时需要启动 Netty 服务。 从 pipline 中可以看出使用了 Protobuf 的编解码（具体报文在客户端中分析）。 注册发现需要满足 IM 服务端的水平扩展需求，所以 cim-server 是需要将自身数据发布到注册中心的。 这里参考之前分享的《搞定服务注册与发现》有具体介绍。 所以在应用启动成功后需要将自身数据注册到 Zookeeper 中。 最主要的目的就是将当前应用的 ip + cim-server-port+ http-port 注册上去。 上图是我在演示环境中注册的两个 cim-server 实例（由于在一台服务器，所以只是端口不同）。 这样在客户端（监听这个 Zookeeper 节点）就能实时的知道目前可用的服务信息。 登录当客户端请求 cim-forward-route 中的登录接口（详见下文）做完业务验证（就相当于日常登录其他网站一样）之后，客户端会向服务端发起一个长连接，如之前的流程所示： 这时客户端会发送一个特殊报文，表明当前是登录信息。 服务端收到后就需要将该客户端的 userID 和当前 Channel 通道关系保存起来。 同时也缓存了用户的信息，也就是 userID 和 用户名。 离线当客户端断线后也需要将刚才缓存的信息清除掉。 同时也需要调用 route 接口清除相关信息（具体接口看下文）。 IM 路由 从架构图中可以看出，路由层是非常重要的一环；它提供了一系列的 HTTP 服务承接了客户端和服务端。 目前主要是以下几个接口。 注册接口 由于每一个客户端都是需要登录才能使用的，所以第一步自然是注册。 这里就设计的比较简单，直接利用 Redis 来存储用户信息；用户信息也只有 ID 和 userName 而已。 只是为了方便查询在 Redis 中的 KV 又反过来存储了一份 VK，这样 ID 和 userName 都必须唯一。 登录接口这里的登录和 cim-server 中的登录不一样，具有业务性质， 登录成功之后需要判断是否是重复登录（一个用户只能运行一个客户端）。 登录成功后需要从 Zookeeper 中获取服务列表（cim-server）并根据某种算法选择一台服务返回给客户端。 登录成功之后还需要保存路由信息，也就是当前用户分配的服务实例保存到 Redis 中。 为了实现只能一个用户登录，使用了 Redis 中的 set 来保存登录信息；利用 userID 作为 key ，重复的登录就会写入失败。 类似于 Java 中的 HashSet，只能去重保存。 获取一台可用的路由实例也比较简单： 先从 Zookeeper 获取所有的服务实例做一个内部缓存。 轮询选择一台服务器（目前只有这一种算法，后续会新增）。 当然要获取 Zookeeper 中的服务实例前自然是需要监听 cim-server 之前注册上去的那个节点。 具体代码如下： 也是在应用启动之后监听 Zookeeper 中的路由节点，一旦发生变化就会更新内部缓存。 这里使用的是 Guava 的 cache，它基于 ConcurrentHashMap，所以可以保证清除、新增缓存的原子性。 群聊接口这是一个真正发消息的接口，实现的效果就是其中一个客户端发消息，其余所有客户端都能收到！ 流程肯定是客户端发送一条消息到服务端，服务端收到后在上文介绍的 SessionSocketHolder 中遍历所有 Channel（通道）然后下发消息即可。 服务端是单机倒也可以，但现在是集群设计。所以所有的客户端会根据之前的轮询算法分配到不同的 cim-server 实例中。 因此就需要路由层来发挥作用了。 路由接口收到消息后首先遍历出所有的客户端和服务实例的关系。 路由关系在 Redis 中的存放如下： 由于 Redis 单线程的特质，当数据量大时；一旦使用 keys 匹配所有 cim-route:* 数据，会导致 Redis 不能处理其他请求。 所以这里改为使用 scan 命令来遍历所有的 cim-route:*。 接着会挨个调用每个客户端所在的服务端的 HTTP 接口用于推送消息。 在 cim-server 中的实现如下： cim-server 收到消息后会在内部缓存中查询该 userID 的通道，接着只需要发消息即可。 在线用户接口这是一个辅助接口，可以查询出当前在线用户信息。 实现也很简单，也就是查询之前保存 ”用户登录状态的那个去重 set “即可。 私聊接口之所以说获取在线用户是一个辅助接口，其实就是用于辅助私聊使用的。 一般我们使用私聊的前提肯定得知道当前哪些用户在线，接着你才会知道你要和谁进行私聊。 类似于这样： 在我们这个场景中，私聊的前提就是需要获得在线用户的 userID。 所以私聊接口在收到消息后需要查询到接收者所在的 cim-server 实例信息，后续的步骤就和群聊一致了。调用接收者所在实例的 HTTP 接口下发信息。 只是群聊是遍历所有的在线用户，私聊只发送一个的区别。 下线接口一旦客户端下线，我们就需要将之前存放在 Redis 中的一些信息删除掉（路由信息、登录状态）。 IM 客户端客户端中的一些逻辑其实在上文已经谈到一些了。 登录第一步也就是登录，需要在启动时调用 route 的登录接口，获得 cim-server 信息再创建连接。 登录过程中 route 接口会判断是否为重复登录，重复登录则会直接退出程序。 接下来是利用 route 接口返回的 cim-server 实例信息（ip+port）创建连接。 最后一步就是发送一个登录标志的信息到服务端，让它保持客户端和 Channel 的关系。 自定义协议上文提到的一些登录报文、真正的消息报文这些其实都是在我们自定义协议中可以区别出来的。 由于是使用 Google Protocol Buffer 编解码，所以先看看原始格式。 其实这个协议中目前一共就三个字段： requestId 可以理解为 userId。 reqMsg 就是真正的消息。 type 也就是上文提到的消息类别。 目前主要是三种类型，分别对应不同的业务： 心跳为了保持客户端和服务端的连接，每隔一段时间没有发送消息都需要自动的发送心跳。 目前的策略是每隔一分钟就是发送一个心跳包到服务端： 这样服务端每隔一分钟没有收到业务消息时就会收到 ping 的心跳包： 内置命令客户端也内置了一些基本命令来方便使用。 命令 描述 :q 退出客户端 :olu 获取所有在线用户信息 :all 获取所有命令 : 更多命令正在开发中。。 比如输入 :q 就会退出客户端，同时会关闭一些系统资源。 当输入 :olu(onlineUser 的简写)就会去调用 route 的获取所有在线用户接口。 群聊群聊的使用非常简单，只需要在控制台输入消息回车即可。 这时会去调用 route 的群聊接口。 私聊私聊也是同理，但前提是需要触发关键字；使用 userId;;消息内容 这样的格式才会给某个用户发送消息，所以一般都需要先使用 :olu 命令获取所以在线用户才方便使用。 消息回调为了满足一些定制需求，比如消息需要保存之类的。 所以在客户端收到消息之后会回调一个接口，在这个接口中可以自定义实现。 因此先创建了一个 caller 的 bean，这个 bean 中包含了一个 CustomMsgHandleListener 接口，需要自行处理只需要实现此接口即可。 自定义界面由于我自己不怎么会写界面，但保不准有其他大牛会写。所以客户端中的群聊、私聊、获取在线用户、消息回调等业务(以及之后的业务)都是以接口形式提供。 也方便后面做页面集成，只需要调这些接口就行了；具体实现不用怎么关心。 总结cim 目前只是第一版，BUG 多，功能少（只拉了几个群友做了测试）；不过后续还会接着完善，至少这一版会给那些没有相关经验的朋友带来一些思路。 后续计划： 完整源码： https://github.com/crossoverJie/cim 如果这篇对你有所帮助还请不吝转发。]]></content>
      <categories>
        <category>Netty</category>
        <category>cim</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Zookeeper</tag>
        <tag>IM</tag>
        <tag>推送</tag>
        <tag>IOT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018 年度复盘]]></title>
    <url>%2F2018%2F12%2F30%2Fannual-summary%2F2018%2F</url>
    <content type="text"><![CDATA[前言看着今年的进度表已经所剩无几，是时候来复盘一把了。 从 16 年初写博客开始到现在我觉得写年终总结的习惯不错，毕竟每次看着去年的 flag 又可以复制粘贴了。 今年我会从工作、技术、身体等方面回顾，这几块也是今年变化最大的几个点。 工作先说工作吧，这个变化也贯穿了整年。 从今年年初开始，我从上一个技术团队调到现在的部门；首先是组织结构上的变更，当然更主要的还是角色的变化。 由一个开发人员转变为团队的技术负责人，说实话刚开始是措手不及的。 以前我只需要对我写的代码负责，现在不行了。得对整个团队的产出负责；需要为每一个成员的质量、成长负责。 这对于一个刚入门的菜鸟来说挑战无疑是巨大的。 而且整个研发团队基本上是重头组建，我这入职一年多的都成了司龄最大的老员工了😢。 随着人员的增加，对我的要求也越来越高。在请教了老司机后也逐渐的走上正轨了，虽然中间也踩了不少坑。 总的来说： 以前只关注我代码写的 6 不 6；现在重点是整个团队的研发进度、质量把控。这两点是评估我工作好坏的直接因素。 要把这两项搞好我不得不提高一些通用技能：包括沟通协调、需求判断、排期风险、人员流动等。 明年的人数还会持续增加，要学的东西还有很多。 技术作为一个代码从业者，技术能力才是我的本职工作。 随着今年业务性质的变化，我所接触的技术也略有不同。 前几年打交道的主要是 web 相关的技术；大多数技术栈都是围绕着它来展开的。 而今年不太一样的是在 web 的基础上，还需要涉及到网络。主要是现在业务和物联网相关，看平台的还好最直接的就是能支持了多少连接。 这个就需要对物联网特有的一些协议有所了解、应用。 所以今年恶补了 Netty 相关的知识，同时在平时的开发中进行了一些实践发现想要做好网络这种底层开发需要储备的知识太多了。 什么操作系统、IO、TCP 都得掌握，正好也补习了这些短板。 开源项目 GitHub 官方的年度报告可以看出今年是开源大年。 从我今年的贡献图可以看出也花了很多时间在这上面。 从注册 GitHub 账号算起每年的提交量看起来今年确实是花了不少心思： 最显著的体现就是 JCSprout 一年时间涨了 1W7 star。 主要开源的有： JCSprout Java Core Sprout：处于萌芽阶段的 Java 核心知识库。 cicada 基于 Netty 实现的快速、轻量级 HTTP 框架。 distributed-redis-tool 根据日常需求实现的一个分布式工具，包括分布式锁、分布式限流。 netty-action 看名字就知道，一个 netty 实战相关案例，现在也正在修改为可水平扩展的 IM 即使通讯系统；预计元旦后发布。 要感谢每一位给我提 issue、PR 的朋友，希望来年能把挖的坑填完😭。 技术博客 从年初到现在一共撸了 49 篇博客，我还特意按照时间排序、阅读量做了一个柱状图（数据来源为个人博客：https://crossoverjie.top ）： 统计了一下，全年这个博客的阅读总数为：22W，平均每篇差不多 4500 的阅读；虽说不能和一些大佬相比，但比去年可不知道高哪里去了。 同时最高的有将近 2W 当然低的也有4 500的阅读数，不过从这个图中还是可以看出一些规律的。 比如阅读量高的也是比较吸引眼球的，这不就是常说的“标题党”嘛。 微信公众号再来谈谈公众号，现在做公众号的技术人也越来越多；不过在今年申请的账号已经没有留言功能了，还好我申请的早，至少和读者有一个交流的机会。 今年也是把公众号从 0 做到了 1 ，也就是有了 1W+ 的关注数；不过说实话我确实没有画什么心思运营，里面的内容也都是同步于我的博客，除了几篇翻译之外可以说是 100% 原创。 写过技术文的应该都知道产出一篇文章并不轻松，所以为了能正向激励我也会适当的接一些广告；这样不管是对读者还是我都有好处。 中途也有一些朋友找我投稿，由于目前不是定位于做一个自媒体；我个人也不能完全对转载的文章理解透彻，还是希望做一个原创的技术号，所以抱歉都没有转载。 身体从前几年的计划表中都提到了身体，但实话说直到现在记性没长只有体重长了。。。 原本热爱的篮球也从每周一次调整为一个月一次，曾经潇洒的 crossover 也变为键盘里一个个的 Bug。 从下面的视频中可以看得出来（需要 FQ 观看）： 第一段是五年前的，后面两段为最近的。 明年真得上心了，借着搬家到新小区内的篮球场看能否拯救我这多年的键盘手。 总结回顾一下对于我个人的几个大事件吧： 工作角色大变化，带来的挑战也很大。 做了几个还算成功开源项目，并且带来了一些实质性的好处。 公众号从 0 到 1 ，并且能补贴一些鸡腿钱。 求婚成功，感谢高中班主任当年的不杀之恩（没有揭发我）。 等了三年终于接房装修了。 按照历史传统照例还是写个明年的 TODO-LIST 吧： 别拖团队后腿，多和老司机学习下软技能。 开源项目接着更新，这也是可持续发展道路之一。 博客、公众号持续输出优质内容，只是更新周期可能会提高。 要逼就往死里逼，看年底能否扣个篮！ 搞个事情，看能否把婚接了。 对来年写总结的我诚恳的说一句：别在 Ctrl+C,Ctrl+V 了🙏。]]></content>
      <categories>
        <category>annual-summary</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一次生产 CPU 100% 排查优化实践]]></title>
    <url>%2F2018%2F12%2F17%2Ftroubleshoot%2Fcpu-percent-100%2F</url>
    <content type="text"><![CDATA[前言到了年底果然都不太平，最近又收到了运维报警：表示有些服务器负载非常高，让我们定位问题。 还真是想什么来什么，前些天还故意把某些服务器的负载提高（没错，老板让我写个 BUG！），不过还好是不同的环境互相没有影响。 定位问题拿到问题后首先去服务器上看了看，发现运行的只有我们的 Java 应用。于是先用 ps 命令拿到了应用的 PID。 接着使用 top -Hp pid 将这个进程的线程显示出来。输入大写的 P 可以将线程按照 CPU 使用比例排序，于是得到以下结果。 果然某些线程的 CPU 使用率非常高。 为了方便定位问题我立马使用 jstack pid &gt; pid.log 将线程栈 dump 到日志文件中。 我在上面 100% 的线程中随机选了一个 pid=194283 转换为 16 进制（2f6eb）后在线程快照中查询： 因为线程快照中线程 ID 都是16进制存放。 发现这是 Disruptor 的一个堆栈，前段时间正好解决过一个由于 Disruptor 队列引起的一次 OOM：强如 Disruptor 也发生内存溢出？ 没想到又来一出。 为了更加直观的查看线程的状态信息，我将快照信息上传到专门分析的平台上。 http://fastthread.io/ 其中有一项菜单展示了所有消耗 CPU 的线程，我仔细看了下发现几乎都是和上面的堆栈一样。 也就是说都是 Disruptor 队列的堆栈，同时都在执行 java.lang.Thread.yield 函数。 众所周知 yield 函数会让当前线程让出 CPU 资源，再让其他线程来竞争。 根据刚才的线程快照发现处于 RUNNABLE 状态并且都在执行 yield 函数的线程大概有 30几个。 因此初步判断为大量线程执行 yield 函数之后互相竞争导致 CPU 使用率增高，而通过对堆栈发现是和使用 Disruptor 有关。 解决问题而后我查看了代码，发现是根据每一个业务场景在内部都会使用 2 个 Disruptor 队列来解耦。 假设现在有 7 个业务类型，那就等于是创建 2*7=14 个 Disruptor 队列，同时每个队列有一个消费者，也就是总共有 14 个消费者（生产环境更多）。 同时发现配置的消费等待策略为 YieldingWaitStrategy 这种等待策略确实会执行 yield 来让出 CPU。 代码如下： 初步看来和这个等待策略有很大的关系。 本地模拟为了验证，我在本地创建了 15 个 Disruptor 队列同时结合监控观察 CPU 的使用情况。 创建了 15 个 Disruptor 队列，同时每个队列都用线程池来往 Disruptor队列 里面发送 100W 条数据。 消费程序仅仅只是打印一下。 跑了一段时间发现 CPU 使用率确实很高。 同时 dump 线程发现和生产的现象也是一致的：消费线程都处于 RUNNABLE 状态，同时都在执行 yield。 通过查询 Disruptor 官方文档发现： YieldingWaitStrategy 是一种充分压榨 CPU 的策略，使用自旋 + yield的方式来提高性能。当消费线程（Event Handler threads）的数量小于 CPU 核心数时推荐使用该策略。 同时查阅到其他的等待策略 BlockingWaitStrategy （也是默认的策略），它使用的是锁的机制，对 CPU 的使用率不高。 于是在和之前同样的条件下将等待策略换为 BlockingWaitStrategy。 和刚才的 CPU 对比会发现到后面使用率的会有明显的降低；同时 dump 线程后会发现大部分线程都处于 waiting 状态。 优化解决看样子将等待策略换为 BlockingWaitStrategy 可以减缓 CPU 的使用， 但留意到官方对 YieldingWaitStrategy 的描述里谈道：当消费线程（Event Handler threads）的数量小于 CPU 核心数时推荐使用该策略。 而现有的使用场景很明显消费线程数已经大大的超过了核心 CPU 数了，因为我的使用方式是一个 Disruptor 队列一个消费者，所以我将队列调整为只有 1 个再试试(策略依然是 YieldingWaitStrategy)。 跑了一分钟，发现 CPU 的使用率一直都比较平稳而且不高。 总结所以排查到此可以有一个结论了，想要根本解决这个问题需要将我们现有的业务拆分；现在是一个应用里同时处理了 N 个业务，每个业务都会使用好几个 Disruptor 队列。 由于是在一台服务器上运行，所以 CPU 资源都是共享的，这就会导致 CPU 的使用率居高不下。 所以我们的调整方式如下： 为了快速缓解这个问题，先将等待策略换为 BlockingWaitStrategy，可以有效降低 CPU 的使用率（业务上也还能接受）。 第二步就需要将应用拆分（上文模拟的一个 Disruptor 队列），一个应用处理一种业务类型；然后分别单独部署，这样也可以互相隔离互不影响。 当然还有其他的一些优化，因为这也是一个老系统了，这次 dump 线程居然发现创建了 800+ 的线程。 创建线程池的方式也是核心线程数、最大线程数是一样的，导致一些空闲的线程也得不到回收；这样会有很多无意义的资源消耗。 所以也会结合业务将创建线程池的方式调整一下，将线程数降下来，尽量的物尽其用。 本文的演示代码已上传至 GitHub： https://github.com/crossoverJie/JCSprout 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>问题排查</category>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>concurrent</tag>
        <tag>JVM</tag>
        <tag>disruptor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[没错，老板让我写个 BUG！]]></title>
    <url>%2F2018%2F12%2F12%2Fjava-senior%2Fjava-memary-allocation%2F</url>
    <content type="text"><![CDATA[前言标题没有看错，真的是让我写个 bug！ 刚接到这个需求时我内心没有丝毫波澜，甚至还有点激动。这可是我特长啊；终于可以光明正大的写 bug 了🙄。 先来看看具体是要干啥吧，其实主要就是要让一些负载很低的服务器额外消耗一些内存、CPU 等资源（至于背景就不多说了），让它的负载可以提高一些。 JVM 内存分配回顾于是我刷刷一把梭的就把代码写好了，大概如下： 写完之后我就在想一个问题，代码中的 mem 对象在方法执行完之后会不会被立即回收呢？我想肯定会有一部分人认为就是在方法执行完之后回收。 我也正儿八经的去调研了下，问了一些朋友；果不其然确实有一部分认为是在方法执行完毕之后回收。 那事实情况如何呢？我做了一个试验。 我用以下的启动参数将刚才这个应用启动起来。 123456java -Djava.rmi.server.hostname=10.xx.xx.xx -Djava.security.policy=jstatd.all.policy -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=8888 -Xms4g -Xmx4g -jar bug-0.0.1-SNAPSHOT.jar 这样我就可以通过 JMX 端口远程连接到这个应用观察内存、GC 情况了。 如果是方法执行完毕就回收 mem 对象，当我分配 250M 内存时；内存就会有一个明显的曲线，同时 GC 也会执行。 这时观察内存曲线。 会发现确实有明显的涨幅，但是之后并没有立即回收，而是一直保持在这个水位。同时左边的 GC 也没有任何的反应。 用 jstat 查看内存布局也是同样的情况。 不管是 YGC,FGC 都没有，只是 Eden 区的使用占比有所增加，毕竟分配了 250M 内存嘛。 那怎样才会回收呢？ 我再次分配了两个 250M 之后观察内存曲线。 发现第三个 250M 的时候 Eden 区达到了 98.83% 于是再次分配时就需要回收 Eden 区产生了 YGC。 同时内存曲线也得到了下降。 整个的换算过程如图： 由于初始化的堆内存为 4G，所以算出来的 Eden 区大概为 1092M 内存。 加上应用启动 Spring 之类消耗的大约 20% 内存，所以分配 3 次 250M 内存就会导致 YGC。 再来回顾下刚才的问题： mem 对象既然在方法执行完毕后不会回收，那什么时候回收呢。 其实只要记住一点即可：对象都需要垃圾回收器发生 GC 时才能回收；不管这个对象是局部变量还是全局变量。 通过刚才的实验也发现了，当 Eden 区空间不足产生 YGC 时才会回收掉我们创建的 mem 对象。 但这里其实还有一个隐藏条件：那就是这个对象是局部变量。如果该对象是全局变量那依然不能被回收。 也就是我们常说的对象不可达，这样不可达的对象在 GC 发生时就会被认为是需要回收的对象从而进行回收。 在多考虑下，为什么有些人会认为方法执行完毕后局部变量会被回收呢？ 我想这应当是记混了，其实方法执行完毕后回收的是栈帧。 它最直接的结果就是导致 mem 这个对象没有被引用了。但没有引用并不代表会被马上回收，也就是上面说到的需要产生 GC 才会回收。 所以使用的是上面提到的对象不可达所采用的可达性分析算法来表明哪些对象需要被回收。 当对象没有被引用后也就认为不可达了。 这里有一张动图比较清晰： 当方法执行完之后其中的 mem 对象就相当于图中的 Object 5，所以在 GC 时候就会回收掉。 优先在 Eden 区分配对象其实从上面的例子中可以看出对象是优先分配在新生代中 Eden 区的，但有个前提就是对象不能太大。 以前也写过相关的内容： 大对象直接进入老年代而大对象则是直接分配到老年代中（至于多大算大，可以通过参数配置）。 当我直接分配 1000M 内存时，由于 Eden 区不能直接装下，所以改为分配在老年代中。 可以看到 Eden 区几乎没有变动，但是老年代却涨了 37% ，根据之前计算的老年代内存 2730M 算出来也差不多是 1000M 的内存。 Linux 内存查看回到这次我需要完成的需求：增加服务器内存和 CPU 的消耗。 CPU 还好，本身就有一定的使用，同时每创建一个对象也会消耗一些 CPU。 主要是内存,先来看下没启动这个应用之前的内存情况。 大概只使用了 3G 的内存。 启动应用之后大概只消耗了 600M 左右的内存。 为了满足需求我需要分配一些内存，但这里有点需要讲究。 不能一直分配内存，这样会导致 CPU 负载太高了，同时内存也会由于 GC 回收导致占用也不是特别多。 所以我需要少量的分配，让大多数对象在新生代中，为了不被回收需要保持在百分之八九十。 同时也需要分配一些大对象到老年代中，也要保持老年代的使用在百分之八九十。 这样才能最大限度的利用这 4G 的堆内存。 于是我做了以下操作： 先分配一些小对象在新生代中（800M）保持新生代在90% 接着又分配了老年代内 *（100%-已使用的28%）；也就是 2730*60%=1638M 让老年代也在 90% 左右。 效果如上。 最主要的是一次 GC 都没有发生这样也就达到了我的目的。 最终内存消耗了 3.5G 左右。 总结虽说这次的需求是比较奇葩，但想要精确的控制 JVM 的内存分配还是没那么容易。 需要对它的内存布局，回收都要有一定的了解，写这个 Bug 的过程确实也加深了印象，如果对你有所帮助请不要吝啬你的点赞与分享。 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何判断一个元素在亿级数据中是否存在？]]></title>
    <url>%2F2018%2F11%2F26%2Fguava%2Fguava-bloom-filter%2F</url>
    <content type="text"><![CDATA[前言最近有朋友问我这么一个面试题目： 现在有一个非常庞大的数据，假设全是 int 类型。现在我给你一个数，你需要告诉我它是否存在其中(尽量高效)。 需求其实很清晰，只是要判断一个数据是否存在即可。 但这里有一个比较重要的前提：非常庞大的数据。 常规实现先不考虑这个条件，我们脑海中出现的第一种方案是什么？ 我想大多数想到的都是用 HashMap 来存放数据，因为它的写入查询的效率都比较高。 写入和判断元素是否存在都有对应的 API，所以实现起来也比较简单。 为此我写了一个单测，利用 HashSet 来存数据（底层也是 HashMap ）；同时为了后面的对比将堆内存写死： 1-Xms64m -Xmx64m -XX:+PrintHeapAtGC -XX:+HeapDumpOnOutOfMemoryError 为了方便调试加入了 GC 日志的打印，以及内存溢出后 Dump 内存。 123456789101112131415@Testpublic void hashMapTest()&#123; long star = System.currentTimeMillis(); Set&lt;Integer&gt; hashset = new HashSet&lt;&gt;(100) ; for (int i = 0; i &lt; 100; i++) &#123; hashset.add(i) ; &#125; Assert.assertTrue(hashset.contains(1)); Assert.assertTrue(hashset.contains(2)); Assert.assertTrue(hashset.contains(3)); long end = System.currentTimeMillis(); System.out.println("执行时间：" + (end - star));&#125; 当我只写入 100 条数据时自然是没有问题的。 还是在这个基础上，写入 1000W 数据试试： 执行后马上就内存溢出。 可见在内存有限的情况下我们不能使用这种方式。 实际情况也是如此；既然要判断一个数据是否存在于集合中，考虑的算法的效率以及准确性肯定是要把数据全部 load 到内存中的。 Bloom Filter基于上面分析的条件，要实现这个需求最需要解决的是如何将庞大的数据 load 到内存中。 而我们是否可以换种思路，因为只是需要判断数据是否存在，也不是需要把数据查询出来，所以完全没有必要将真正的数据存放进去。 伟大的科学家们已经帮我们想到了这样的需求。 Burton Howard Bloom 在 1970 年提出了一个叫做 Bloom Filter（中文翻译：布隆过滤）的算法。 它主要就是用于解决判断一个元素是否在一个集合中，但它的优势是只需要占用很小的内存空间以及有着高效的查询效率。 所以在这个场景下在合适不过了。 Bloom Filter 原理下面来分析下它的实现原理。 官方的说法是：它是一个保存了很长的二级制向量，同时结合 Hash 函数实现的。 听起来比较绕，但是通过一个图就比较容易理解了。 如图所示： 首先需要初始化一个二进制的数组，长度设为 L（图中为 8），同时初始值全为 0 。 当写入一个 A1=1000 的数据时，需要进行 H 次 hash 函数的运算（这里为 2 次）；与 HashMap 有点类似，通过算出的 HashCode 与 L 取模后定位到 0、2 处，将该处的值设为 1。 A2=2000 也是同理计算后将 4、7 位置设为 1。 当有一个 B1=1000 需要判断是否存在时，也是做两次 Hash 运算，定位到 0、2 处，此时他们的值都为 1 ，所以认为 B1=1000 存在于集合中。 当有一个 B2=3000 时，也是同理。第一次 Hash 定位到 index=4 时，数组中的值为 1，所以再进行第二次 Hash 运算，结果定位到 index=5 的值为 0，所以认为 B2=3000 不存在于集合中。 整个的写入、查询的流程就是这样，汇总起来就是： 对写入的数据做 H 次 hash 运算定位到数组中的位置，同时将数据改为 1 。当有数据查询时也是同样的方式定位到数组中。一旦其中的有一位为 0 则认为数据肯定不存在于集合，否则数据可能存在于集合中。 所以布隆过滤有以下几个特点： 只要返回数据不存在，则肯定不存在。 返回数据存在，但只能是大概率存在。 同时不能清除其中的数据。 第一点应该都能理解，重点解释下 2、3 点。 为什么返回存在的数据却是可能存在呢，这其实也和 HashMap 类似。 在有限的数组长度中存放大量的数据，即便是再完美的 Hash 算法也会有冲突，所以有可能两个完全不同的 A、B 两个数据最后定位到的位置是一模一样的。 这时拿 B 进行查询时那自然就是误报了。 删除数据也是同理，当我把 B 的数据删除时，其实也相当于是把 A 的数据删掉了，这样也会造成后续的误报。 基于以上的 Hash 冲突的前提，所以 Bloom Filter 有一定的误报率，这个误报率和 Hash 算法的次数 H，以及数组长度 L 都是有关的。 自己实现一个布隆过滤算法其实很简单不难理解，于是利用 Java 实现了一个简单的雏形。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class BloomFilters &#123; /** * 数组长度 */ private int arraySize; /** * 数组 */ private int[] array; public BloomFilters(int arraySize) &#123; this.arraySize = arraySize; array = new int[arraySize]; &#125; /** * 写入数据 * @param key */ public void add(String key) &#123; int first = hashcode_1(key); int second = hashcode_2(key); int third = hashcode_3(key); array[first % arraySize] = 1; array[second % arraySize] = 1; array[third % arraySize] = 1; &#125; /** * 判断数据是否存在 * @param key * @return */ public boolean check(String key) &#123; int first = hashcode_1(key); int second = hashcode_2(key); int third = hashcode_3(key); int firstIndex = array[first % arraySize]; if (firstIndex == 0) &#123; return false; &#125; int secondIndex = array[second % arraySize]; if (secondIndex == 0) &#123; return false; &#125; int thirdIndex = array[third % arraySize]; if (thirdIndex == 0) &#123; return false; &#125; return true; &#125; /** * hash 算法1 * @param key * @return */ private int hashcode_1(String key) &#123; int hash = 0; int i; for (i = 0; i &lt; key.length(); ++i) &#123; hash = 33 * hash + key.charAt(i); &#125; return Math.abs(hash); &#125; /** * hash 算法2 * @param data * @return */ private int hashcode_2(String data) &#123; final int p = 16777619; int hash = (int) 2166136261L; for (int i = 0; i &lt; data.length(); i++) &#123; hash = (hash ^ data.charAt(i)) * p; &#125; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; return Math.abs(hash); &#125; /** * hash 算法3 * @param key * @return */ private int hashcode_3(String key) &#123; int hash, i; for (hash = 0, i = 0; i &lt; key.length(); ++i) &#123; hash += key.charAt(i); hash += (hash &lt;&lt; 10); hash ^= (hash &gt;&gt; 6); &#125; hash += (hash &lt;&lt; 3); hash ^= (hash &gt;&gt; 11); hash += (hash &lt;&lt; 15); return Math.abs(hash); &#125;&#125; 首先初始化了一个 int 数组。 写入数据的时候进行三次 hash 运算，同时把对应的位置置为 1。 查询时同样的三次 hash 运算，取到对应的值，一旦值为 0 ，则认为数据不存在。 实现逻辑其实就和上文描述的一样。 下面来测试一下，同样的参数： 1-Xms64m -Xmx64m -XX:+PrintHeapAtGC 123456789101112131415@Testpublic void bloomFilterTest()&#123; long star = System.currentTimeMillis(); BloomFilters bloomFilters = new BloomFilters(10000000) ; for (int i = 0; i &lt; 10000000; i++) &#123; bloomFilters.add(i + "") ; &#125; Assert.assertTrue(bloomFilters.check(1+"")); Assert.assertTrue(bloomFilters.check(2+"")); Assert.assertTrue(bloomFilters.check(3+"")); Assert.assertTrue(bloomFilters.check(999999+"")); Assert.assertFalse(bloomFilters.check(400230340+"")); long end = System.currentTimeMillis(); System.out.println("执行时间：" + (end - star));&#125; 执行结果如下： 只花了 3 秒钟就写入了 1000W 的数据同时做出来准确的判断。 当让我把数组长度缩小到了 100W 时就出现了一个误报，400230340 这个数明明没在集合里，却返回了存在。 这也体现了 Bloom Filter 的误报率。 我们提高数组长度以及 hash 计算次数可以降低误报率，但相应的 CPU、内存的消耗就会提高；这就需要根据业务需要自行权衡。 Guava 实现 刚才的方式虽然实现了功能，也满足了大量数据。但其实观察 GC 日志非常频繁，同时老年代也使用了 90%，接近崩溃的边缘。 总的来说就是内存利用率做的不好。 其实 Google Guava 库中也实现了该算法，下面来看看业界权威的实现。 1-Xms64m -Xmx64m -XX:+PrintHeapAtGC 12345678910111213141516171819@Testpublic void guavaTest() &#123; long star = System.currentTimeMillis(); BloomFilter&lt;Integer&gt; filter = BloomFilter.create( Funnels.integerFunnel(), 10000000, 0.01); for (int i = 0; i &lt; 10000000; i++) &#123; filter.put(i); &#125; Assert.assertTrue(filter.mightContain(1)); Assert.assertTrue(filter.mightContain(2)); Assert.assertTrue(filter.mightContain(3)); Assert.assertFalse(filter.mightContain(10000000)); long end = System.currentTimeMillis(); System.out.println("执行时间：" + (end - star));&#125; 也是同样写入了 1000W 的数据，执行没有问题。 观察 GC 日志会发现没有一次 fullGC，同时老年代的使用率很低。和刚才的一对比这里明显的要好上很多，也可以写入更多的数据。 源码分析那就来看看 Guava 它是如何实现的。 构造方法中有两个比较重要的参数，一个是预计存放多少数据，一个是可以接受的误报率。我这里的测试 demo 分别是 1000W 以及 0.01。 Guava 会通过你预计的数量以及误报率帮你计算出你应当会使用的数组大小 numBits 以及需要计算几次 Hash 函数 numHashFunctions 。 这个算法计算规则可以参考维基百科。 put 写入函数真正存放数据的 put 函数如下： 根据 murmur3_128 方法的到一个 128 位长度的 byte[]。 分别取高低 8 位的到两个 hash 值。 再根据初始化时的到的执行 hash 的次数进行 hash 运算。 1bitsChanged |= bits.set((combinedHash &amp; Long.MAX_VALUE) % bitSize); 其实也是 hash取模拿到 index 后去赋值 1. 重点是 bits.set() 方法。 其实 set 方法是 BitArray 中的一个函数，BitArray 就是真正存放数据的底层数据结构。 利用了一个 long[] data 来存放数据。 所以 set() 时候也是对这个 data 做处理。 在 set 之前先通过 get() 判断这个数据是否存在于集合中，如果已经存在则直接返回告知客户端写入失败。 接下来就是通过位运算进行位或赋值。 get() 方法的计算逻辑和 set 类似，只要判断为 0 就直接返回存在该值。 mightContain 是否存在函数 前面几步的逻辑都是类似的，只是调用了刚才的 get() 方法判断元素是否存在而已。 总结布隆过滤的应用还是蛮多的，比如数据库、爬虫、防缓存击穿等。 特别是需要精确知道某个数据不存在时做点什么事情就非常适合布隆过滤。 这段时间的研究发现算法也挺有意思的，后续应该会继续分享一些类似的内容。 如果对你有帮助那就分享一下吧。 本问的示例代码参考这里： https://github.com/crossoverJie/JCSprout 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Bloom Filter</tag>
        <tag>算法</tag>
        <tag>Hash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享一些 Kafka 消费数据的小经验]]></title>
    <url>%2F2018%2F11%2F20%2Fkafka%2Fkafka-consumer%2F</url>
    <content type="text"><![CDATA[前言之前写过一篇《从源码分析如何优雅的使用 Kafka 生产者》 ，有生产者自然也就有消费者。 建议对 Kakfa 还比较陌生的朋友可以先看看。 就我的使用经验来说，大部分情况都是处于数据下游的消费者角色。也用 Kafka 消费过日均过亿的消息（不得不佩服 Kakfa 的设计），本文将借助我使用 Kakfa 消费数据的经验来聊聊如何高效的消费数据。 单线程消费以之前生产者中的代码为例，事先准备好了一个 Topic:data-push，3个分区。 先往里边发送 100 条消息，没有自定义路由策略，所以消息会均匀的发往三个分区。 先来谈谈最简单的单线程消费，如下图所示： 由于数据散列在三个不同分区，所以单个线程需要遍历三个分区将数据拉取下来。 单线程消费的示例代码： 这段代码大家在官网也可以找到：将数据取出放到一个内存缓冲中最后写入数据库的过程。 先不讨论其中的 offset 的提交方式。 通过消费日志可以看出： 取出的 100 条数据确实是分别遍历了三个分区。 单线程消费虽然简单，但存在以下几个问题： 效率低下。如果分区数几十上百个，单线程无法高效的取出数据。 可用性很低。一旦消费线程阻塞，甚至是进程挂掉，那么整个消费程序都将出现问题。 多线程消费既然单线程有诸多问题，那是否可以用多线程来提高效率呢？ 在多线程之前不得不将消费模式分为两种进行探讨：消费组、独立消费者。 这两种消费模式对应的处理方式有着很大的不同，所以很有必要单独来讲。 独立消费者模式先从独立消费者模式谈起，这种模式相对于消费组来说用的相对小众一些。 看一个简单示例即可知道它的用法： 值得注意的是：独立消费者可以不设置 group.id 属性。 也是发送100条消息，消费结果如下： 通过 API 可以看出：我们可以手动指定需要消费哪些分区。 比如 data-push Topic 有三个分区，我可以手动只消费其中的 1 2 分区，第三个可以视情况来消费。 同时它也支持多线程的方式，每个线程消费指定分区进行消费。 为了直观，只发送了 10 条数据。 根据消费结果可以看出： c1 线程只取 0 分区；c2 只取 1 分区；c3 只取 2 分区的数据。 甚至我们可以将消费者多进程部署，这样的消费方式如下： 假设 Topic:data-push 的分区数为 4 个，那我们就可以按照图中的方式创建两个进程。 每个进程内有两个线程，每个线程再去消费对应的分区。 这样当我们性能不够新增 Topic 的分区数时，消费者这边只需要这样水平扩展即可，非常的灵活。 这种自定义分区消费的方式在某些场景下还是适用的，比如生产者每次都将某一类的数据只发往一个分区。这样我们就可以只针对这一个分区消费。 但这种方式有一个问题：可用性不高，当其中一个进程挂掉之后；该进程负责的分区数据没法转移给其他进程处理。 消费组模式消费组模式应当是使用最多的一种消费方式。 我们可以创建 N 个消费者实例（new KafkaConsumer()）,当这些实例都用同一个 group.id 来创建时，他们就属于同一个消费组。 在同一个消费组中的消费实例可以收到消息，但一个分区的消息只会发往一个消费实例。 还是借助官方的示例图来更好的理解它。 某个 Topic 有四个分区 p0 p1 p2 p3，同时创建了两个消费组 groupA，groupB。 A 消费组中有两个消费实例 C1、C2。 B 消费组中有四个消费实例 C3、C4、C5、C6。 这样消息是如何划分到每个消费实例的呢？ 通过图中可以得知： A 组中的 C1 消费了 P0 和 P3 分区；C2 消费 P1、P2 分区。 B 组有四个实例，所以每个实例消费一个分区；也就是消费实例和分区是一一对应的。 需要注意的是： 这里的消费实例简单的可以理解为 new KafkaConsumer，它和进程没有关系。 比如说某个 Topic 有三个分区，但是我启动了两个进程来消费它。 其中每个进程有两个消费实例，那其实就相当于有四个实例了。 这时可能就会问 4 个实例怎么消费 3 个分区呢？ 消费组自平衡这个 Kafka 已经帮我做好了，它会来做消费组里的 Rebalance。 比如上面的情况，3 个分区却有 4 个消费实例；最终肯定只有三个实例能取到消息。但至于是哪三个呢，这点 Kakfa 会自动帮我们分配好。 看个例子，还在之前的 data-push 这个 Topic，其中有三个分区。 当其中一个进程（其中有三个线程，每个线程对应一个消费实例）时，消费结果如下： 里边的 20 条数据都被这个进程的三个实例消费掉。 这时我新启动了一个进程，程序和上面那个一模一样；这样就相当于有两个进程，同时就是 6 个实例。 我再发送 10 条消息会发现： 进程1 只取到了分区 1 里的两条数据（之前是所有数据都是进程1里的线程获取的）。 同时进程2则消费了剩下的 8 条消息，分别是分区 0、2 的数据（总的还是只有三个实例取到了数据，只是分别在不同的进程里）。 当我关掉进程2，再发送10条数据时会发现所有数据又被进程1里的三个线程消费了。 通过这些测试相信大家已经可以看到消费组的优势了。 我们可以在一个消费组中创建多个消费实例来达到高可用、高容错的特性，不会出现单线程以及独立消费者挂掉之后数据不能消费的情况。同时基于多线程的方式也极大的提高了消费效率。 而当新增消费实例或者是消费实例挂掉时 Kakfa 会为我们重新分配消费实例与分区的关系就被称为消费组 Rebalance。 发生这个的前提条件一般有以下几个： 消费组中新增消费实例。 消费组中消费实例 down 掉。 订阅的 Topic 分区数发生变化。 如果是正则订阅 Topic 时，匹配的 Topic 数发生变化也会导致 Rebalance。 所以推荐使用这样的方式消费数据，同时扩展性也非常好。当性能不足新增分区时只需要启动新的消费实例加入到消费组中即可。 总结本次只分享了几个不同消费数据的方式，并没有着重研究消费参数、源码；这些内容感兴趣的话可以在下次分享。 文中提到的部分源码可以在这里查阅： https://github.com/crossoverJie/JCSprout 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>Kafka</category>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计一个可拔插的 IOC 容器]]></title>
    <url>%2F2018%2F11%2F15%2Fwheel%2Fcicada6%2F</url>
    <content type="text"><![CDATA[前言磨了许久，借助最近的一次通宵上线 cicada 终于更新了 v2.0.0 版本。 之所以大的版本号变为 2，确实是向下不兼容了；主要表现为： 修复了几个反馈的 bug。 灵活的路由方式。 可拔插的 IOC 容器选择。 其中重点是后面两个。 新的路由方式先来看第一个：路由方式的更新。 在之前的版本想要写一个接口必须的实现一个 WorkAction；而且最麻烦的是一个实现类只能做一个接口。 因此也有朋友给我提过这个 issue。 于是改进后的使用方式如下： 是否有点似曾相识的感觉😊。 如上图所示，不需要实现某个特定的接口；只需要使用不同的注解即可。 同时也支持自定义 pojo, cicada 会在调用过程中对参数进行实例化。 拿这个 getUser 接口为例，当这样请求时这些参数就会被封装进 DemoReq 中. http://127.0.0.1:5688/cicada-example/routeAction/getUser?id=1234&amp;name=zhangsan 同时得到响应： 1&#123;"message":"hello =zhangsan"&#125; 实现过程也挺简单，大家查看源码便会发现；这里贴一点比较核心的步骤。 扫描所有使用 @CicadaAction 注解的类。 扫描所有使用 @CicadaRoute 注解的方法。 将他们的映射关系存入 Map 中。 请求时根据 URL 去 Map 中查找这个关系。 反射构建参数及方法调用。 扫描类以及写入映射关系 请求时查询映射关系 反射调用这些方法 是否需要 IOC 容器上面那几个步骤其实我都是一把梭写完的，但当我写到执行具体方法时感觉有点意思了。 大家都知道反射调用方法有两个重要的参数： obj 方法执行的实例。 args.. 自然是方法的参数。 我第一次写的时候是这样的： 1method.invoke(method.getDeclaringClass().newInstance(), object); 然后一测试，也没问题。 当我写完之后 review 代码时发现不对：这样这里每次都会创建一个新的实例，而且反射调用 newInstance() 效率也不高。 这时我不自觉的想到了 Spring 中 IOC 容器，和这里场景也非常的类似。 在应用初始化时将所有的接口实例化并保存到 bean 容器中，当需要使用时只需要从容器中获取即可。 这样只是会在启动时做很多加载工作，但造福后代啊。 可拔插的 IOC 容器于是我打算自己实现一个这样的 bean 容器。 但在实现之前又想到一个 feature: 不如把实现 bean 容器的方案交给使用者选择，可以选择使用 bean 容器，也可以就用之前的每次都创建新的实例，就像 Spring 中的 prototype 作用域一样。 甚至可以自定义容器实现，比如将 bean 存放到数据库、Redis 都行；当然一般人也不会这么干。 和 SPI 的机制也有点类似。 要实现上述的需求大致需要以下步骤： 一个通用的接口，包含了注册容器、从容器中获取实例等方法。 BeanManager 类，由它来管理具体使用哪种 IOC 容器。 所以首先定义了一个接口；CicadaBeanFactory: 包含了注册和获取实例的接口。 同时分别有两个不同的容器实现方案。 默认实现；CicadaDefaultBean： 也就是文中说道的，每次都会创建实例；由于这种方式其实根本就没有 bean 容器，所以也不存在注册了。 接下来是真正的 IOC 容器；CicadaIoc： 它将所有的实例都存放在一个 Map 中。 当然也少不了刚才提到的 CicadaBeanManager，它会在应用启动的时候将所有的实例注册到 bean 容器中。 重点是图中标红的部分： 需要根据用户的选择实例化 CicadaBeanFactory 接口。 将所有的实例注册到 CicadaBeanFactory 接口中。 同时也提供了一个获取实例的方法： 就是直接调用 CicadaBeanFactory 接口的方法。 然后在上文提到的反射调用方法处就变为： 从 bean 容器中获取实例了；获取的过程可以是每次都创建一个新的对象，也可以是直接从容器中获取实例。这点对于这里的调用者来说并不关心。 所以这也实现了标题所说的：可拔插。 为了实现这个目的，我将 CicadaIoc 的实现单独放到一个模块中，以 jar 包的形式提供实现。 所以如果你想要使用 IOC 容器的方式获取实例时只需要在你的应用中额外加入这个 jar 包即可。 12345&lt;dependency&gt; &lt;groupId&gt;top.crossoverjie.opensource&lt;/groupId&gt; &lt;artifactId&gt;cicada-ioc&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; 如果不使用则是默认的 CicadaDefaultBean 实现，也就是每次都会创建对象。 这样有个好处： 当你自己想实现一个 IOC 容器时；只需要实现 cicada 提供的 CicadaBeanFactory 接口，并在你的应用中只加入你的 jar 包即可。 其余所有的代码都不需要改变，便可随意切换不的容器。 当然我是推荐大家使用 IOC 容器的（其实就是单例），牺牲一点应用启动时间带来后续性能的提升是值得的。 总结cicada 的大坑填的差不多了，后续也会做一些小功能的迭代。 还没有关注的朋友赶紧关注一波： https://github.com/TogetherOS/cicada PS：虽然没有仔细分析 Spring IOC 的实现，但相信看完此篇的朋友应该对 Spring IOC 以及 SpringMVC 会有一些自己的理解。 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>cicada</category>
        <category>轮子</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>HTTP</tag>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不改一行代码定位线上性能问题]]></title>
    <url>%2F2018%2F11%2F12%2Fjava-senior%2Fcoding-online-analysis%2F</url>
    <content type="text"><![CDATA[背景最近时运不佳，几乎天天被线上问题骚扰。前几天刚解决了一个 HashSet 的并发问题，周六又来了一个性能问题。 大致的现象是： 我们提供出去的一个 OpenAPI 反应时快时慢，快的时候几十毫秒，慢的时候几秒钟才响应。 尝试解决由于这种也不是业务问题，不能直接定位。所以尝试在测试环境复现，但遗憾的测试环境贼快。 没办法只能硬着头皮上了。 中途有抱着侥幸心里让运维查看了 Nginx 里 OpenAPI 的响应时间，想把锅扔给网络。结果果然打脸了；Nginx 里的日志也表明确实响应时间确实有问题。 为了清晰的了解这个问题，我简单梳理了这个调用过程。 整个的流程算是比较常见的分层架构： 客户端请求到 Nginx。 Nginx 负载了后端的 web 服务。 web 服务通过 RPC 调用后端的 Service 服务。 日志大法我们首先想到的是打日志，在可能会慢的方法或接口处记录处理时间来判断哪里有问题。 但通过刚才的调用链来说，这个请求流程不短。加日志涉及的改动较多而且万一加漏了还有可能定位不到问题。 再一个是改动代码之后还会涉及到发版上线。 工具分析所以最好的方式就是不改动一行代码把这个问题分析出来。 这时就需要一个 agent 工具了。我们选用了阿里以前开源的 Tprofile 来使用。 只需要在启动参数中加入 -javaagent:/xx/tprofiler.jar 即可监控你想要监控的方法耗时，并且可以给你输出报告，非常方便。对代码没有任何侵入性同时性能影响也较小。 工具使用下面来简单展示下如何使用这个工具。 首先第一步自然是 clone 源码然后打包，可以克隆我修改过的源码。 因为这个项目阿里多年没有维护了，还残留一些 bug,我在它原有的基础上修复了个影响使用的 bug，同时做了一些优化。 执行以下脚本即可。123git clone https://github.com/crossoverJie/TProfilermvn assembly:assembly 到这里之后会在项目的 TProfiler/pkg/TProfiler/lib/tprofiler-1.0.1.jar 中生成好我们要使用的 jar 包。 接下来只需要将这个 jar 包配置到启动参数中，同时再配置一个配置文件路径即可。 这个配置文件我 copy 官方的解释。 1234567891011121314151617181920212223242526272829303132333435363738394041#log file namelogFileName = tprofiler.logmethodFileName = tmethod.logsamplerFileName = tsampler.log#basic configuration items# 开始取样时间startProfTime = 1:00:00# 结束取样时间endProfTime = 23:00:00# 取样的时间长度eachProfUseTime = 10# 每次取样的时间间隔eachProfIntervalTime = 1samplerIntervalTime = 20# 端口，主要不要冲突了port = 50000debugMode = falseneedNanoTime = false# 是否忽略 get set 方法ignoreGetSetMethod = true#file paths 日志路径logFilePath = /data/work/logs/tprofile/$&#123;logFileName&#125;methodFilePath =/data/work/logs/tprofile/$&#123;methodFileName&#125;samplerFilePath =/data/work/logs/tprofile/$&#123;samplerFileName&#125;#include &amp; excludes itemsexcludeClassLoader = org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader# 需要监控的包includePackageStartsWith = top.crossoverjie.cicada.example.action# 不需要监控的包excludePackageStartsWith = com.taobao.sketch;org.apache.velocity;com.alibaba;com.taobao.forest.domain.dataobject 最终的启动参数如下： 12-javaagent:/TProfiler/lib/tprofiler-1.0.1.jar-Dprofile.properties=/TProfiler/profile.properties 为了模拟排查接口响应慢的问题，我用 cicada 实现了一个 HTTP 接口。其中调用了两个耗时方法： 这样当我启动应用时，Tprofile 就会在我配置的目录记录它所收集的方法信息。 我访问接口 http://127.0.0.1:5688/cicada-example/demoAction?name=test&amp;id=10 几次后它就会把每个方法的明细响应写入 tprofile.log。 由左到右每列分别代表为： 线程ID、方法栈深度、方法编号、耗时（毫秒）。 但 tmethod.log 还是空的； 这时我们只需要执行这个命令即可把最新的方法采样信息刷到 tmethod.log 文件中。 123java -cp /TProfiler/tprofiler.jar com.taobao.profile.client.TProfilerClient 127.0.0.1 50000 flushmethodflushmethod success 其实就是访问了 Tprofile 暴露出的一个服务，他会读取、解析 tprofile.log 同时写入 tmethod.log. 其中的端口就是配置文件中的 port。 再打开 tmethod.log ： 其中会记录方法的信息。 第一行数字为方法的编号。可以通过这个编号去 tprofile.log(明细)中查询每次的耗时情况。 行末的数字则是这个方法在源码中最后一行的行号。 其实大部分的性能分析都是统计某个方法的平均耗时。 所以还需要执行下面的命令，通过 tmethod.log tprofile.log来生成每个方法的平均耗时。 12java -cp /TProfiler/tprofiler.jar com.taobao.profile.analysis.ProfilerLogAnalysis tprofiler.log tmethod.log topmethod.log topobject.logprint result success 打开 topmethod.log 就是所有方法的平均耗时。 4 为请求次数。 205 为平均耗时。 818 则为总耗时。 和实际情况是相符的。 方法的明细耗时这是可能还会有其他需求；比如说我想查询某个方法所有的明细耗时怎么办呢？ 官方没有提供，但也是可以的，只是要麻烦一点。 比如我想查看 selectDB() 的耗时明细： 首先得知道这个方法的编号，在 tmethod.log 中可以看查到。 12 top/crossoverjie/cicada/example/action/DemoAction:selectDB:84 编号为 2. 之前我们就知道 tprofile.log 记录的是明细，所以通过下面的命令即可查看。 1grep 2 tprofiler.log 通过第三列方法编号为 2 的来查看每次执行的明细。 但这样的方式显然不够友好，需要人为来过滤干扰，步骤也多；所以我也准备加上这样一个功能。 只需要传入一个方法名称即可查询采集到的所有方法耗时明细。 总结回到之前的问题；线上通过这个工具分析我们得到了如下结果。 有些方法确实执行时快时慢，但都是和数据库相关的。由于目前数据库压力较大，准备在接下来进行冷热数据分离，以及分库分表。 在第一步操作还没实施之前将部分写数据库的操作改为异步，减小响应时间。 考虑接入 pinpoint 这样的 APM工具。 类似于 Tprofile 的工具确实挺多的，找到适合自己的就好。 在还没有使用类似于 pinpoint 这样的分布式跟踪工具之前应该会大量依赖于这个工具，所以后续说不定也会做一些定制，比如增加一些可视化界面等，可以提高排查效率。 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Tprofile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次 HashSet 所引起的并发问题]]></title>
    <url>%2F2018%2F11%2F08%2Fjava-senior%2FJVM-concurrent-HashSet-problem%2F</url>
    <content type="text"><![CDATA[背景上午刚到公司，准备开始一天的摸鱼之旅时突然收到了一封监控中心的邮件。 心中暗道不好，因为监控系统从来不会告诉我应用完美无 bug，其实系统挺猥琐。 打开邮件一看，果然告知我有一个应用的线程池队列达到阈值触发了报警。 由于这个应用出问题非常影响用户体验；于是立马让运维保留现场 dump 线程和内存同时重启应用，还好重启之后恢复正常。于是开始着手排查问题。 分析首先了解下这个应用大概是做什么的。 简单来说就是从 MQ 中取出数据然后丢到后面的业务线程池中做具体的业务处理。 而报警的队列正好就是这个线程池的队列。 跟踪代码发现构建线程池的方式如下： 1234ThreadPoolExecutor executor = new ThreadPoolExecutor(coreSize, maxSize, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());; put(poolName,executor); 采用的是默认的 LinkedBlockingQueue 并没有指定大小（这也是个坑），于是这个队列的默认大小为 Integer.MAX_VALUE。 由于应用已经重启，只能从仅存的线程快照和内存快照进行分析。 内存分析先利用 MAT 分析了内存，的到了如下报告。 其中有两个比较大的对象，一个就是之前线程池存放任务的 LinkedBlockingQueue，还有一个则是 HashSet。 当然其中队列占用了大量的内存，所以优先查看，HashSet 一会儿再看。 由于队列的大小给的够大，所以结合目前的情况来看应当是线程池里的任务处理较慢，导致队列的任务越堆越多，至少这是目前可以得出的结论。 线程分析再来看看线程的分析，这里利用 fastthread.io 这个网站进行线程分析。 因为从表现来看线程池里的任务迟迟没有执行完毕，所以主要看看它们在干嘛。 正好他们都处于 RUNNABLE 状态，同时堆栈如下： 发现正好就是在处理上文提到的 HashSet，看这个堆栈是在查询 key 是否存在。通过查看 312 行的业务代码确实也是如此。 这里的线程名字也是个坑，让我找了好久。 定位分析了内存和线程的堆栈之后其实已经大概猜出一些问题了。 这里其实有一个前提忘记讲到： 这个告警是凌晨三点发出的邮件，但并没有电话提醒之类的，所以大家都不知道。 到了早上上班时才发现并立即 dump 了上面的证据。 所有有一个很重要的事实：这几个业务线程在查询 HashSet 的时候运行了 6 7 个小时都没有返回。 通过之前的监控曲线图也可以看出： 操作系统在之前一直处于高负载中，直到我们早上看到报警重启之后才降低。 同时发现这个应用生产上运行的是 JDK1.7 ，所以我初步认为应该是在查询 key 的时候进入了 HashMap 的环形链表导致 CPU 高负载同时也进入了死循环。 为了验证这个问题再次 review 了代码。 整理之后的伪代码如下： 1234567891011121314151617181920212223242526272829303132333435363738//线程池private ExecutorService executor;private Set&lt;String&gt; set = new hashSet();private void execute()&#123; while(true)&#123; //从 MQ 中获取数据 String key = subMQ(); executor.excute(new Worker(key)) ; &#125;&#125;public class Worker extends Thread&#123; private String key ; public Worker(String key)&#123; this.key = key; &#125; @Override private void run()&#123; if(!set.contains(key))&#123; //数据库查询 if(queryDB(key))&#123; set.add(key); return; &#125; &#125; //达到某种条件时清空 set if(flag)&#123; set = null ; &#125; &#125; &#125; 大致的流程如下： 源源不断的从 MQ 中获取数据。 将数据丢到业务线程池中。 判断数据是否已经写入了 Set。 没有则查询数据库。 之后写入到 Set 中。 这里有一个很明显的问题，那就是作为共享资源的 Set 并没有做任何的同步处理。 这里会有多个线程并发的操作，由于 HashSet 其实本质上就是 HashMap，所以它肯定是线程不安全的，所以会出现两个问题： Set 中的数据在并发写入时被覆盖导致数据不准确。 会在扩容的时候形成环形链表。 第一个问题相对于第二个还能接受。 通过上文的内存分析我们已经知道这个 set 中的数据已经不少了。同时由于初始化时并没有指定大小，仅仅只是默认值，所以在大量的并发写入时候会导致频繁的扩容，而在 1.7 的条件下又可能会形成环形链表。 不巧的是代码中也有查询操作（contains()）,观察上文的堆栈情况： 发现是运行在 HashMap 的 465 行，来看看 1.7 中那里具体在做什么： 已经很明显了。这里在遍历链表，同时由于形成了环形链表导致这个 e.next 永远不为空，所以这个循环也不会退出了。 到这里其实已经找到问题了，但还有一个疑问是为什么线程池里的任务队列会越堆越多。我第一直觉是任务执行太慢导致的。 仔细查看了代码发现只有一个地方可能会慢：也就是有一个数据库的查询。 把这个 SQL 拿到生产环境执行发现确实不快，查看索引发现都有命中。 但我一看表中的数据发现已经快有 7000W 的数据了。同时经过运维得知 MySQL 那台服务器的 IO 压力也比较大。 所以这个原因也比较明显了： 由于每消费一条数据都要去查询一次数据库，MySQL 本身压力就比较大，加上数据量也很高所以导致这个 IO 响应较慢，导致整个任务处理的就比较慢了。 但还有一个原因也不能忽视；由于所有的业务线程在某个时间点都进入了死循环，根本没有执行完任务的机会，而后面的数据还在源源不断的进入，所以这个队列只会越堆越多！ 这其实是一个老应用了，可能会有人问为什么之前没出现问题。 这是因为之前数据量都比较少，即使是并发写入也没有出现并发扩容形成环形链表的情况。这段时间业务量的暴增正好把这个隐藏的雷给揪出来了。所以还是得信墨菲他老人家的话。 总结至此整个排查结束，而我们后续的调整措施大概如下： HashSet 不是线程安全的，换为 ConcurrentHashMap同时把 value 写死一样可以达到 set 的效果。 根据我们后面的监控，初始化 ConcurrentHashMap 的大小尽量大一些，避免频繁的扩容。 MySQL 中很多数据都已经不用了，进行冷热处理。尽量降低单表数据量。同时后期考虑分表。 查数据那里调整为查缓存，提高查询效率。 线程池的名称一定得取的有意义，不然是自己给自己增加难度。 根据监控将线程池的队列大小调整为一个具体值，并且要有拒绝策略。 升级到 JDK1.8。 再一个是报警邮件酌情考虑为电话通知😂。 HashMap 的死循环问题在网上层出不穷，没想到还真被我遇到了。现在要满足这个条件还是挺少见的，比如 1.8 以下的 JDK 这一条可能大多数人就碰不到，正好又证实了一次墨菲定律。 同时我会将文章更到这里，方便大家阅读和查询。 https://crossoverjie.top/JCSprout/ 你的点赞与分享是对我最大的支持]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>concurrent</tag>
        <tag>HashMap</tag>
        <tag>JVM</tag>
        <tag>HashSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.6W star 的 JCSprout 阅读体验大提升]]></title>
    <url>%2F2018%2F11%2F06%2Fpersonal%2F1W-star-update%2F</url>
    <content type="text"><![CDATA[万万没想到 JCSprout 截止目前居然有将近1.6W star。真的非常感谢各位大佬的支持。 年初时创建这个 repo 原本只是想根据自己面试与被面试的经历记录一些核心知识点，结果却是越写越多。 在我自己宣传和其他技术大佬(包括阮大)的助攻之下连续两个月都在 GitHub trending Java片区的榜首。 甚至有一次还一跃到整个 GitHub 的第一，同时还有帮助一些同学拿到了大厂 offer。 扯了这么多进入这次的正题。 之前有一朋友建议将文档以 gitbook 的形式查看，一直没有时间弄。直到有一天我看到了 docsify 这个项目，瞬间被它的外观，阅读方式所吸引。于是抽了一晚上把所有的文章全部迁移过去。 现在打开 https://crossoverjie.top/JCSprout/ 即可看到全新的主页，大概长这样： 确实不管从颜值还是阅读方式来说都非常不错；希望新的界面能让更多的人看的进去学到点东西。 同时也更新完善了其中的一些内容。比如有些写的早的内容其实并不完善，也优化的处理了。 同时欢迎更多朋友参与进来，不管是提新的点子、修改 bug 都是可以。 之前的文章也留了不少坑，包括 cicada 还有好几个 bug 待处理、推送的示例代码以及 Kafka 源码的后续更新。 突然有点像写长篇小说的感觉，还好没有多少人催更🤣。 不出意外本周会再更新一篇，请持续关注。 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>Person</category>
        <category>GitHub</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一份针对于新手的多线程实践--进阶篇]]></title>
    <url>%2F2018%2F10%2F31%2Fjava-senior%2Fconcurrent-in-action2%2F</url>
    <content type="text"><![CDATA[前言在上文《一份针对于新手的多线程实践》留下了一个问题： 这只是多线程其中的一个用法，相信看到这里的朋友应该多它的理解更进一步了。 再给大家留个阅后练习，场景也是类似的： 在 Redis 或者其他存储介质中存放有上千万的手机号码数据，每个号码都是唯一的，需要在最快的时间内把这些号码全部都遍历一遍。 有想法感兴趣的朋友欢迎在文末留言参与讨论🤔🤨。 网友们的方案 我在公众号以及其他一些平台收到了大家的回复，果然是众人拾柴火焰高啊。 感谢每一位参与的朋友。 其实看了大家的方案大多都想到了数据肯定要分段，因为大量的数据肯定没法一次性 load 到内存。 但怎么加载就要考虑清楚了，有些人说放在数据库中通过分页的方式进行加载，然后将每页的数据丢到一个线程里去做遍历。 其实想法挺不错的，但有个问题就是： 这样肯定会导致有一个主线程去遍历所有的号码，即便是分页查询的那也得全部查询一遍，效率还是很低。 即便是分页加载号码用多线程，那就会涉及到锁的问题，怎么保证每个线程读取的数据是互不冲突的。 但如果存储换成 Redis 的 String 结构这样就更行不通了。 遍历数据方案有没有一种利用多线程加载效率高，并且线程之间互相不需要竞争锁的方案呢？ 下面来看看这个方案： 首先在存储这千万号码的时候我们把它的号段单独提出来并冗余存储一次。 比如有个号码是 18523981123 那么就还需要存储一个号段：1852398。 这样当我们有以下这些号码时： 18523981123 18523981124 18523981125 13123874321 13123874322 13123874323 我们就还会维护一个号段数据为： 1852398 1312387 这样我想大家应该明白下一步应当怎么做了吧。 在需要遍历时： 通过主线程先把所有的号段加载到内存，即便是千万的号码号段也顶多几千条数据。 遍历这个号段，将每个号段提交到一个 task 线程中。 由这个线程通过号段再去查询真正的号码进行遍历。 最后所有的号段都提交完毕再等待所有的线程执行完毕即可遍历所有的号码。 这样做的根本原因其实是避免了线程之间加锁，通过号段可以让每个线程只取自己那一部分数据。 可能会有人说，如果号码持续增多导致号段的数据也达到了上万甚至几十万这怎么办呢？ 那其实也是同样的思路，可以再把号段进行拆分。 比如之前是 1852398 的号段，那我继续拆分为 1852 。 这样只需要在之前的基础上再启动一个线程去查询子号段即可，有点 fork/join 的味道。 这样的思路其实也和 JDK1.7 中的 ConcurrentHashMap 类似，定位一个真正的数据需要两次定位。 分布式方案上面的方案也是由局限性的，毕竟说到底还是一个单机应用。没法扩展；处理的数据始终是有上限。 这个上限就和服务器的配置以及线程数这些相关，说的高大上一点其实就是垂直扩展增加单机的处理性能。 因此随着数据量的提升我们肯定得需要通过水平扩展的方式才能达到最好的性能，这就是分布式的方案。 假设我现在有上亿的数据需要遍历，但我当前的服务器配置只能支撑一个应用启动 N 个线程 5 分钟跑5000W 的数据。 于是我水平扩展，在三台服务器上启动了三个独立的进程。假设一个应用能跑 5000W ，那么理论上来说三个应用就可以跑1.5亿的数据了。 但这个的前提还是和上文一样：每个应用只能处理自己的数据，不能出现加锁的情况（这样会大大的降低性能）。 所以我们得对刚才的号段进行分组。 先通过一张图来直观的表示这个逻辑： 假设现在我有 9 个号段，那么我就得按照图中的方式把数据隔离开来。 第一个数据给应用0，第二个数据给应用1，第三个数据给应用2。后面的数据以此类推（就是一个简单的取模运算）。 这样就可以将号段均匀的分配给不同的应用来进行处理，然后每个应用再按照上文提到的将分配给自己的号段丢到线程池中由具体的线程去查询、遍历即可。 分布式带来的问题这样看似没啥问题，但一旦引入了分布式之后就不可避免的会出现 CAP 的取舍，这里不做过多讨论，感兴趣的朋友可以自行搜索。 首先要解决的一个问题就是： 这三个应用怎么知道它自己应该取哪些号段的数据呢？比如 0 号应用就取 0 3 6（这个相当于号段的下标），难道在配置文件里配置嘛？ 那如果数据量又增大了，对应的机器数也增加到了 5 台，那自然 0 号应用就不是取 0 3 6 了（取模之后数据会变）。 所以我们得需要一个统一的调度来分配各个应用他们应当取哪些号段，这也就是数据分片。 假设我这里有一个统一的分配中心，他知道现在有多少个应用来处理数据。还是假设上文的三个应用吧。 在真正开始遍历数据的时候，这个分配中心就会去告诉这三个应用： 你们要开始工作了啊，0 号应用你的工作内容是 0 3 6，1 号应用你的工作内容是 1 4 7，2 号应用你的工作内容是 2 5 8。 这样各个应用就知道他们所应当处理的数据了。 当我们新增了一个应用来处理数据时也很简单，同样这个分配中心知道现在有多少台应用会工作。 他会再拿着现有的号段对 4(3+1台应用) 进行取模然后对数据进行重新分配，这样就可以再次保证数据分配均匀了。 只是分配中心如何知道有多少应用呢，其实也简单，只要中心和应用之间通信就可以了。比如启动的时候调用分配中心的接口即可。 上面提到的这个分配中心其实就是一个常见的定时任务的分布式调度中心，由它来统一发起调度，当然分片只是它其中的一个功能而已（关于调度中心之后有兴趣再细说）。 总结本次探讨了多线程的更多应用方式，如要是如何高效的运行。最主要的一点其实就是尽量的避免加锁。 同时对分布式水平扩展谈了一些处理建议，本次也是难得的一行代码都没贴，大家感兴趣的话在后面更新相关代码。 也欢迎大家留言讨论。😄 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>ThreadPool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一份针对于新手的多线程实践]]></title>
    <url>%2F2018%2F10%2F29%2Fjava-senior%2Fconcurrent-in-action%2F</url>
    <content type="text"><![CDATA[前言 前段时间在某个第三方平台看到我写作字数居然突破了 10W 字，难以想象高中 800 字作文我都得巧妙的利用换行来完成(懂的人肯定也干过😏)。 干了这行养成了一个习惯：能撸码验证的事情都自己验证一遍。 于是在上周五通宵加班的空余时间写了一个工具： https://github.com/crossoverJie/NOWS 利用 SpringBoot 只需要一行命令即可统计自己写了多少个字。 1java -jar nows-0.0.1-SNAPSHOT.jar /xx/Hexo/source/_posts 传入需要扫描的文章目录即可输出结果（目前只支持 .md 结尾 Markdown 文件） 当然结果看个乐就行（40 几万字），因为早期的博客我喜欢大篇的贴代码，还有一些英文单词也没有过滤，所以导致结果相差较大。 如果仅仅只是中文文字统计肯定是准的，并且该工具内置灵活的扩展方式，使用者可以自定义统计策略，具体请看后文。 其实这个工具挺简单的，代码量也少，没有多少可以值得拿出来讲的。但经过我回忆不管是面试还是和网友们交流都发现一个普遍的现象： 大部分新手开发都会去看多线程、但几乎都没有相关的实践。甚至有些都不知道多线程拿来在实际开发中有什么用。 为此我想基于这个简单的工具为这类朋友带来一个可实践、易理解的多线程案例。 至少可以让你知道： 为什么需要多线程？ 怎么实现一个多线程程序？ 多线程带来的问题及解决方案？ 单线程统计再谈多线程之前先来聊聊单线程如何实现。 本次的需求也很简单，只是需要扫描一个目录读取下面的所有文件即可。 所有我们的实现有以下几步： 读取某个目录下的所有文件。 将所有文件的路径保持到内存。 遍历所有的文件挨个读取文本记录字数即可。 先来看前两个如何实现，并且当扫描到目录时需要继续读取当前目录下的文件。 这样的场景就非常适合递归： 1234567891011121314151617181920 public List&lt;String&gt; getAllFile(String path)&#123; File f = new File(path) ; File[] files = f.listFiles(); for (File file : files) &#123; if (file.isDirectory())&#123; String directoryPath = file.getPath(); getAllFile(directoryPath); &#125;else &#123; String filePath = file.getPath(); if (!filePath.endsWith(".md"))&#123; continue; &#125; allFile.add(filePath) ; &#125; &#125; return allFile ; &#125;&#125; 读取之后将文件的路径保持到一个集合中。 需要注意的是这个递归次数需要控制下，避免出现栈溢出(StackOverflow)。 最后读取文件内容则是使用 Java8 中的流来进行读取，这样代码可以更简洁： 12Stream&lt;String&gt; stringStream = Files.lines(Paths.get(path), StandardCharsets.UTF_8);List&lt;String&gt; collect = stringStream.collect(Collectors.toList()); 接下来便是读取字数，同时要过滤一些特殊文本（比如我想过滤掉所有的空格、换行、超链接等）。 扩展能力简单处理可在上面的代码中遍历 collect 然后把其中需要过滤的内容替换为空就行。 但每个人的想法可能都不一样。比如我只想过滤掉空格、换行、超链接就行了，但有些人需要去掉其中所有的英文单词，甚至换行还得留着（就像写作文一样可以充字数）。 所有这就需要一个比较灵活的处理方式。 看过上文《利用责任链模式设计一个拦截器》应该很容易想到这样的场景责任链模式再合适不过了。 关于责任链模式具体的内容就不在详述了，感兴趣的可以查看上文。 这里直接看实现吧： 定义责任链的抽象接口及处理方法： 12345678public interface FilterProcess &#123; /** * 处理文本 * @param msg * @return */ String process(String msg) ;&#125; 处理空格和换行的实现： 1234567public class WrapFilterProcess implements FilterProcess&#123; @Override public String process(String msg) &#123; msg = msg.replaceAll("\\s*", ""); return msg ; &#125;&#125; 处理超链接的实现： 1234567public class HttpFilterProcess implements FilterProcess&#123; @Override public String process(String msg) &#123; msg = msg.replaceAll("^((https|http|ftp|rtsp|mms)?:\\/\\/)[^\\s]+",""); return msg ; &#125;&#125; 这样在初始化时需要将这些处理 handle 都加入责任链中，同时提供一个 API 供客户端执行即可。 这样一个简单的统计字数的工具就完成了。 多线程模式在我本地一共就几十篇博客的条件下执行一次还是很快的，但如果我们的文件是几万、几十万甚至上百万呢。 虽然功能可以实现，但可以想象这样的耗时绝对是成倍的增加。 这时多线程就发挥优势了，由多个线程分别去读取文件最后汇总结果即可。 这样实现的过程就变为： 读取某个目录下的所有文件。 将文件路径交由不同的线程自行处理。 最终汇总结果。 多线程带来的问题也不是使用多线程就万事大吉了，先来看看第一个问题：共享资源。 简单来说就是怎么保证多线程和单线程统计的总字数是一致的。 基于我本地的环境先看看单线程运行的结果： 总计为：414142 字。 接下来换为多线程的方式： 12345678910111213141516171819202122232425262728293031323334List&lt;String&gt; allFile = scannerFile.getAllFile(strings[0]);logger.info("allFile size=[&#123;&#125;]",allFile.size());for (String msg : allFile) &#123; executorService.execute(new ScanNumTask(msg,filterProcessManager));&#125;public class ScanNumTask implements Runnable &#123; private static Logger logger = LoggerFactory.getLogger(ScanNumTask.class); private String path; private FilterProcessManager filterProcessManager; public ScanNumTask(String path, FilterProcessManager filterProcessManager) &#123; this.path = path; this.filterProcessManager = filterProcessManager; &#125; @Override public void run() &#123; Stream&lt;String&gt; stringStream = null; try &#123; stringStream = Files.lines(Paths.get(path), StandardCharsets.UTF_8); &#125; catch (Exception e) &#123; logger.error("IOException", e); &#125; List&lt;String&gt; collect = stringStream.collect(Collectors.toList()); for (String msg : collect) &#123; filterProcessManager.process(msg); &#125; &#125;&#125; 使用线程池管理线程，更多线程池相关的内容请看这里：《如何优雅的使用和理解线程池》 执行结果： 我们会发现无论执行多少次，这个值都会小于我们的预期值。 来看看统计那里是怎么实现的。 123456789101112@Componentpublic class TotalWords &#123; private long sum = 0 ; public void sum(int count)&#123; sum += count; &#125; public long total()&#123; return sum; &#125;&#125; 可以看到就是对一个基本类型进行累加而已。那导致这个值比预期小的原因是什么呢？ 我想大部分人都会说：多线程运行时会导致有些线程把其他线程运算的值覆盖。 但其实这只是导致这个问题的表象，根本原因还是没有讲清楚。 内存可见性核心原因其实是由 Java 内存模型（JMM）的规定导致的。 这里引用一段之前写的《你应该知道的 volatile 关键字》一段解释： 由于 Java 内存模型(JMM)规定，所有的变量都存放在主内存中，而每个线程都有着自己的工作内存(高速缓存)。 线程在工作时，需要将主内存中的数据拷贝到工作内存中。这样对数据的任何操作都是基于工作内存(效率提高)，并且不能直接操作主内存以及其他线程工作内存中的数据，之后再将更新之后的数据刷新到主内存中。 这里所提到的主内存可以简单认为是堆内存，而工作内存则可以认为是栈内存。 如下图所示： 所以在并发运行时可能会出现线程 B 所读取到的数据是线程 A 更新之前的数据。 更多相关内容就不再展开了，感兴趣的朋友可以翻翻以前的博文。 直接来说如何解决这个问题吧，JDK 其实已经帮我们想到了这些问题。 在 java.util.concurrent 并发包下有许多你可能会使用到的并发工具。 这里就非常适合 AtomicLong，它可以原子性的对数据进行修改。 来看看修改后的实现： 123456789101112@Componentpublic class TotalWords &#123; private AtomicLong sum = new AtomicLong() ; public void sum(int count)&#123; sum.addAndGet(count) ; &#125; public long total()&#123; return sum.get() ; &#125;&#125; 只是使用了它的两个 API 而已。再来运行下程序会发现结果居然还是不对。 甚至为 0 了。 线程间通信这时又出现了一个新的问题，来看看获取总计数据是怎么实现的。 12345678910List&lt;String&gt; allFile = scannerFile.getAllFile(strings[0]);logger.info("allFile size=[&#123;&#125;]",allFile.size());for (String msg : allFile) &#123; executorService.execute(new ScanNumTask(msg,filterProcessManager));&#125;executorService.shutdown();long total = totalWords.total();long end = System.currentTimeMillis();logger.info("total sum=[&#123;&#125;],[&#123;&#125;] ms",total,end-start); 不知道大家看出问题没有，其实是在最后打印总数时并不知道其他线程是否已经执行完毕了。 因为 executorService.execute() 会直接返回，所以当打印获取数据时还没有一个线程执行完毕，也就导致了这样的结果。 关于线程间通信之前我也写过相关的内容：《深入理解线程通信》 大概的方式有以下几种： 这里我们使用线程池的方式： 在停用线程池后加上一个判断条件即可： 1234567executorService.shutdown();while (!executorService.awaitTermination(100, TimeUnit.MILLISECONDS)) &#123; logger.info("worker running");&#125;long total = totalWords.total();long end = System.currentTimeMillis();logger.info("total sum=[&#123;&#125;],[&#123;&#125;] ms",total,end-start); 这样我们再次尝试，发现无论多少次结果都是正确的了： 效率提升可能还会有朋友问，这样的方式也没见提升多少效率啊。 这其实是由于我本地文件少，加上一个文件处理的耗时也比较短导致的。 甚至线程数开的够多导致频繁的上下文切换还是让执行效率降低。 为了模拟效率的提升，每处理一个文件我都让当前线程休眠 100 毫秒来模拟执行耗时。 先看单线程运行需要耗时多久。 总共耗时：[8404] ms 接着在线程池大小为 4 的情况下耗时： 总共耗时：[2350] ms 可见效率提升还是非常明显的。 更多思考这只是多线程其中的一个用法，相信看到这里的朋友应该多它的理解更进一步了。 再给大家留个阅后练习，场景也是类似的： 在 Redis 或者其他存储介质中存放有上千万的手机号码数据，每个号码都是唯一的，需要在最快的时间内把这些号码全部都遍历一遍。 有想法感兴趣的朋友欢迎在文末留言参与讨论🤔🤨。 总结希望看完的朋友心中能对文初的几个问题能有自己的答案： 为什么需要多线程？ 怎么实现一个多线程程序？ 多线程带来的问题及解决方案？ 文中的代码都在此处。 https://github.com/crossoverJie/NOWS 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>ThreadPool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用责任链模式设计一个拦截器]]></title>
    <url>%2F2018%2F10%2F22%2Fwheel%2Fcicada5%2F</url>
    <content type="text"><![CDATA[前言近期在做 Cicada 的拦截器功能，正好用到了责任链模式。 这个设计模式在日常使用中频率还是挺高的，借此机会来分析分析。 责任链模式先来看看什么是责任链模式。 引用一段维基百科对其的解释： 责任链模式在面向对象程式设计里是一种软件设计模式，它包含了一些命令对象和一系列的处理对象。每一个处理对象决定它能处理哪些命令对象，它也知道如何将它不能处理的命令对象传递给该链中的下一个处理对象。该模式还描述了往该处理链的末尾添加新的处理对象的方法。 光看这段描述可能大家会觉得懵，简单来说就是该设计模式用于对某个对象或者请求进行一系列的处理，这些处理逻辑正好组成一个链条。 下面来简单演示使用与不使用责任链模式有什么区别和优势。 责任链模式的应用传统实现假设这样的场景：传入了一段内容，需要对这段文本进行加工；比如过滤敏感词、错别字修改、最后署上版权等操作。 常见的写法如下： 123456789public class Main &#123; public static void main(String[] args) &#123; String msg = "内容内容内容" ; String result = Process.sensitiveWord() .typo() .copyright(); &#125;&#125; 这样看似没啥问题也能解决需求，但如果我还需要为为内容加上一个统一的标题呢？在现有的方式下就不得不新增处理方法，并且是在这个客户端（Process）的基础上进行新增。 显然这样的扩展性不好。 责任链模式实现这时候就到了责任链模式发挥作用了。 该需求非常的符合对某一个对象、请求进行一系列处理的特征。 于是我们将代码修改： 这时 Process 就是一个接口了，用于定义真正的处理函数。 12345678public interface Process &#123; /** * 执行处理 * @param msg */ void doProcess(String msg) ;&#125; 同时之前对内容的各种处理只需要实现该接口即可： 12345678910111213141516171819202122public class SensitiveWordProcess implements Process &#123; @Override public void doProcess(String msg) &#123; System.out.println(msg + "敏感词处理"); &#125;&#125;public class CopyrightProcess implements Process &#123; @Override public void doProcess(String msg) &#123; System.out.println(msg + "版权处理"); &#125;&#125;public class CopyrightProcess implements Process &#123; @Override public void doProcess(String msg) &#123; System.out.println(msg + "版权处理"); &#125;&#125; 然后只需要给客户端提供一个执行入口以及添加责任链的入口即可： 123456789101112131415161718192021222324public class MsgProcessChain &#123; private List&lt;Process&gt; chains = new ArrayList&lt;&gt;() ; /** * 添加责任链 * @param process * @return */ public MsgProcessChain addChain(Process process)&#123; chains.add(process) ; return this ; &#125; /** * 执行处理 * @param msg */ public void process(String msg)&#123; for (Process chain : chains) &#123; chain.doProcess(msg); &#125; &#125;&#125; 这样使用起来就非常简单： 123456789101112public class Main &#123; public static void main(String[] args) &#123; String msg = "内容内容内容==" ; MsgProcessChain chain = new MsgProcessChain() .addChain(new SensitiveWordProcess()) .addChain(new TypoProcess()) .addChain(new CopyrightProcess()) ; chain.process(msg) ; &#125;&#125; 当我需要再增加一个处理逻辑时只需要添加一个处理单元即可（addChain(Process process)），并对客户端 chain.process(msg) 是无感知的，不需要做任何的改动。 可能大家没有直接写过责任链模式的相关代码，但不经意间使用到的却不少。 比如 Netty 中的 pipeline 就是一个典型的责任链模式，它可以让一个请求在整个管道中进行流转。 通过官方图就可以非常清楚的看出是一个责任链模式： 用责任链模式设计一个拦截器对于拦截器来说使用责任链模式再好不过了。 下面来看看在 Cicada 中的实现： 首先是定义了和上文 Process 接口类似的 CicadaInterceptor 抽象类： 12345678public abstract class CicadaInterceptor &#123; public boolean before(CicadaContext context,Param param) throws Exception&#123; return true; &#125; public void after(CicadaContext context,Param param) throws Exception&#123;&#125;&#125; 同时定义了一个 InterceptProcess 的客户端： 其中的 loadInterceptors() 会将所有的拦截器加入到责任链中。 再提供了两个函数分别对应了拦截前和拦截后的入口： 实际应用现在来看看具体是怎么使用的吧。 在请求的 handle 中首先进行加载（loadInterceptors(AppConfig appConfig)），也就是初始化责任链。 接下来则是客户端的入口；调用拦截前后的入口方法即可。 由于是拦截器，那么在 before 函数中是可以对请求进行拦截的。只要返回 false 就不会继续向后处理。所以这里做了一个返回值的判断。 同时对于使用者来说只需要创建拦截器类继承 CicadaInterceptor 类即可。 这里做了一个演示，分别有两个拦截器： 记录一个业务 handle 的执行时间。 在 after 里打印了请求参数。 同时可在第一个拦截器中返回 false 让请求被拦截。 先来做前两个试验： 这样当我请求其中一个接口时会将刚才的日志打印出来： 接下来我让打印执行时间的拦截器中拦截请求，同时输入向前端输入一段文本： 请求接口可以看到如下内容： 同时后面的请求参数也没有打印出来，说明请求确实被拦截下来。 同时我也可以调整拦截顺序，只需要在@Interceptor(order = 1) 注解中定义这个 order 属性即可（默认值是 0，越小越先执行）。 之前是打印请求参数的拦截器先执行，这次我手动将它的 order 调整为 2，而打印时间的 order 为 1 。 再次请求接口观察后台日志： 发现打印执行时间的拦截器先执行。 那这个执行执行顺序如何实现自定义配置的呢？ 其实也比较简单，有以下几步： 在加载拦截器时将注解里的 order 保存起来。 设置拦截器到责任链中时通过反射将 order 的值保存到各个拦截器中。 最终通过排序重新排列这个责任链的顺序。 贴一些核心代码。 扫描拦截器时保存 order 值： 保存 order 值到拦截器中： 重新对责任链排序： 总结整个责任链模式已经讲完，希望对这个设计模式还不了解的朋友带来些帮助。 上文中的源码如下： https://github.com/TogetherOS/cicada:一个高性能、轻量 HTTP 框架 https://git.io/fxKid 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>cicada</category>
        <category>轮子</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>HTTP</tag>
        <tag>Netty</tag>
        <tag>责任链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享几个 SpringBoot 实用的小技巧]]></title>
    <url>%2F2018%2F10%2F15%2FSpringBoot%2FSpringBoot-tips%2F</url>
    <content type="text"><![CDATA[前言最近分享的一些源码、框架设计的东西。我发现大家热情不是特别高，想想大多数应该还是正儿八经写代码的居多；这次就分享一点接地气的： SpringBoot 使用中的一些小技巧。 算不上多高大上的东西，但都还挺有用。 屏蔽外部依赖第一个是屏蔽外部依赖，什么意思呢？ 比如大家日常开发时候有没有这样的烦恼： 项目是基于 SpringCloud 或者是 dubbo 这样的分布式服务，你需要依赖许多基础服务。 比如说某个订单号的生成、获取用户信息等。 由于服务拆分，这些功能都是在其他应用中以接口的形式提供，单测还好我还可以利用 Mock 把它屏蔽掉。 但如果自己想把应用启动起来同时把自己相关的代码跑一遍呢？ 通常有几种做法： 本地把所有的服务都启动起来。 把注册中心换为开发环境，依赖开发环境的服务。 直接把代码推送到开发环境自测。 看起来三种都可以，以前我也是这么干的。但还是有几个小问题： 本地启动有可能服务很多，全部起来电脑能不能撑住还两说，万一服务有问题就进行不下去了。 依赖开发环境的前提是网络打通，还有一个问题就是开发环境代码很不稳定很大可能会影响你的测试。 推送到开发环境应该是比较靠谱的方案，但如果想调试只有日志大法，没有本地 debug 的效率高效。 那如何解决问题呢？既可以在本地调试也不用启动其他服务。 其实也可以利用单测的做法，把其他外部依赖 Mock 掉就行了。 大致的流程分为以下几步： SpringBoot 启动之后在 Spring 中找出你需要屏蔽的那个 API 的 bean（通常情况下这个接口都是交给 Spring 管理的）。 手动从 bean 容器中删除该 bean。 重新创建一个该 API 的对象，只不过是通过 Mock 出来的。 再手动注册进 bean 容器中。 以下面这段代码为例： 123456789@Overridepublic BaseResponse&lt;OrderNoResVO&gt; getUserByHystrix(@RequestBody UserReqVO userReqVO) &#123; OrderNoReqVO vo = new OrderNoReqVO(); vo.setAppId(123L); vo.setReqNo(userReqVO.getReqNo()); BaseResponse&lt;OrderNoResVO&gt; orderNo = orderServiceClient.getOrderNo(vo); return orderNo;&#125; 这是一个 SpringCloud 应用。 它依赖于 orderServiceClient 获取一个订单号。 其中的 orderServiceClient 就是一个外部 API，也是被 Spring 所管理。 替换原有的 Bean下一步就是替换原有的 Bean。 12345678910111213141516171819202122232425262728293031323334@Componentpublic class OrderMockServiceConfig implements CommandLineRunner &#123; private final static Logger logger = LoggerFactory.getLogger(OrderMockServiceConfig.class); @Autowired private ApplicationContext applicationContext; @Value("$&#123;excute.env&#125;") private String env; @Override public void run(String... strings) throws Exception &#123; // 非本地环境不做处理 if ("dev".equals(env) || "test".equals(env) || "pro".equals(env)) &#123; return; &#125; DefaultListableBeanFactory defaultListableBeanFactory = (DefaultListableBeanFactory) applicationContext.getAutowireCapableBeanFactory(); OrderServiceClient orderServiceClient = defaultListableBeanFactory.getBean(OrderServiceClient.class); logger.info("======orderServiceClient &#123;&#125;=====", orderServiceClient.getClass()); defaultListableBeanFactory.removeBeanDefinition(OrderServiceClient.class.getCanonicalName()); OrderServiceClient mockOrderApi = PowerMockito.mock(OrderServiceClient.class, invocationOnMock -&gt; BaseResponse.createSuccess(DateUtil.getLongTime() + "", "mock orderNo success")); defaultListableBeanFactory.registerSingleton(OrderServiceClient.class.getCanonicalName(), mockOrderApi); logger.info("======mockOrderApi &#123;&#125;=====", mockOrderApi.getClass()); &#125;&#125; 其中实现了 CommandLineRunner 接口，可以在 Spring 容器初始化完成之后调用 run() 方法。 代码非常简单，简单来说首先判断下是什么环境，毕竟除开本地环境其余的都是需要真正调用远程服务的。 之后就是获取 bean 然后手动删除掉。 关键的一步： 1234OrderServiceClient mockOrderApi = PowerMockito.mock(OrderServiceClient.class, invocationOnMock -&gt; BaseResponse.createSuccess(DateUtil.getLongTime() + "", "mock orderNo success"));defaultListableBeanFactory.registerSingleton(OrderServiceClient.class.getCanonicalName(), mockOrderApi); 创建了一个新的 OrderServiceClient 对象并手动注册进了 Spring 容器中。 第一段代码使用的是 PowerMockito.mock 的 API，他可以创建一个代理对象，让所有调用 OrderServiceClient 的方法都会做默认的返回。 1BaseResponse.createSuccess(DateUtil.getLongTime() + "", "mock orderNo success")) 测试一下，当我们没有替换时调用刚才那个接口并且本地也没有启动 OrderService： 因为没有配置 fallback 所以会报错，表示找不到这个服务。 替换掉 bean 时： 再次请求没有报错，并且获得了我们默认的返回。 通过日志也会发现 OrderServiceClient 最后已经被 Mock 代理了，并不会去调用真正的方法。 配置加密下一个则是配置加密，这应该算是一个基本功能。 比如我们配置文件中的一些账号和密码，都应该是密文保存的。 因此这次使用了一个开源组件来实现加密与解密，并且对 SpringBoot 非常友好只需要几段代码即可完成。 首先根据加密密码将需要加密的配置加密为密文。 替换原本明文保存的配置。 再使用时进行解密。 使用该包也只需要引入一个依赖即可： 12345&lt;dependency&gt; &lt;groupId&gt;com.github.ulisesbocchio&lt;/groupId&gt; &lt;artifactId&gt;jasypt-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.14&lt;/version&gt;&lt;/dependency&gt; 同时写一个单测根据密码生成密文，密码也可保存在配置文件中： 1jasypt.encryptor.password=123456 接着在单测中生成密文。 1234567891011@Autowiredprivate StringEncryptor encryptor;@Testpublic void getPass() &#123; String name = encryptor.encrypt("userName"); String password = encryptor.encrypt("password"); System.out.println(name + "----------------"); System.out.println(password + "----------------");&#125; 之后只需要使用密文就行。 由于我这里是对数据库用户名和密码加密，所以还得有一个解密的过程。 利用 Spring Bean 的一个增强接口即可实现： 12345678910111213141516171819202122232425@Componentpublic class DataSourceProcess implements BeanPostProcessor &#123; @Autowired private StringEncryptor encryptor; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if (bean instanceof DataSourceProperties)&#123; DataSourceProperties dataSourceProperties = (DataSourceProperties) bean; dataSourceProperties.setUsername(encryptor.decrypt(dataSourceProperties.getUsername())) ; dataSourceProperties.setPassword(encryptor.decrypt(dataSourceProperties.getPassword())); return dataSourceProperties ; &#125; return bean; &#125;&#125; 这样就可以在真正使用时还原为明文。 同时也可以在启动命令中配置刚才的密码： 1java -Djasypt.encryptor.password=password -jar target/jasypt-spring-boot-demo-0.0.1-SNAPSHOT.jar 总结这样两个小技巧就讲完了，大家有 SpringBoot 的更多使用技巧欢迎留言讨论。 上文的一些实例代码可以在这里找到： https://github.com/crossoverJie/springboot-cloud 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Mock</tag>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从源码分析如何优雅的使用 Kafka 生产者]]></title>
    <url>%2F2018%2F10%2F11%2Fkafka%2Fkafka-product%2F</url>
    <content type="text"><![CDATA[前言在上文 设计一个百万级的消息推送系统 中提到消息流转采用的是 Kafka 作为中间件。 其中有朋友咨询在大量消息的情况下 Kakfa 是如何保证消息的高效及一致性呢？ 正好以这个问题结合 Kakfa 的源码讨论下如何正确、高效的发送消息。 内容较多，对源码感兴趣的朋友请系好安全带😏(源码基于 v0.10.0.0 版本分析)。同时最好是有一定的 Kafka 使用经验，知晓基本的用法。 简单的消息发送在分析之前先看一个简单的消息发送是怎么样的。 以下代码基于 SpringBoot 构建。 首先创建一个 org.apache.kafka.clients.producer.Producer 的 bean。 主要关注 bootstrap.servers，它是必填参数。指的是 Kafka 集群中的 broker 地址，例如 127.0.0.1:9094。 其余几个参数暂时不做讨论，后文会有详细介绍。 接着注入这个 bean 即可调用它的发送函数发送消息。 这里我给某一个 Topic 发送了 10W 条数据，运行程序消息正常发送。 但这仅仅只是做到了消息发送，对消息是否成功送达完全没管，等于是纯异步的方式。 同步那么我想知道消息到底发送成功没有该怎么办呢？ 其实 Producer 的 API 已经帮我们考虑到了，发送之后只需要调用它的 get() 方法即可同步获取发送结果。 发送结果： 这样的发送效率其实是比较低下的，因为每次都需要同步等待消息发送的结果。 异步为此我们应当采取异步的方式发送，其实 send() 方法默认则是异步的，只要不手动调用 get() 方法。 但这样就没法获知发送结果。 所以查看 send() 的 API 可以发现还有一个参数。 1Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; producer, Callback callback); Callback 是一个回调接口，在消息发送完成之后可以回调我们自定义的实现。 执行之后的结果： 同样的也能获取结果，同时发现回调的线程并不是上文同步时的主线程，这样也能证明是异步回调的。 同时回调的时候会传递两个参数： RecordMetadata 和上文一致的消息发送成功后的元数据。 Exception 消息发送过程中的异常信息。 但是这两个参数并不会同时都有数据，只有发送失败才会有异常信息，同时发送元数据为空。 所以正确的写法应当是： 至于为什么会只有参数一个有值，在下文的源码分析中会一一解释。 源码分析现在只掌握了基本的消息发送，想要深刻的理解发送中的一些参数配置还是得源码说了算。 首先还是来谈谈消息发送时的整个流程是怎么样的，Kafka 并不是简单的把消息通过网络发送到了 broker 中，在 Java 内部还是经过了许多优化和设计。 发送流程为了直观的了解发送的流程，简单的画了几个在发送过程中关键的步骤。 从上至下依次是： 初始化以及真正发送消息的 kafka-producer-network-thread IO 线程。 将消息序列化。 得到需要发送的分区。 写入内部的一个缓存区中。 初始化的 IO 线程不断的消费这个缓存来发送消息。 步骤解析接下来详解每个步骤。 初始化 调用该构造方法进行初始化时，不止是简单的将基本参数写入 KafkaProducer。比较麻烦的是初始化 Sender 线程进行缓冲区消费。 初始化 IO 线程处： 可以看到 Sender 线程有需要成员变量，比如： 1acks,retries,requestTimeout 等，这些参数会在后文分析。 序列化消息在调用 send() 函数后其实第一步就是序列化，毕竟我们的消息需要通过网络才能发送到 Kafka。 其中的 valueSerializer.serialize(record.topic(), record.value()); 是一个接口，我们需要在初始化时候指定序列化实现类。 我们也可以自己实现序列化，只需要实现 org.apache.kafka.common.serialization.Serializer 接口即可。 路由分区接下来就是路由分区，通常我们使用的 Topic 为了实现扩展性以及高性能都会创建多个分区。 如果是一个分区好说，所有消息都往里面写入即可。 但多个分区就不可避免需要知道写入哪个分区。 通常有三种方式。 指定分区可以在构建 ProducerRecord 为每条消息指定分区。 这样在路由时会判断是否有指定，有就直接使用该分区。 这种一般在特殊场景下会使用。 自定义路由策略 如果没有指定分区，则会调用 partitioner.partition 接口执行自定义分区策略。 而我们也只需要自定义一个类实现 org.apache.kafka.clients.producer.Partitioner 接口，同时在创建 KafkaProducer 实例时配置 partitioner.class 参数。 通常需要自定义分区一般是在想尽量的保证消息的顺序性。 或者是写入某些特有的分区，由特别的消费者来进行处理等。 默认策略最后一种则是默认的路由策略，如果我们啥都没做就会执行该策略。 该策略也会使得消息分配的比较均匀。 来看看它的实现： 简单的来说分为以下几步： 获取 Topic 分区数。 将内部维护的一个线程安全计数器 +1。 与分区数取模得到分区编号。 其实这就是很典型的轮询算法，所以只要分区数不频繁变动这种方式也会比较均匀。 写入内部缓存在 send() 方法拿到分区后会调用一个 append() 函数： 该函数中会调用一个 getOrCreateDeque() 写入到一个内部缓存中 batches。 消费缓存在最开始初始化的 IO 线程其实是一个守护线程，它会一直消费这些数据。 通过图中的几个函数会获取到之前写入的数据。这块内容可以不必深究，但其中有个 completeBatch 方法却非常关键。 调用该方法时候肯定已经是消息发送完毕了，所以会调用 batch.done() 来完成之前我们在 send() 方法中定义的回调接口。 从这里也可以看出为什么之前说发送完成后元数据和异常信息只会出现一个。 Producer 参数解析发送流程讲完了再来看看 Producer 中比较重要的几个参数。 acksacks 是一个影响消息吞吐量的一个关键参数。 主要有 [all、-1, 0, 1] 这几个选项，默认为 1。 由于 Kafka 不是采取的主备模式，而是采用类似于 Zookeeper 的主备模式。 前提是 Topic 配置副本数量 replica &gt; 1。 当 acks = all/-1 时： 意味着会确保所有的 follower 副本都完成数据的写入才会返回。 这样可以保证消息不会丢失！ 但同时性能和吞吐量却是最低的。 当 acks = 0 时： producer 不会等待副本的任何响应，这样最容易丢失消息但同时性能却是最好的！ 当 acks = 1 时： 这是一种折中的方案，它会等待副本 Leader 响应，但不会等到 follower 的响应。 一旦 Leader 挂掉消息就会丢失。但性能和消息安全性都得到了一定的保证。 batch.size这个参数看名称就知道是内部缓存区的大小限制，对他适当的调大可以提高吞吐量。 但也不能极端，调太大会浪费内存。小了也发挥不了作用，也是一个典型的时间和空间的权衡。 上图是几个使用的体现。 retriesretries 该参数主要是来做重试使用，当发生一些网络抖动都会造成重试。 这个参数也就是限制重试次数。 但也有一些其他问题。 因为是重发所以消息顺序可能不会一致，这也是上文提到就算是一个分区消息也不会是完全顺序的情况。 还是由于网络问题，本来消息已经成功写入了但是没有成功响应给 producer，进行重试时就可能会出现消息重复。这种只能是消费者进行幂等处理。 高效的发送方式如果消息量真的非常大，同时又需要尽快的将消息发送到 Kafka。一个 producer 始终会收到缓存大小等影响。 那是否可以创建多个 producer 来进行发送呢？ 配置一个最大 producer 个数。 发送消息时首先获取一个 producer，获取的同时判断是否达到最大上限，没有就新建一个同时保存到内部的 List 中，保存时做好同步处理防止并发问题。 获取发送者时可以按照默认的分区策略使用轮询的方式获取（保证使用均匀）。 这样在大量、频繁的消息发送场景中可以提高发送效率减轻单个 producer 的压力。 关闭 Producer最后则是 Producer 的关闭，Producer 在使用过程中消耗了不少资源（线程、内存、网络等）因此需要显式的关闭从而回收这些资源。 默认的 close() 方法和带有超时时间的方法都是在一定的时间后强制关闭。 但在过期之前都会处理完剩余的任务。 所以使用哪一个得视情况而定。 总结本文内容较多，从实例和源码的角度分析了 Kafka 生产者。 希望看完的朋友能有收获，同时也欢迎留言讨论。 不出意外下期会讨论 Kafka 消费者。 如果对你有帮助还请分享让更多的人看到。 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>Kafka</category>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「造个轮子」——cicada 设计全局上下文]]></title>
    <url>%2F2018%2F10%2F09%2Fwheel%2Fcicada4%2F</url>
    <content type="text"><![CDATA[前言本次 Cicada 已经更新到了 v1.0.3。 主要是解决了两个 issue，#9 #8。 所以本次的主要更新为： Cicada 采用合理的线程分配来处理接入请求线程以及 IO 线程。 支持多种响应方式（以前只有 json，现在支持 text）。 为了满足上者引入了 context。 优雅停机。 其中我觉得最核心也最有用的就是这个 Context，并为此重构了大部分代码。 多种响应方式在起初 Cicada 默认只能响应 json，这一点确实不够灵活。加上后续也打算支持模板解析，所以不如直接在 API 中加入可让用户自行选择不同的响应方式。 因此调整后的 API 如下。 想要输出 text/plain 时。 123456789@CicadaAction("textAction")public class TextAction implements WorkAction &#123; @Override public void execute(CicadaContext context, Param param) throws Exception &#123; String url = context.request().getUrl(); String method = context.request().getMethod(); context.text("hello world url=" + url + " method=" + method); &#125;&#125; 而响应输出 application/json 时只需要把需要响应的对象写入到 json() 方法中. 因此原有的业务 action 中也加入了一个上下文的参数： 1234567/** * abstract execute method * @param context current context * @param param request params * @throws Exception throw exception */void execute(CicadaContext context ,Param param) throws Exception; 下面就来看看这个 Context 是如何完成的。 Cicada Context先看看有了这个上下文之后可以做什么。 比如有些场景下我们需要拿到本次请求中的头信息，这时就可以通过这个 Context 对象直接获取。 当然不止是头信息： 获取请求头。 设置响应头。 设置 cookie。 获取请求 URL。 获取请求的 method（get/post）等。 其实通过这些特点可以看出这些信息其实都和一次 请求、响应 密切相关，并且各个请求之间的信息应互不影响。 这样的特性是不是非常熟悉，没错那就是 ThreadLocal，它可以将每个线程的信息存储起来互不影响。 ThreadLocal 的原理本次不做过多分析，只谈它在 Cicada 中的应用。 CicadaContext.class先来看看 CicadaContext 这个类的主要成员变量以及方法。 成员变量是两个接口 CicadaRequest、CicadaResponse，名称就能看出肯定是存放请求和响应数据的。 HttpDispatcher.class想要存放本次请求的上下文自然是在真正请求分发的地方 HttpDispatcher。 这里改的较大的就是两个红框处，第一部分是做上下文初始化及赋值。 第二部分自然就是卸载上下文。 先看初始化。 CicadaRequest cicadaRequest = CicadaHttpRequest.init(defaultHttpRequest) ; 首先是将 request 初始化： CicadaHttpRequest 自然是实现了 CicadaRequest 接口： 这里只保存了请求的 URL、method 等信息，后续要加的请求头也存放在此处即可。 Response 也是同理的。 这两个具体的实现类都私有化了构造函数，防止外部破坏了整体性。 接着将当前请求的上下文保存到了 CicadaContext 中。 1CicadaContext.setContext(new CicadaContext(cicadaRequest,cicadaResponse)); 而这个函数本质使用的则是 ThreadLocal 来存放 CicadaContext。 12345678910111213public static void setContext(CicadaContext context)&#123; ThreadLocalHolder.setCicadaContext(context) ;&#125;private static final ThreadLocal&lt;CicadaContext&gt; CICADA_CONTEXT= new ThreadLocal() ;/** * set cicada context * @param context current context */public static void setCicadaContext(CicadaContext context)&#123; CICADA_CONTEXT.set(context) ;&#125; 处理业务及响应接着就是处理业务，调用不同的 API 做不同响应。 拿 context.text() 来说： 其实就是设置了对应的响应方式、以及把响应内容写入了 CicadaResponse 的 httpContent 中。 业务处理完后调用 responseContent() 进行响应： 1responseContent(ctx,CicadaContext.getResponse().getHttpContent()); 其实就是在上下文中拿到的响应方式及响应内容返回给客户端。 卸载上下文最后有点非常重要，那就是 卸载上下文。 如果这里不做处理，之后随着请求的增多，ThreadLocal 里存放的数据也越来越多，最终肯定会导致内存溢出。 所以 CicadaContext.removeContext() 就是为了及时删除当前上下文。 优雅停机最后还新增了一个停机的方法。 其实也就是利用 Hook 函数实现的。 由于目前 Cicada 开的线程，占用的资源都不是特别多，所以只是关闭了 Netty 所使用的线程。 如果后续新增了自身的线程等资源，那也可以全部放到这里来进行释放。 总结Cicada 已经更新了 4 个版本，雏形都有了。 后续会重点实现模板解析和注解请求路由完成，把 MVC 中的 view 完成就差不多了。 还没有了解的朋友可以点击下面链接进入主页了解下😋。 https://github.com/TogetherOS/cicada]]></content>
      <categories>
        <category>cicada</category>
        <category>轮子</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>HTTP</tag>
        <tag>Netty</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计一个百万级的消息推送系统]]></title>
    <url>%2F2018%2F09%2F25%2Fnetty%2Fmillion-sms-push%2F</url>
    <content type="text"><![CDATA[前言首先迟到的祝大家中秋快乐。 最近一周多没有更新了。其实我一直想憋一个大招，分享一些大家感兴趣的干货。 鉴于最近我个人的工作内容，于是利用这三天小长假憋了一个出来（其实是玩了两天🤣）。 先简单说下本次的主题，由于我最近做的是物联网相关的开发工作，其中就不免会遇到和设备的交互。 最主要的工作就是要有一个系统来支持设备的接入、向设备推送消息；同时还得满足大量设备接入的需求。 所以本次分享的内容不但可以满足物联网领域同时还支持以下场景： 基于 WEB 的聊天系统（点对点、群聊）。 WEB 应用中需求服务端推送的场景。 基于 SDK 的消息推送平台。 技术选型要满足大量的连接数、同时支持双全工通信，并且性能也得有保障。 在 Java 技术栈中进行选型首先自然是排除掉了传统 IO。 那就只有选 NIO 了，在这个层面其实选择也不多，考虑到社区、资料维护等方面最终选择了 Netty。 最终的架构图如下： 现在看着蒙没关系，下文一一介绍。 协议解析既然是一个消息系统，那自然得和客户端定义好双方的协议格式。 常见和简单的是 HTTP 协议，但我们的需求中有一项需要是双全工的交互方式，同时 HTTP 更多的是服务于浏览器。我们需要的是一个更加精简的协议，减少许多不必要的数据传输。 因此我觉得最好是在满足业务需求的情况下定制自己的私有协议，在我这个场景下其实有标准的物联网协议。 如果是其他场景可以借鉴现在流行的 RPC 框架定制私有协议，使得双方通信更加高效。 不过根据这段时间的经验来看，不管是哪种方式都得在协议中预留安全相关的位置。 协议相关的内容就不过讨论了，更多介绍具体的应用。 简单实现首先考虑如何实现功能，再来思考百万连接的情况。 注册鉴权在做真正的消息上、下行之前首先要考虑的就是鉴权问题。 就像你使用微信一样，第一步怎么也得是登录吧，不能无论是谁都可以直接连接到平台。 所以第一步得是注册才行。 如上面架构图中的 注册/鉴权 模块。通常来说都需要客户端通过 HTTP 请求传递一个唯一标识，后台鉴权通过之后会响应一个 token，并将这个 token 和客户端的关系维护到 Redis 或者是 DB 中。 客户端将这个 token 也保存到本地，今后的每一次请求都得带上这个 token。一旦这个 token 过期，客户端需要再次请求获取 token。 鉴权通过之后客户端会直接通过TCP 长连接到图中的 push-server 模块。 这个模块就是真正处理消息的上、下行。 保存通道关系在连接接入之后，真正处理业务之前需要将当前的客户端和 Channel 的关系维护起来。 假设客户端的唯一标识是手机号码，那就需要把手机号码和当前的 Channel 维护到一个 Map 中。 这点和之前 SpringBoot 整合长连接心跳机制 类似。 同时为了可以通过 Channel 获取到客户端唯一标识（手机号码），还需要在 Channel 中设置对应的属性： 123public static void putClientId(Channel channel, String clientId) &#123; channel.attr(CLIENT_ID).set(clientId);&#125; 获取时手机号码时： 123public static String getClientId(Channel channel) &#123; return (String)getAttribute(channel, CLIENT_ID);&#125; 这样当我们客户端下线的时便可以记录相关日志： 123String telNo = NettyAttrUtil.getClientId(ctx.channel());NettySocketHolder.remove(telNo);log.info("客户端下线，TelNo=" + telNo); 这里有一点需要注意：存放客户端与 Channel 关系的 Map 最好是预设好大小（避免经常扩容），因为它将是使用最为频繁同时也是占用内存最大的一个对象。 消息上行接下来则是真正的业务数据上传，通常来说第一步是需要判断上传消息输入什么业务类型。 在聊天场景中，有可能上传的是文本、图片、视频等内容。 所以我们得进行区分，来做不同的处理；这就和客户端协商的协议有关了。 可以利用消息头中的某个字段进行区分。 更简单的就是一个 JSON 消息，拿出一个字段用于区分不同消息。 不管是哪种只有可以区分出来即可。 消息解析与业务解耦消息可以解析之后便是处理业务，比如可以是写入数据库、调用其他接口等。 我们都知道在 Netty 中处理消息一般是在 channelRead() 方法中。 在这里可以解析消息，区分类型。 但如果我们的业务逻辑也写在里面，那这里的内容将是巨多无比。 甚至我们分为好几个开发来处理不同的业务，这样将会出现许多冲突、难以维护等问题。 所以非常有必要将消息解析与业务处理完全分离开来。 这时面向接口编程就发挥作用了。 这里的核心代码和 「造个轮子」——cicada(轻量级 WEB 框架) 是一致的。 都是先定义一个接口用于处理业务逻辑，然后在解析消息之后通过反射创建具体的对象执行其中的处理函数即可。 这样不同的业务、不同的开发人员只需要实现这个接口同时实现自己的业务逻辑即可。 伪代码如下： 想要了解 cicada 的具体实现请点击这里： https://github.com/TogetherOS/cicada 上行还有一点需要注意；由于是基于长连接，所以客户端需要定期发送心跳包用于维护本次连接。同时服务端也会有相应的检查，N 个时间间隔没有收到消息之后将会主动断开连接节省资源。 这点使用一个 IdleStateHandler 就可实现，更多内容可以查看 Netty(一) SpringBoot 整合长连接心跳机制。 消息下行有了上行自然也有下行。比如在聊天的场景中，有两个客户端连上了 push-server,他们直接需要点对点通信。 这时的流程是： A 将消息发送给服务器。 服务器收到消息之后，得知消息是要发送给 B，需要在内存中找到 B 的 Channel。 通过 B 的 Channel 将 A 的消息转发下去。 这就是一个下行的流程。 甚至管理员需要给所有在线用户发送系统通知也是类似： 遍历保存通道关系的 Map，挨个发送消息即可。这也是之前需要存放到 Map 中的主要原因。 伪代码如下： 具体可以参考： https://github.com/crossoverJie/netty-action/ 分布式方案单机版的实现了，现在着重讲讲如何实现百万连接。 百万连接其实只是一个形容词，更多的是想表达如何来实现一个分布式的方案，可以灵活的水平拓展从而能支持更多的连接。 再做这个事前首先得搞清楚我们单机版的能支持多少连接。影响这个的因素就比较多了。 服务器自身配置。内存、CPU、网卡、Linux 支持的最大文件打开数等。 应用自身配置，因为 Netty 本身需要依赖于堆外内存，但是 JVM 本身也是需要占用一部分内存的，比如存放通道关系的大 Map。这点需要结合自身情况进行调整。 结合以上的情况可以测试出单个节点能支持的最大连接数。 单机无论怎么优化都是有上限的，这也是分布式主要解决的问题。 架构介绍在将具体实现之前首先得讲讲上文贴出的整体架构图。 先从左边开始。 上文提到的 注册鉴权 模块也是集群部署的，通过前置的 Nginx 进行负载。之前也提过了它主要的目的是来做鉴权并返回一个 token 给客户端。 但是 push-server 集群之后它又多了一个作用。那就是得返回一台可供当前客户端使用的 push-server。 右侧的 平台 一般指管理平台，它可以查看当前的实时在线数、给指定客户端推送消息等。 推送消息则需要经过一个推送路由（push-server）找到真正的推送节点。 其余的中间件如：Redis、Zookeeper、Kafka、MySQL 都是为了这些功能所准备的，具体看下面的实现。 注册发现首先第一个问题则是 注册发现，push-server 变为多台之后如何给客户端选择一台可用的节点是第一个需要解决的。 这块的内容其实已经在 分布式(一) 搞定服务注册与发现 中详细讲过了。 所有的 push-server 在启动时候需要将自身的信息注册到 Zookeeper 中。 注册鉴权 模块会订阅 Zookeeper 中的节点，从而可以获取最新的服务列表。结构如下： 以下是一些伪代码： 应用启动注册 Zookeeper。 对于注册鉴权模块来说只需要订阅这个 Zookeeper 节点： 路由策略既然能获取到所有的服务列表，那如何选择一台刚好合适的 push-server 给客户端使用呢？ 这个过程重点要考虑以下几点： 尽量保证各个节点的连接均匀。 增删节点是否要做 Rebalance。 首先保证均衡有以下几种算法： 轮询。挨个将各个节点分配给客户端。但会出现新增节点分配不均匀的情况。 Hash 取模的方式。类似于 HashMap，但也会出现轮询的问题。当然也可以像 HashMap 那样做一次 Rebalance，让所有的客户端重新连接。不过这样会导致所有的连接出现中断重连，代价有点大。 由于 Hash 取模方式的问题带来了一致性 Hash算法，但依然会有一部分的客户端需要 Rebalance。 权重。可以手动调整各个节点的负载情况，甚至可以做成自动的，基于监控当某些节点负载较高就自动调低权重，负载较低的可以提高权重。 还有一个问题是： 当我们在重启部分应用进行升级时，在该节点上的客户端怎么处理？ 由于我们有心跳机制，当心跳不通之后就可以认为该节点出现问题了。那就得重新请求注册鉴权模块获取一个可用的节点。在弱网情况下同样适用。 如果这时客户端正在发送消息，则需要将消息保存到本地等待获取到新的节点之后再次发送。 有状态连接在这样的场景中不像是 HTTP 那样是无状态的，我们得明确的知道各个客户端和连接的关系。 在上文的单机版中我们将这个关系保存到本地的缓存中，但在分布式环境中显然行不通了。 比如在平台向客户端推送消息的时候，它得首先知道这个客户端的通道保存在哪台节点上。 借助我们以前的经验，这样的问题自然得引入一个第三方中间件用来存放这个关系。 也就是架构图中的存放路由关系的 Redis，在客户端接入 push-server 时需要将当前客户端唯一标识和服务节点的 ip+port 存进 Redis。 同时在客户端下线时候得在 Redis 中删掉这个连接关系。 这样在理想情况下各个节点内存中的 map 关系加起来应该正好等于 Redis 中的数据。 伪代码如下： 这里存放路由关系的时候会有并发问题，最好是换为一个 lua 脚本。 推送路由设想这样一个场景：管理员需要给最近注册的客户端推送一个系统消息会怎么做？ 结合架构图 假设这批客户端有 10W 个，首先我们需要将这批号码通过平台下的 Nginx 下发到一个推送路由中。 为了提高效率甚至可以将这批号码再次分散到每个 push-route 中。 拿到具体号码之后再根据号码的数量启动多线程的方式去之前的路由 Redis 中获取客户端所对应的 push-server。 再通过 HTTP 的方式调用 push-server 进行真正的消息下发（Netty 也很好的支持 HTTP 协议）。 推送成功之后需要将结果更新到数据库中，不在线的客户端可以根据业务再次推送等。 消息流转也许有些场景对于客户端上行的消息非常看重，需要做持久化，并且消息量非常大。 在 push-sever 做业务显然不合适，这时完全可以选择 Kafka 来解耦。 将所有上行的数据直接往 Kafka 里丢后就不管了。 再由消费程序将数据取出写入数据库中即可。 其实这块内容也很值得讨论，可以先看这篇了解下：强如 Disruptor 也发生内存溢出？ 后续谈到 Kafka 再做详细介绍。 分布式问题分布式解决了性能问题但却带来了其他麻烦。 应用监控比如如何知道线上几十个 push-server 节点的健康状况？ 这时就得监控系统发挥作用了，我们需要知道各个节点当前的内存使用情况、GC。 以及操作系统本身的内存使用，毕竟 Netty 大量使用了堆外内存。 同时需要监控各个节点当前的在线数，以及 Redis 中的在线数。理论上这两个数应该是相等的。 这样也可以知道系统的使用情况，可以灵活的维护这些节点数量。 日志处理日志记录也变得异常重要了，比如哪天反馈有个客户端一直连不上，你得知道问题出在哪里。 最好是给每次请求都加上一个 traceID 记录日志，这样就可以通过这个日志在各个节点中查看到底是卡在了哪里。 以及 ELK 这些工具都得用起来才行。 总结本次是结合我日常经验得出的，有些坑可能在工作中并没有踩到，所有还会有一些遗漏的地方。 就目前来看想做一个稳定的推送系统其实是比较麻烦的，其中涉及到的点非常多，只有真正做过之后才会知道。 看完之后觉得有帮助的还请不吝转发分享。 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
        <tag>Redis</tag>
        <tag>Zookeeper</tag>
        <tag>推送</tag>
        <tag>路由策略</tag>
        <tag>注册发现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「造个轮子」——cicada 设计一个配置模块]]></title>
    <url>%2F2018%2F09%2F14%2Fwheel%2Fcicada3%2F</url>
    <content type="text"><![CDATA[前言在前两次的 cicada 版本中其实还不支持读取配置文件，比如对端口、路由的配置。 因此我按照自己的想法创建了一个 issue ，也收集到了一些很不错的建议。 最终其实还是按照我之前的想法来做了这个配置管理。 同时将 cicada 升级到了 v1.0.2。 目标在做之前是要把需求想好，到底怎样的一个配置管理是对开发人员来说比较友好的？ 我认为有以下几点: 可以自定义配置，并且支持不同的环境（开发、测试、生产）。 使用灵活。对使用者来说不要有太多的束缚。 理论上来说配置这个东西应当完全独立出来，由一个配置中心来负责管理并且这样可以与应用解耦。 不过这样的实现和当前 cicada 的定义有些冲突，我想尽量小的依赖第三方组件并可以完全独立运行。 因此基于这样的情况便有了以下的实现。 使用在看实现之前先看看基于目前的配置管理如何在业务中使用起来。 结合现在大家使用 SpringBoot 的习惯，cicada 默认会读取 classpath 下的 application.properties 配置文件。并且会默认读取其中的应用端口以及初始路由地址。 同时也新增了一个 api。 12345678910111213public class MainStart &#123; public static void main(String[] args) throws Exception &#123; CicadaServer.start(MainStart.class,"/cicada-example") ; &#125;&#125;public class MainStart &#123; public static void main(String[] args) throws Exception &#123; CicadaServer.start(MainStart.class) ; &#125;&#125; 这样在不传默认地址的时候 cicada 会从 application.properties 中读取。 考虑到后面可维护的情况，cicada 也支持配置各种不同的配置文件。 使用也比较简单，只需要继承 cicada 提供的一个抽象类即可。 1234567891011121314151617public class KafkaConfiguration extends AbstractCicadaConfiguration &#123; public KafkaConfiguration() &#123; super.setPropertiesName("kafka.properties"); &#125;&#125;public class RedisConfiguration extends AbstractCicadaConfiguration &#123; public RedisConfiguration() &#123; super.setPropertiesName("redis.properties"); &#125;&#125; 按照这样的配置也会默认从 classpath 读取这两个配置文件。 当然这里有个前提：代码里配置的文件名必须得和配置文件名称相同。 那如何在业务中读取这两个配置文件的内容呢？ 这也简单，代码一看就懂： 首先需要通过 ConfigurationHolder 获取各自不同配置的管理对象（需要显式指定类类型）。 通过 get() 方法直接获取配置。 同时也支持获取 application.properties 里的配置。 同时为了支持在不同环境的使用，当配置了启动参数将会优先读取。 123-Dapplication.properties=/xx/application.properties-Dkafka.properties=/xx/kakfa.properties-Dredis.properties=/xx/redis.properties 这样算是基本实现了上述的配置要求。 实现要实现以上的功能有几个核心点： 加载所有配置文件。 将不同的配置文件用不同的对象进行管理。 提供简易的接口使用。 由于 cicada 需要支持多个配置文件，所有需要定义一个抽象类供所有的配置管理实现。 定义比较简单，其中有两个重要的成员变量： 文件名称：用于初始化时通过名称加载配置文件。 Properties 其实就是一个 Map 结构的缓存，用于存放所有的配置。当然对外提供的查询是基于它的。 接着就是在初始化时需要找出所有继承了 AbstractCicadaConfiguration 的类。 查询出来之后自然是要进行遍历同时反射创建对象。 由于之前已经调用了 super.setPropertiesName(&quot;redis.properties&quot;); 来赋值配置文件名称，所以还需要在遍历过程中将 Properties 进行赋值。 同时在这里也体现出优先读取的是 VM 启动参数中的配置文件。 1String systemProperty = System.getProperty(conf.getPropertiesName()); 需要额外提一点的是：在查找所有用户自定义的配置管理类时需要手动将 cicada 内置的ApplicationConfiguration 加入其中。 因为使用应用的包名通过反射是查询不出该类的。 保存自定义配置管理为了方便用户在使用时候可以随意的读取各个配置文件，所以还需要将反射创建的对象保存到一个内部缓存中，核心代码就是上上图中的这段代码： 12// add configuration cacheConfigurationHolder.addConfiguration(aClass.getName(), conf); 其中 ConfigurationHolder 的定义如下。 其实也是利用一个 Map 来存放这些对象。 这样在使用时候只需要取出即可。 12KafkaConfiguration configuration = (KafkaConfiguration) getConfiguration(KafkaConfiguration.class);String brokerList = configuration.get("kafka.broker.list"); 重构本次升级同时还重构了部分代码，比如启动类。 现在看上去要清爽和直接的多： 其中也有一点需要注意的地方。 大家如果查看日志的话会发现应用启动之后会打印本次的耗时，自然就是在启动时候记录一个时间，初始化完毕之后记录一个即可。 在之前的实现中由于都是在一个方法内，所以直接使用就行了。 但现在优化之后跨越了不同的方法和类，难道要把时间作为参数在各个方法之前传递嘛？ 那未免太不优雅了。 所以 ThreadLocal 就有了发挥余地。 在初始化的方法中我将当前时间写入： 1ThreadLocalHolder.setLocalTime(System.currentTimeMillis()); 在最后记录日志的地方直接取出比较即可： 这样使用起来就完全不需要管什么参数传递了。 同时 ThreadLocalHolder 的定义： 这里还是有一点需要注意，在这种长生命周期的容器中一定得要记得及时清除。 我这里的时间在查询一次之后就不用了，所以完全放心的在 getLocalTime() 方法中删掉。 总结这就是本次 v1.0.2 中的升级内容，包含了配置支持以及代码重构。其中有些内容我觉得对接触少的同学来说还是挺有帮助的。 关于上两次的版本介绍请查看这里： 「造个轮子」——cicada(轻量级 WEB 框架) 「造个轮子」——cicada 源码分析 还没点关注的朋友可以点波关注： https://github.com/TogetherOS/cicada 也欢迎大家参与一起维护！。 同时后续关于 cicada 的更新会放慢一些。会介绍一些平时实战相关的内容，比如 Kafka 之类的，请持续关注。 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>cicada</category>
        <category>轮子</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>HTTP</tag>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【译】如何高效的使用 Git]]></title>
    <url>%2F2018%2F09%2F07%2Ftranslation%2Fhow-to-use-git-efficiently%2F</url>
    <content type="text"><![CDATA[原文链接 代码昨天还是运行好好的今天就不行了。 代码被删了。 突然出现了一个奇怪的 bug，但是没人知道怎么回事。 如果你出现过上面的任何一种情况，那本篇文章就是为你准备的。 除了知道 git add, git commit , git push 之外，Git 中还需要其他重要的技术需要掌握。长远来看对我们是有帮助的。这里我将向你展示 Git 的最佳实践。 Git 工作流当有多个开发者同时涉及到一个项目时那么就非常有必要正确使用 Git 工作流。 这里我将介绍一种工作流，它在一个多人大型项目中将非常有用。 前言突然有一天，你成为了一个项目的技术 Leader 并计划做出下一个 Facebook。在这个项目中你有三个开发人员。 Alice：一个开发小白。 Bob：拥有一年工作经验，了解基本开发。 John：三年开发经验，熟练开发技能。 你：该项目的技术负责人。 Git 开发流程Master 分支 Master 分支应该始终和生产环境保持一致。 由于 master 和生产代码是一致的，所以没有人包括技术负责人能在 master 上直接开发。 真正的开发代码应当写在其他分支上。 Release(发布) 分支 当项目开始时，第一件事情就是创建发布分支。发布分支是基于 master 分支创建而来。 所有与本项目相关的代码都在发布分支中，这个分支也是一个以 release/ 开头的普通分支。 比如这次的发布分支名为 release/fb。 可能有多个项目都基于同一份代码运行，因此对于每一个项目来说都需要创建一个独立的发布分支。假设现在还有一个项目正在并行运行，那就得为这个项目创建一个单独的发布分支比如 release/messenger。 需要单独的发布分支的原因是：多个并行项目是基于同一份代码运行的，但是项目之间不能有冲突。 Feature(功能分支) branch 对于应用中的每一个功能都应该创建一个独立的功能分支，这会确保这些功能能被单独构建。 功能分支也和其他分支一样，只是以 feature/ 开头。 现在作为技术 Leader，你要求 Alice 去做 Facebook 的登录页面。因此他创建了一个新的功能分支。把他命名为 feature/login。Alice 将会在这个分支上编写所有的登录代码。 这个功能分支通常是基于 Release(发布) 分支 创建而来。 Bob 的任务为创建添加好友页面，因此他创建了一个名为 feature/friendrequest 的功能分支。 John 则被安排构建消息流，因此创建了一个 feature/newsfeed 的功能分支。 所有的开发人员都在自己的分支上进行开发，目前为止都很正常。 现在当 Alice 完成了他的登录开发，他需要将他的功能分支 feature/login 发送给 Release(发布) 分支。这个过程是通过发起一个 pull request 完成的。 Pull request首先 pull request 不能和 git pull 搞混了。 开发人员不能直接向 Release(发布) 分支推送代码，技术 Leader 需要在功能分支合并到 Release(发布) 分支之前做好代码审查。这也是通过 pull request 完成的。 Alice 能够按照如下 GitHub 方式提交 pull request。 在分支名字的旁边有一个 “New pull request” 按钮，点击之后将会显示如下界面： 比较分支是 Alice 的功能分支 feature/login。 base 分支则应该是发布分支 release/fb。 点击之后 Alice 需要为这个 pull request 输入名称和描述，最后再点击 “Create Pull Request” 按钮。 同时 Alice 需要为这个 pull request 指定一个 reviewer。作为技术 Leader 的你被选为本次 pull request 的 reviewer。 你完成代码审查之后就需要把这个功能分支合并到 Release(发布) 分支。 现在你已经把 feature/login 分支合并到 release/fb，并且 Alice 非常高兴他的代码被合并了。 代码冲突 😠 Bob 完成了他的编码工作，同时向 release/fb 分支发起了一个 pull request。 因为发布分支已经合并了登录的代码，这时代码冲突发生了。解决冲突和合并代码是 reviewer 的责任。在这样的情况下，作为技术 Leader 就需要解决冲突和合并代码了。 现在 John 也已经完成了他的开发，同时也想把代码合并到发布分支。但 John 非常擅长于解决代码冲突。他将 release/fb 上最新的代码合并到他自己的功能分支 feature/newsfeed （通过 git pull 或 git merge 命令）。同时他解决了所有存在的冲突，现在 feature/newsfeed 已经有了所有发布分支 release/fb 的代码。 最后 John 创建了一个 pull request，由于 John 已经解决了所有问题，所以本次 pull request 不会再有冲突了。 因此通常有两种方式来解决代码冲突： pull request 的 reviewer 需要解决所有的代码冲突。 开发人员需要确保将发布分支的最新代码合并到功能分支，并且解决所有的冲突。 还是 Master 分支一旦项目完成，发布分支的代码需要合并回 master 分支，同时需要发布到生产环境。 因此生产环境中的代码总是和 master 分支保持一致。同时对于今后的任何项目来说都是要确保 master 代码是最新的。 我们现在团队就是按照这样的方式进行开发，确实可以尽可能的减少代码管理上的问题。 题外话像之前那篇《如何成为一位「不那么差」的程序员》说的那样，建议大家都多看看国外的优质博客。 甚至尝试和作者交流，经过沟通原作者也会在原文中贴上我的翻译链接。大家互惠互利使好的文章转播的更广。 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「造个轮子」——cicada 源码分析]]></title>
    <url>%2F2018%2F09%2F05%2Fwheel%2Fcicada2%2F</url>
    <content type="text"><![CDATA[前言两天前写了文章《「造个轮子」——cicada(轻量级 WEB 框架)》 向大家介绍了 cicada 之后收到很多反馈，也有许多不错的建议。 同时在 GitHub 也收获了 100 多颗 小♥♥（绝对不是刷的。。） 也有朋友希望能出一个源码介绍，本文就目前的 v1.0.1 版本来一起分析分析。 没有看错，刚发布就修复了一个 bug，想要试用的请升级到 1.0.1 吧。 技术选型一般在做一个新玩意之前都会有技术选型的过程，但这点在做 cicada 的时候却异常简单。 因为我的需求是想提供一个高性能的 HTTP 服务，纵观整个开源界其实选择不多。 加上最近我在做 Netty 相关的开发，所以自然而然就选择了它。 同时 Netty 自带了对 HTTP 协议的编解码器，可以非常简单快速的开发一个 HTTP 服务器。我只需要把精力放在参数处理、路由等业务处理上即可。 同时 Netty 也是基于 NIO 实现，性能上也有保证。关于 Netty 相关内容可以参考这里。 下面来重点分析其中的各个过程。 路由规则最核心的自然就是 HTTP 的处理 handle，对应的就是 HttpHandle 类。 查看源码其实很容易看出具体的步骤，注释也很明显。 这里只分析重点功能。 先来考虑下需求。 首先作为一个 HTTP 框架，自然是得让使用者能有地方来实现业务代码；就像咱们现在使用 SpringMVC 时写的 controller 一样。 其实当时考虑过三种方案： 像 SpringMVC 一样定义注解，只要声明了对应注解我就认为这是一个业务类。 用过 Struts2 的同学应该有印象，它的业务类 Action 都是配置到一个 XML 中；在里面配置接口对应的业务处理类。 同样的思路，只是把 XML 文件换成 properties 配置文件，在里面编写 JSON 格式的对应关系。 这时就得分析各个方案的优缺点了。 方案二和三其实就是 XML 和 json 的对比了；XML 会让维护者感到结构清晰，同时便于维护和新增。 JSON 就不太方便处理了，并且在这样的场景并不用于传输自然也发挥不出优势。 最后考虑到现在流行的 SpringBoot 都在去 XML，要是再搞一个依赖于 XML 的东西也跟不上大家的使用习惯。 于是就采用类似于 SpringMVC 这样的注解形式。 既然采用了注解，那框架怎么知道用户访问某个接口时能对应到业务类呢？ 所以首先第一步自然是需要将加有注解的类全部扫描一遍，放到一个本地缓存中。 这样才能方便后续的路由定位。 路由策略其中核心的源码在 routeAction 方法中。 首先会全局扫描使用了 @CicadaAction 的注解，然后再根据请求地址找到对应的业务类。 全局扫描代码： 首先是获取到项目中自定义的所有类，然后判断是否加有 @CicadaAction 注解。 是目标类则把他缓存到一个本地 Map 中，方便下次访问时可以不再扫描直接从缓存中获取即可（反射很耗性能）。 执行完 routeAction 后会获得真正的业务类类型。 Class&lt;?&gt; actionClazz = routeAction(queryStringDecoder, appConfig); 传参方式拿到业务类的类类型之后就成功一大半了，只需要反射生成它的对象然后执行方法即可。 在执行方法之前又要涉及到一个问题，参数我该怎么传递呢？ 考虑到灵活性我采用了最简答 Map 方式。 因此定义了一个通用的 Param 接口并继承了 Map 接口。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public interface Param extends Map&lt;String, Object&gt; &#123; /** * get String * @param param * @return */ String getString(String param); /** * get Integer * @param param * @return */ Integer getInteger(String param); /** * get Long * @param param * @return */ Long getLong(String param); /** * get Double * @param param * @return */ Double getDouble(String param); /** * get Float * @param param * @return */ Float getFloat(String param); /** * get Boolean * @param param * @return */ Boolean getBoolean(String param) ;&#125; 其中封装了几种基本类型的获取方式。 同时在 buildParamMap() 方法中，将接口中的参数封装到这个 Map 中。 1Param paramMap = buildParamMap(queryStringDecoder); 业务执行最后只需要执行业务即可；由于在上文已经获取到业务类的类类型，所以这里通过反射即可调用。 同时也定义了一个业务类需要实现的一个通用接口 WorkAction，想要实现具体业务只要实现它就行。 而这里的方法参数自然就是刚才定义的参数接口 Param。 由于所有的业务类都是实现了 WorkAction，所以在反射时都可以定义为 WorkAction 对象。 12WorkAction action = (WorkAction) actionClazz.newInstance();WorkRes execute = action.execute(paramMap); 最后将构建好的参数 map 传入即可。 响应返回有了请求那自然也得有响应，观察刚才定义的 WorkAction 接口可以发现其实定义了一个 WorkRes 响应类。 所有的响应数据都需要封装到这个对象中。 这个没啥好说的，都是一些基本数据。 最后在 responseMsg() 方法中将响应数据编码为 JSON 输出即可。 拦截器设计拦截器也是一个框架基本的功能，用处非常多。 cicada 的实现原理非常简单，就是在 WorkAction 接口执行业务逻辑之前调用一个方法、执行完毕之后调用另一个方法。 也是同样的思路需要定义一个接口 CicadaInterceptor，其中有两个方法。 看方法名字自然也能看出具体作用。 同时在这两个方法中执行具体的调用。 这里重点要看看 interceptorBefore 方法。 其中也是加入了一个缓存，尽量的减少反射操作。 适配器就这样的拦截器接口是够用了，但并不是所有的业务都需要实现两个接口。 因此也提供了一个适配器 AbstractCicadaInterceptorAdapter。 它作为一个抽象类实现了 CicadaInterceptor 接口，这样后续的拦截业务也可继承该接口选择性的实现方法即可。 类似于这样： 总结v1.0.1 版本的 cicada 就介绍完毕了，其中的原理和源码都比较简单。 大量使用了反射和一些设计模式、多态等应用，这方面经验较少的朋友可以参考下。 同时也有很多不足；比如传参后续会考虑更加优雅的方式、拦截器目前写的比较死，后续会利用动态代理实现自定义拦截。 其实 cicada 只是利用周末两天时间做的，bug 肯定少不了；也欢迎大家在 GitHub 上提 issue 参与。 最后贴下项目地址： https://github.com/TogetherOS/cicada 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>cicada</category>
        <category>轮子</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>HTTP</tag>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「造个轮子」——cicada(轻量级 WEB 框架)]]></title>
    <url>%2F2018%2F09%2F03%2Fwheel%2Fcicada1%2F</url>
    <content type="text"><![CDATA[前言俗话说 「不要重复造轮子」，关于是否有必要不再本次讨论范围。 创建这个项目的主要目的还是提升自己，看看和知名类开源项目的差距以及学习优秀的开源方式。 好了，现在着重来谈谈 cicada 这个项目的核心功能。 我把他定义为一个快速、轻量级 WEB 框架；没有过多的依赖，核心 jar 包仅 30KB。 也仅需要一行代码即可启动一个 HTTP 服务。 特性现在来谈谈重要的几个特性。 当前版本主要实现了基本的请求、响应、自定义参数以及拦截器功能。 功能虽少，但五脏俱全。 在今后的迭代过程中会逐渐完善上图功能，有好的想法也欢迎提 https://github.com/crossoverJie/cicada/issues。 快速启动下面来看看如何快速启动一个 HTTP 服务。 只需要创建一个 Maven 项目，并引入核心包。 12345&lt;dependency&gt; &lt;groupId&gt;top.crossoverjie.opensource&lt;/groupId&gt; &lt;artifactId&gt;cicada-core&lt;/artifactId&gt; &lt;version&gt;1.0.1&lt;/version&gt;&lt;/dependency&gt; 如上图所示，再配置一个启动类即可。 123456public class MainStart &#123; public static void main(String[] args) throws InterruptedException &#123; CicadaServer.start(MainStart.class,"/cicada-example") ; &#125;&#125; 配置业务 Action当然我们还需要一个实现业务逻辑的地方。cicada 提供了一个接口，只需要实现该接口即可实现具体逻辑。 创建业务 Action 实现 top.crossoverjie.cicada.server.action.WorkAction 接口。 123456789101112131415161718192021222324@CicadaAction(value = "demoAction")public class DemoAction implements WorkAction &#123; private static final Logger LOGGER = LoggerBuilder.getLogger(DemoAction.class) ; private static AtomicLong index = new AtomicLong() ; @Override public WorkRes&lt;DemoResVO&gt; execute(Param paramMap) throws Exception &#123; String name = paramMap.getString("name"); Integer id = paramMap.getInteger("id"); LOGGER.info("name=[&#123;&#125;],id=[&#123;&#125;]" , name,id); DemoResVO demoResVO = new DemoResVO() ; demoResVO.setIndex(index.incrementAndGet()); WorkRes&lt;DemoResVO&gt; res = new WorkRes(); res.setCode(StatusEnum.SUCCESS.getCode()); res.setMessage(StatusEnum.SUCCESS.getMessage()); res.setDataBody(demoResVO) ; return res; &#125;&#125; 同时需要再自定义类中加上 @CicadaAction 注解，并需要指定一个 value，该 value 主要是为了在请求路由时能找到业务类。 这样启动应用并访问 http://127.0.0.1:7317/cicada-example/demoAction?name=12345&amp;id=10 便能执行业务逻辑同时得到服务端的返回。 目前默认支持的是 json 响应，后期也会加上模板解析。 服务中也会打印相关日志。 灵活的参数配置这里所有的请求参数都封装在 Param 中，可以利用其中的各种 API 获取请求数据。 之所以是灵活的：我们甚至可以这样请求： 1234http://127.0.0.1:7317/cicada-example/demoAction?jsonData=&quot;info&quot;: &#123; &quot;age&quot;: 22, &quot;name&quot;: &quot;zhangsan&quot; &#125; 这样就可以传递任意结构的数据，只要业务处理时进行解析即可。 自定义拦截器拦截器是一个框架的基本功能，可以利用拦截器实现日志记录、事务提交等通用工作。 为此 cicada 提供一个接口: top.crossoverjie.cicada.server.intercept.CicadaInterceptor。 我们只需要实现该接口即可编写拦截功能： 123456789101112131415161718192021@Interceptor(value = "executeTimeInterceptor")public class ExecuteTimeInterceptor implements CicadaInterceptor &#123; private static final Logger LOGGER = LoggerBuilder.getLogger(ExecuteTimeInterceptor.class); private Long start; private Long end; @Override public void before(Param param) &#123; start = System.currentTimeMillis(); &#125; @Override public void after(Param param) &#123; end = System.currentTimeMillis(); LOGGER.info("cast [&#123;&#125;] times", end - start); &#125;&#125; 这里演示的是记录所有 action 的执行时间。 目前默认只实现了 action 的拦截，后期也会加入自定义拦截器。 拦截适配器虽说在拦截器中提供了 before/after 两个方法，但也不是所有的方法都需要实现。 因此 cicada 提供了一个适配器： top.crossoverjie.cicada.server.intercept.AbstractCicadaInterceptorAdapter 我们需要继承他便可按需实现其中的某个方法，如下所示： 1234567891011@Interceptor(value = "loggerInterceptor")public class LoggerInterceptorAbstract extends AbstractCicadaInterceptorAdapter &#123; private static final Logger LOGGER = LoggerBuilder.getLogger(LoggerInterceptorAbstract.class) ; @Override public void before(Param param) &#123; LOGGER.info("logger param=[&#123;&#125;]",param.toString()); &#125;&#125; 性能测试既然是一个 HTTP 服务框架，那性能自然也得保证。 在测试条件为：300 并发连续压测两轮；1G 内存、单核 CPU、1Mbps。用 Jmeter 压测情况如下： 同样的服务器用 Tomcat 来压测看看结果。 Tomcat 的线程池配置: 12&lt;Executor name="tomcatThreadPool" namePrefix="consumer-exec-" maxThreads="510" minSpareThreads="10"/&gt; 我这里请求的是 Tomcat 的一个 doc 目录，虽说结果看似 cicada 的性能比 Tomcat 还强。 但其实这个对比过程中的变量并没有完全控制好，Tomcat 所返回的是 HTML，而 cicada 仅仅返回了 json，当然问题也不止这些。 但还是能说明 cicada 目前的性能还是不错的。 总结本文没有过多讨论 cicada 实现原理，感兴趣的可以看看源码，都比较简单。 在后续的更新中会仔细探讨这块内容。 同时不出意外 cicada 会持续更新，未来也会加入更多实用的功能。 甚至我会在适当的时机将它应用于我的生产项目，也希望更多朋友能参与进来一起把这个「轮子」做的更好。 项目地址：https://github.com/crossoverJie/cicada 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>cicada</category>
        <category>轮子</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>HTTP</tag>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强如 Disruptor 也发生内存溢出？]]></title>
    <url>%2F2018%2F08%2F29%2Fjava-senior%2FOOM-Disruptor%2F</url>
    <content type="text"><![CDATA[前言OutOfMemoryError 问题相信很多朋友都遇到过，相对于常见的业务异常（数组越界、空指针等）来说这类问题是很难定位和解决的。 本文以最近碰到的一次线上内存溢出的定位、解决问题的方式展开；希望能对碰到类似问题的同学带来思路和帮助。 主要从表现--&gt;排查--&gt;定位--&gt;解决 四个步骤来分析和解决问题。 表象最近我们生产上的一个应用不断的爆出内存溢出，并且随着业务量的增长出现的频次越来越高。 该程序的业务逻辑非常简单，就是从 Kafka 中将数据消费下来然后批量的做持久化操作。 而现象则是随着 Kafka 的消息越多，出现的异常的频次就越快。由于当时还有其他工作所以只能让运维做重启，并且监控好堆内存以及 GC 情况。 重启大法虽好，可是依然不能根本解决问题。 排查于是我们想根据运维之前收集到的内存数据、GC 日志尝试判断哪里出现问题。 结果发现老年代的内存使用就算是发生 GC 也一直居高不下，而且随着时间推移也越来越高。 结合 jstat 的日志发现就算是发生了 FGC 老年代也已经回收不了，内存已经到顶。 甚至有几台应用 FGC 达到了上百次，时间也高的可怕。 这说明应用的内存使用肯定是有问题的，有许多赖皮对象始终回收不掉。 定位由于生产上的内存 dump 文件非常大，达到了几十G。也是由于我们的内存设置太大有关。 所以导致想使用 MAT 分析需要花费大量时间。 因此我们便想是否可以在本地复现，这样就要好定位的多。 为了尽快的复现问题，我将本地应用最大堆内存设置为 150M。 然后在消费 Kafka 那里 Mock 为一个 while 循环一直不断的生成数据。 同时当应用启动之后利用 VisualVM 连上应用实时监控内存、GC 的使用情况。 结果跑了 10 几分钟内存使用并没有什么问题。根据图中可以看出，每产生一次 GC 内存都能有效的回收，所以这样并没有复现问题。 没法复现问题就很难定位了。于是我们 review 代码，发现生产的逻辑和我们用 while 循环 Mock 数据还不太一样。 查看生产的日志发现每次从 Kafka 中取出的都是几百条数据，而我们 Mock 时每次只能产生一条。 为了尽可能的模拟生产情况便在服务器上跑着一个生产者程序，一直源源不断的向 Kafka 中发送数据。 果然不出意外只跑了一分多钟内存就顶不住了，观察左图发现 GC 的频次非常高，但是内存的回收却是相形见拙。 同时后台也开始打印内存溢出了，这样便复现出问题。 解决从目前的表现来看就是内存中有许多对象一直存在强引用关系导致得不到回收。 于是便想看看到底是什么对象占用了这么多的内存，利用 VisualVM 的 HeapDump 功能可以立即 dump 出当前应用的内存情况。 结果发现 com.lmax.disruptor.RingBuffer 类型的对象占用了将近 50% 的内存。 看到这个包自然就想到了 Disruptor 环形队列。 再次 review 代码发现：从 Kafka 里取出的 700 条数据是直接往 Disruptor 里丢的。 这里也就能说明为什么第一次模拟数据没复现问题了。 模拟的时候是一个对象放进队列里，而生产的情况是 700 条数据放进队列里。这个数据量是 700 倍的差距。 而 Disruptor 作为一个环形队列，再对象没有被覆盖之前是一直存在的。 我也做了一个实验，证明确实如此。 我设置队列大小为 8 ，从 0~9 往里面写 10 条数据，当写到 8 的时候就会把之前 0 的位置覆盖掉，后面的以此类推（类似于 HashMap 的取模定位）。 所以在生产上假设我们的队列大小是 1024，那么随着系统的运行最终肯定会导致 1024 个位置上装满了对象，而且每个位置是 700 个！ 于是查看了生产上 Disruptor 的 RingBuffer 配置，结果是：1024*1024。 这个数量级就非常吓人了。 为了验证是否是这个问题，我在本地将该值换为 2 ，一个最小值试试。 同样的 128M 内存，也是通过 Kafka 一直源源不断的取出数据。通过监控如下： 跑了 20 几分钟系统一切正常，每当一次 GC 都能回收大部分内存，最终呈现锯齿状。 这样问题就找到了，不过生产上这个值具体设置多少还得根据业务情况测试才能知道，但原有的 1024*1024 是绝对不能再使用了。 总结虽然到了最后也就改了一行代码(还没改，直接修改配置)，但这排查过程我觉得是有意义的。 也会让大部分觉得 JVM 这样的黑盒难以下手的同学有一个直观的感受。 同时也得感叹 Disruptor 东西虽好，也不能乱用哦！ 相关演示代码查看： https://github.com/crossoverJie/JCSprout/tree/master/src/main/java/com/crossoverjie/disruptor 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>concurrent</tag>
        <tag>JVM</tag>
        <tag>OOM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式(一) 搞定服务注册与发现]]></title>
    <url>%2F2018%2F08%2F27%2Fdistributed%2Fdistributed-discovery-zk%2F</url>
    <content type="text"><![CDATA[背景最近在做分布式相关的工作，由于人手不够只能我一个人来怼；看着这段时间的加班表想想就是够惨的。 不过其中也有遇到的不少有意思的事情今后再拿来分享，今天重点来讨论服务的注册与发现。 分布式带来的问题我的业务比较简单，只是需要知道现在有哪些服务实例可供使用就可以了（并不是做远程调用，只需要拿到信息即可）。 要实现这一功能最简单的方式可以在应用中配置所有的服务节点，这样每次在使用时只需要通过某种算法从配置列表中选择一个就可以了。 但这样会有一个非常严重的问题： 由于应用需要根据应用负载情况来灵活的调整服务节点的数量，这样我的配置就不能写死。 不然就会出现要么新增的节点没有访问或者是已经 down 掉的节点却有请求，这样肯定是不行的。 往往要解决这类分布式问题都需要一个公共的区域来保存这些信息，比如是否可以利用 Redis？ 每个节点启动之后都向 Redis 注册信息，关闭时也删除数据。 其实就是存放节点的 ip + port，然后在需要知道服务节点信息时候只需要去 Redis 中获取即可。 如下图所示： 但这样会导致每次使用时都需要频繁的去查询 Redis，为了避免这个问题我们可以在每次查询之后在本地缓存一份最新的数据。这样优先从本地获取确实可以提高效率。 但同样又会出现新的问题，如果服务提供者的节点新增或者删除消费者这边根本就不知道情况。 要解决这个问题最先想到的应该就是利用定时任务定期去更新服务列表。 以上的方案肯定不完美，并且不优雅。主要有以下几点： 基于定时任务会导致很多无效的更新。 定时任务存在周期性，没法做到实时，这样就可能存在请求异常。 如果服务被强行 kill，没法及时清除 Redis，这样这个看似可用的服务将永远不可用！ 所以我们需要一个更加靠谱的解决方案，这样的场景其实和 Dubbo 非常类似。 用过的同学肯定对这张图不陌生。 引用自 Dubbo 官网 其中有一块非常核心的内容（红框出）就是服务的注册与发现。 通常来说消费者是需要知道服务提供者的网络地址(ip + port)才能发起远程调用，这块内容和我上面的需求其实非常类似。 而 Dubbo 则是利用 Zookeeper 来解决问题。 Zookeeper 能做什么在具体讨论怎么实现之前先看看 Zookeeper 的几个重要特性。 Zookeeper 实现了一个类似于文件系统的树状结构： 这些节点被称为 znode(名字叫什么不重要)，其中每个节点都可以存放一定的数据。 最主要的是 znode 有四种类型： 永久节点（除非手动删除，节点永远存在） 永久有序节点（按照创建顺序会为每个节点末尾带上一个序号如：root-1） 瞬时节点（创建客户端与 Zookeeper 保持连接时节点存在，断开时则删除并会有相应的通知） 瞬时有序节点（在瞬时节点的基础上加上了顺序） 考虑下上文使用 Redis 最大的一个问题是什么？ 其实就是不能实时的更新服务提供者的信息。 那利用 Zookeeper 是怎么实现的？ 主要看第三个特性：瞬时节点 Zookeeper 是一个典型的观察者模式。 由于瞬时节点的特点，我们的消费者可以订阅瞬时节点的父节点。 当新增、删除节点时所有的瞬时节点也会自动更新。 更新时会给订阅者发起通知告诉最新的节点信息。 这样我们就可以实时获取服务节点的信息，同时也只需要在第一次获取列表时缓存到本地；也不需要频繁和 Zookeeper 产生交互，只用等待通知更新即可。 并且不管应用什么原因节点 down 掉后也会在 Zookeeper 中删除该信息。 效果演示这样实现方式就变为这样。 为此我新建了一个应用来进行演示： https://github.com/crossoverJie/netty-action/tree/master/netty-action-zk 就是一个简单的 SpringBoot 应用，只是做了几件事情。 应用启动时新开一个线程用于向 Zookeeper 注册服务。 同时监听一个节点用于更新本地服务列表。 提供一个接口用于返回一个可有的服务节点。 我在本地启动了两个应用分别是：127.0.0.1:8083,127.0.0.1:8084。来看看效果图。 两个应用启动完成： 当前 Zookeeper 的可视化树状结构： 当想知道所有的服务节点信息时： 想要获取一个可用的服务节点时： 这里只是采取了简单的轮询。 当 down 掉一个节点时：应用会收到通知更新本地缓存。同时 Zookeeper 中的节点会自动删除。 再次获取最新节点时： 当节点恢复时自然也能获取到最新信息。本地缓存也会及时更新。 编码实现实现起来倒也比较简单，主要就是 ZKClient 的 api 使用。 贴几段比较核心的吧。 注册 启动注册 Zookeeper。 主要逻辑都在这个线程中。 首先创建父节点。如上图的 Zookeeper 节点所示；需要先创建 /route 根节点，创建的时候会判断是否已经存在。 接着需要判断是否需要将自己注册到 Zookeeper 中，因为有些节点只是用于服务发现，他自身是不需要承担业务功能（是我自己项目的需求）。 将当前应用的所在 ip 以及端口注册上去，同时需要监听根节点 /route ，这样才能在其他服务上下线时候获得通知。 根据本地缓存 监听到服务变化 12345678910111213public void subscribeEvent(String path) &#123; zkClient.subscribeChildChanges(path, new IZkChildListener() &#123; @Override public void handleChildChange(String parentPath, List&lt;String&gt; currentChilds) throws Exception &#123; logger.info("清除/更新本地缓存 parentPath=【&#123;&#125;】,currentChilds=【&#123;&#125;】", parentPath,currentChilds.toString()); //更新所有缓存/先删除 再新增 serverCache.updateCache(currentChilds) ; &#125; &#125;);&#125; 可以看到这里是更新了本地缓存，该缓存采用了 Guava 提供的 Cache，感兴趣的可以查看之前的源码分析。 123456789101112/** * 更新所有缓存/先删除 再新增 * * @param currentChilds */public void updateCache(List&lt;String&gt; currentChilds) &#123; cache.invalidateAll(); for (String currentChild : currentChilds) &#123; String key = currentChild.split("-")[1]; addCache(key); &#125;&#125; 客户端负载 同时在客户端提供了一个负载算法。 其实就是一个轮询的实现： 1234567891011121314151617/** * 选取服务器 * * @return */public String selectServer() &#123; List&lt;String&gt; all = getAll(); if (all.size() == 0) &#123; throw new RuntimeException("路由列表为空"); &#125; Long position = index.incrementAndGet() % all.size(); if (position &lt; 0) &#123; position = 0L; &#125; return all.get(position.intValue());&#125; 当然这里可以扩展出更多的如权重、随机、LRU 等算法。 Zookeeper 其他优势及问题Zookeeper 自然是一个很棒的分布式协调工具，利用它的特性还可以有其他作用。 数据变更发送通知这一特性可以实现统一配置中心，再也不需要在每个服务中单独维护配置。 利用瞬时有序节点还可以实现分布式锁。 在实现注册、发现这一需求时，Zookeeper 其实并不是最优选。 由于 Zookeeper 在 CAP 理论中选择了 CP（一致性、分区容错性），当 Zookeeper 集群有半数节点不可用时是不能获取到任何数据的。 对于一致性来说自然没啥问题，但在注册、发现的场景下更加推荐 Eureka，已经在 SpringCloud 中得到验证。具体就不在本文讨论了。 但鉴于我的使用场景来说 Zookeeper 已经能够胜任。 总结本文所有完整代码都托管在 GitHub。 https://github.com/crossoverJie/netty-action。 一个看似简单的注册、发现功能实现了，但分布式应用远远不止这些。 由于网络隔离之后带来的一系列问题还需要我们用其他方式一一完善；后续会继续更新分布式相关内容，感兴趣的朋友不妨持续关注。 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么样的简历不会被丢进回收站]]></title>
    <url>%2F2018%2F08%2F21%2Fskill%2Fresume%2F</url>
    <content type="text"><![CDATA[前言从去年校招开始到现在负责部门的面试，从我手上流走的简历多多少少也有上百封了。 同时最近秋招又要开始了，就想着把我这一年来筛选简历的经验分享给大家，多少还是能提高一些命中率。 突出优势「简历」自然是突出简单的好，相信大部分面试官都不是全职做面试工作；多数都是工作之余筛选简历。 就我的情况来说，每天都需要在工作中挤出一部分时间从 10 几份简历中挑选出比较靠谱的。 总共大概花费 5 分钟的时间，平均算下来差不多一份简历只有 30S。现在我终于相信当初语文老师说：“高考语文作文阅卷只有几十秒的时间”。 既然时间很短，就需要像写作文一样突出亮点。 博客、GitHub举个例子，如果我在简历开头的个人介绍栏有看到个人博客、GitHub 链接等，一般都会点进去瞧瞧。 不知道是否是城市原因，我这里几乎 10 份简历中有两份贴有个人博客、1 份贴有 GitHub 链接。 哪怕里面的内容不是非常吸引人，但相比来说这样的简历会比其他多花上一些阅读时间，自然印象就更加深刻。 如果同时内容还非常不错，那就更是加分项了。 这就和上篇《如何成为一位「不那么差」的程序员》不谋而合： 项目特色通常简历的核心区域就是项目介绍。 这块我觉得可以适当减少项目具体的业务描述（自然不是不写），因为具体的项目了解一般会在简历评估通过后在面试中详聊。 所以这里我建议重点描述下自己解决了什么问题，优化了什么地方；比如： 解决了 XX 服务请求超时的问题。 优化了接口，将 QPS 由 1000 提升到了 5000 等等。 大概是这个方向的介绍。 需要避免同时简历中也有许多需要注意的地方。 首先是少用精通的字眼，真的精通也就算了，不然一定会被仔细询问。 再一个是基本错误尽量少出，比如这样的： 这是当时难得看到贴了 GitHub 地址，名字居然还写错。不过我还是点进去看了，也是没啥营养。 甚至之前还收到一封简历，最近一次的工作经历竟然是公司 CEO，但一看工作年纪也才 25 岁工作三年而已。 这样的描述就非常尴尬，建议如果是创业者的身份没什么问题。但这么大一个 title 显然不适合拿来面试。 还有就是附件格式，建议最好使用 PDF 这样通用的格式在所有的操作系统打开都没问题。 word 就非常容易出现变形，比如下面这样的我只能看到身高。 1~3 年由于现阶段我主要关注的是 1~5 年这个范围，通常也会分为两个阶段。 1~3 年多数是初中级岗位，这部分朋友我觉得应当把简历重心放在学习能力、积极主动性上面。 因为在项目经验并没有那么丰富，所有需要从其他方面体现出自己的优势。比如说扎实的基础。 3~5 年3~5 年一般是中高级岗位，这时我觉得需要突出自己解决问题的能力、设计产出方案这些技能表现出来。 同时最好在简历中体现出并发、多线程、分布式相关的经验。 最怕的就是这个阶段给人的感觉还是 1~3 年的水平，但要的薪资可是 N 倍。 总结最后推荐一个在线简历模板：http://cv.ftqq.com/ 。（不是广告，我个人也在用。easy 大佬看到了记得给我广告费。） 以上全是我个人主观感受，欢迎留言讨论。 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
      <tags>
        <tag>简历</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub 1W star 成就达成！]]></title>
    <url>%2F2018%2F08%2F17%2Fpersonal%2F1W-star%2F</url>
    <content type="text"><![CDATA[起因感谢各位大佬的支持收获了人生第一个（很有可能也是唯一一个）1W star 项目。 从今年一月份创建项目至今 8 个月时间。 一共关闭了 27 个 issue，47 个 RP，总共有 11 位小伙伴参与维护。 神奇般的连续两个月上了 GitHub Java 热门榜首。 整个热度走势图也是一路向北： 过程中也有许多朋友反馈得到了帮助，自己确实没想到能起到这么好的作用。 更名趁这机会我想给项目重新换个名字，因为我发现做到现在这里面并不仅仅包含面试的内容。 我们也不应该只为了面试而使用该项目，里面所有的技术内容我认为都应该对实际开发起到帮助，让大家少走弯路。 所有我把项目重命名为： JCSprout : Java Core Sprout：处于萌芽阶段的 Java 核心知识库。 还创建了 logo。 整个技术道路非常漫长，这一点小成就只是一颗小萌芽，希望最后能生根发芽。 未来今后我依然会持续维护，也希望更多的朋友参与进来。 还要把之前给自己挖的坑填好： HTTP SpringBoot Tomcat 等 后期还会继续添加一些源码解析、最佳实践等内容。 还没有关注的朋友难道不想进来看看嘛？最新地址： https://github.com/crossoverJie/JCSprout 你的点赞与转发是最大的支持。]]></content>
      <categories>
        <category>Person</category>
        <category>GitHub</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[如何成为一位「不那么差」的程序员]]></title>
    <url>%2F2018%2F08%2F12%2Fpersonal%2Fhow-to-be-developer%2F</url>
    <content type="text"><![CDATA[前言已经记不清有多少读者问过： 博主，你是怎么学习的？像我这样的情况有啥好的建议嘛？ 也不知道啥时候我居然成人生导师了。当然我不排斥这些问题，和大家交流都是学习的过程。 因此也许诺会准备一篇关于学习方面的文章；所以本文其实准备了很久，篇幅较长，大家耐心看完希望能有收获。 以下内容仅代表我从业以来所积累的相关经验，我会从硬技能、软实力这些方面尽量阐述我所认为的 “不那么差的程序员” 应当做到哪些技能。 技能树作为一名码代码的技术工人，怎么说干的还是技术活。 既然是技术活那专业实力就得过硬，下面我会按照相关类别谈谈我们应该掌握哪些。 计算机基础一名和电脑打交道的工种，计算机是我们赖以生存的工具。所以一些基础技能是我们应该和必须掌握的。 比如网络相关的知识。 其中就包含了 TCP 协议，它和 UDP 的差异。需要理解 TCP 三次握手的含义，拆、粘包等问题。 当然上层最常见的 HTTP 也需要了解，甚至是熟悉。 这块推荐《图解 HTTP》一书。 接着是操作系统相关知识。 由于工作后你写的大部分代码都是运行在 Linux 服务器上，所以对于这个看它脸色行事主你也得熟悉才行。 比如进程、线程、内存等概念；服务器常见的命令使用，这个没啥窍门就是得平时多敲敲多总结。 我也是之前兼职了半年运维才算是对这一块比较熟悉。 Linux 这个自然是推荐业界非常出名的《鸟哥的 Linux 私房菜》。 当作为一个初学者学习这些东西时肯定会觉得枯燥乏味，大学一般在讲专业课之前都会有这些基础学科。我相信大部分同学应该都没怎么仔细听讲，因为确实这些东西就算是学会了记熟了也没有太多直接的激励。 但当你工作几年之后会发现，只要你还在做计算机相关的工作，这些都是绕不开的，当哪天这些知识不经意的帮助到你时你会庆幸当初正确的选择。 数据结构与算法接下来会谈到另一门枯燥的课程：数据结构。 这块当初在大学时也是最不受待见的一门课程，也是我唯一挂过的科目。 记得当时每次上课老师就让大家用 C 语言练习书上的习题，看着一个个拆开都认识的字母组合在一起就六亲不认我果断选择了放弃。 这也造成现在的我每隔一段时间就要看二叉树、红黑树、栈、队列等知识，加深印象。 算法这个东西我确实没有啥发言权，之前坚持刷了部分 LeetCode 的题目也大多停留在初中级。 但像基本的查找、排序算法我觉得还是要会的，不一定要手写出来但要理解其思路。 所以强烈建议还在大学同学们积极参与一些 ACM 比赛，绝对是今后的加分利器。 这一块内容可能会在应届生校招时发挥较大作用，在工作中如果你的本职工作是 Java Web 开发的话，这一块涉猎的几率还是比较低。 不过一旦你接触到了模型设计、中间件、高效存储、查询等内容这些也是绕不过的坎。 这块内容和上面的计算机基础差不多，对于我们 Java 开发来说我觉得平时除了多刷刷 LeetCode 加深印象之外，在日常开发中每选择一个容器存放数据时想想为什么选它？有没有更好的存储方式？写入、查询效率如何？ 同样的坚持下去，今后肯定收货颇丰。 同时推荐《算法（第4版）》 Java 基础这里大部分的读者都是 Java 相关，所以这个强相关的技能非常重要。 Java 基础则是走向 Java 高级的必经之路。 这里抛开基本语法不谈，重点讨论实际工作中高频次的东西。 基本容器，如：HashMap、ArrayList、HashSet、LinkedList 等，不但要会用还得了解其中的原理。这样才能在不同的场景选择最优的设计。 IO、NIO 也是需要掌握。日常开发中大部分是在和磁盘、网络（写日志、数据库、Redis）打交道，这些都是 IO 的过程。 常见的设计模式如：代理、工厂、回调、构建者模式，这对开发灵活、扩展性强的应用有很大帮助。 Java 多线程是非常重要的特性，日常开发很多。能理解线程模型、多线程优缺点、以及如何避免。 良好的单测习惯，很多人觉得写单测浪费时间没有意义。但正是有了单测可以提前暴露出许多问题，减少测试返工几率，提高代码质量。 良好的编程规范，这个可以参考《阿里巴巴 Java 开发手册》以及在它基础上优化的《唯品会 Java 手册》 《Java核心技术·卷 I》值得推荐。 多线程应用有了扎实的基础之后来谈谈多线程、并发相关的内容。 想让自己的 title 里加上“高级”两字肯定得经过并发的洗礼。 这里谈论的并发主要是指单应用里的场景，多应用的可以看后文的分布式内容。 多线程的出现主要是为了提高 CPU 的利用率、任务的执行效率。但并不是用了多线程就一定能达到这样的效果，因为它同时也带来了一些问题： 上下文切换 共享资源 可见性、原子性、有序性等。 一旦使用了多线程那肯定会比单线程的程序要变得复杂和不可控，甚至使用不当还会比单线程慢。所以要考虑清楚是否真的需要多线程。 会用了之后也要考虑为啥多线程会出现那样的问题，这时就需要理解内存模型、可见性之类的知识点。 同样的解决方式又有哪些？各自的优缺点也需要掌握。 谈到多线程就不得不提并发包下面的内容 java.util.concurrent。 最常用及需要掌握的有： 原子类：用于并发场景的原子操作。 队列。常用于解耦，需要了解其实现原理。 并发工具，如 ConcurrentHashMap、CountDownLatch 之类的工具使用以及原理。 线程池使用，以及相关原理。 锁相关内容：synchronized、ReentrantLock 的使用及原理。 这一块的内容可以然我们知道写 JDK 大牛处理并发的思路，对我们自己编写高质量的多线程程序也有很多帮助。 推荐《Java 并发编程的艺术》很好的并发入门书籍。 JVM 虚拟机想要深入 Java ，JVM 是不可或缺的。对于大部分工作 1~3 年的开发者来说直接接触这一些内容是比较少的。 到了 3~5 年这个阶段就必须得了解了，以下内容我觉得是必须要掌握的： JVM 内存划分，知道哪块内存存放哪些内容；线程安全与否；内存不够怎么处理等。 不同情况的内存溢出、栈溢出，以及定位解决方案。 分代的垃圾回收策略。 线上问题定位及相关解决方案。 一个类的加载、创建对象、垃圾回收、类卸载的整个过程。 掌握这些内容真的对实际分析问题起到巨大帮助。 对此强力推荐《深入理解Java虚拟机》，这本书反反复复看过好几遍，每个阶段阅读都有不同的收获。 数据库做 WEB 应用开发的同学肯定要和数据库打不少交道，而且通常来说一个系统最先出现瓶颈往往都是数据库，说数据库是压到系统的最后一根稻草一点也不为过。 所以对数据库的掌握也是非常有必要。拿互联网用的较多的 MySQL 数据库为例，一些必须掌握的知识点： 索引的数据结构及原理、哪些字段应当创建索引。 针对于一个慢 SQL 的优化思路。 数据库水平垂直拆分的方案，需要了解业界常用的 MyCAT、sharding-sphere 等中间件。 常规使用可以参考《阿里巴巴 Java 开发手册》中的数据库章节，想要深入了解 MySQL 那肯定得推荐经典的《高性能 MySQL》一书了。 分布式技术随着互联网的发展，传统的单体应用越来越不适合现有场景。 因此分布式技术出现了，这块涵盖的内容太多了，经验有限只能列举我日常使用到的一些内容： 首先是一些基础理论如：CAP 定理，知道分布式系统会带来的一些问题以及各个应用权衡的方式。 了解近些年大热的微服务相关定义、来源以及对比，有条件的可以阅读 martin fowler 的原文 Microservices，或者也可以搜索相关的国内翻译。 对 Dubbo、SpringCloud 等分布式框架的使用，最好是要了解原理。 接着要对分布式带来的问题提出解决方案。如分布式锁、分布式限流、分布式事务、分布式缓存、分布式 ID、消息中间件等。 也要了解一些分布式中的负载算法：权重、Hash、一致性 Hash、故障转移、LRU 等。 最好能做一个实践如：秒杀架构实践 之前有开源一个分布式相关解决组件： https://github.com/crossoverJie/distributed-redis-tool 同时推荐一本入门科普《大型网站技术架构》，出版时间有点早，从中可以学习一些思路。 懂点架构相信大家都有一个架构师的梦想。 架构师给人的感觉就是画画图纸，搭好架子，下面的人员来添砖加瓦最终产出。 但其实需要的内功也要非常深厚，就上面列举的样样需要掌握，底层到操作系统、算法；上层到应用、框架都需要非常精通。（PPT 架构师除外） 我自身参与架构经验也不多，所以只能提供有限的建议。 首先分布式肯定得掌握，毕竟现在大部分的架构都是基于分布式的。 这其中就得根据 CAP 理论结合项目情况来选择一致性还是可用性，同时如何做好适合现有团队的技术选型。 这里推荐下开涛老师的《亿级流量网站架构核心技术》，列举了很多架构实例，不过网上褒贬不一，但对于刚入门架构的能科普不少知识。 如何学习谈完了技能树，现在来聊聊如何学习，这也是被问的最多的一个话题。 而关于学习讨论的最多的也是看视频还是看书？ 视频不得不承认视频是获取知识最便捷的来源，毕竟包含了图、文、声。 大学几年时间其实我也没好好上专业课，我记得真正入门 Java 还是一个暑假花了两个月的时间天天在家里看 ”马士兵“ 老师的视频教程，当时的资源也很老了，记得好像是 07 年出的视频（用的还是 Google ）。 那段时间早起晚睡，每天学到东西之后马上实践，心里也很有成就感。后来开学之后一度成为同学们眼中的”学霸“人物。 现在打开我 12 年的电脑，硬盘里还躺着好几十 G 的教学视频。 看书工作后时间真的很宝贵，完全没有了学生生涯的想学就学的自由。所以现在我主要知识来源还是书籍。 这些是我最近看的书： 看书又会涉及到电子书和纸质书的区别，我个人比较喜欢纸质书。毕竟我可以方便的记笔记以及可以随时切换章节。最主要的还是从小养成的闻书香的习惯。 知识付费近几年知识付费越来越流行，许多大佬也加入了这个行列，人们也逐渐在习惯为知识去付费。 说实话写一好篇文章出一份视频都非常不容易，能有正向的激励，作者才能持续输出更好的内容。 这块我觉得国内做的比较好我也为之付费的有极客时间、大佬的知识星球等。 这三点没有绝对的好坏之分，其实可以看出我刚入门的时候看视频，工作之后看书及知识付费内容。 视频的好处是可以跟着里面老师的思路一步一步往下走，比较有音视频代入感强，就像学校老师讲课一样。 但由于内容较长使读者没法知晓其中的重点，甚至都不敢快进生怕错过了哪个重要知识，现在由于 IT 越来越火，网上的视频也很多导致质量参差不齐也不成体系。 而看书可以选择性的浏览自己感兴趣的章节，费解的内容也方便反复阅读 所以建议刚入门的同学可以看看视频跟着学，参与工作一段时间后可以尝试多看看书。 当然这不是绝对的，找到适合自己的学习方式就好。但不管是视频还是看书都要多做多实践。 打造个人品牌个人品牌看似很程序员这个职业不怎么沾边，但在现今的互联网时代对于每个人来说都很重要。 以往我们在写简历或是评估他人简历的时候往往不会想到去网络搜索他的个人信息，但在这个信息爆炸的时代你在网上留下的一点印记都能被发现。 博客因此我们需要维护好自己的名片，比如先搭建自己的个人博客。 博客的好处我也谈过几次了，前期关注人少没关系，重要的是坚持，当你写到 50、100篇文章后你会发现自己在这过程中一定是的到了提高。 GitHub第二点就和技术人比较相关了：参与维护好自己的 GitHub。 由于 GitHub 的特殊属性，维护好后可以更好的打造个人品牌。 Talk is cheap. Show me the code 可不是随便说说的。 想要维护好可以从几个方面着手： 参与他人的项目，不管是代码库还是知识库都可以，先融入进社区。 发起自己的开源项目，不管是平时开发过程中的小痛点，还是精心整理的知识点都可以。 但这过程中有几点还是要注意： 我们需要遵守 GitHub 的社交礼仪。能用英文尽量就用英文，特别是在国外厂库中。 尽量少 push 一些与代码工作无关的内容，我认为这并不能提高自己的品牌。 别去刷 star。这也是近期才流行起来，不知道为什么总有一些人会钻这种空子，刷起来的热度对自己并没有任何提高。 这里有一篇国外大佬写的 How to build your personal brand as a new developer : https://medium.freecodecamp.org/building-your-personal-brand-as-a-new-web-developer-f6d4150fd217 English 挺重要再来谈谈英语的重要性，我记得刚上大学时老师以及一些培训机构都会说： 别怕自己英语差就学不了编程，真正常用的就那些词语。 这句话虽没错，但英语在对 IT 这行来说还是有着极大的加分能力。 拿常见的 JDK 里的源码注释也是纯英文的，如果英语还不错的话，一些 Spring 的东西完全可以自学，直接去 Spring 官网就可以查看，甚至后面出的 SpringCloud，官方资料就是最好的教程。 再有就是平时查资料时，有条件的可以尝试用 Google + 英文 搜索，你会发现新的世界。 不然也不会有面向 Google/Stack Overflow 编程。 对于英语好的同学自然不怕，那不怎么好的咋办呢？ 比如我，但我在坚持以下几点： 所有的手机、电脑系统统统换成英语语言，养成习惯（不过也有尴尬的连菜单都找不到的情况）。 订阅一些英语周刊，比如 ”湾区日报“。 定期去类似于 https://medium.com/ 这样具有影响力的国外社区阅读文章。 虽然现在我也谈不上多好，但目前我也在努力，希望大家也一起坚持。 推荐一本近期在看的书《程序员的英语》。 保持竞争力技术这个行业发展迅速、变化太快，每年也都有无数相关行业毕业生加入竞争，稍不留神就会被赶上甚至超越。 所以我们无时无刻都得保持竞争力。 多的谈不上，我只能谈下目前我在做的事情： 打好基础。不是学了之后就忘了，需要不停的去看，巩固，基础是万变不离其宗的。 多看源码，了解原理，不要停留在调参侠的境界。 关注行业发展、新技术、新动态至少不能落伍了。 争取每周产出一篇技术相关文章。 积极参与开源项目。 思维导图 结合上文产出了一个思维导图更直观些。 总结本文结合了自身的一些经验列举了一些方法，不一定对每位都有效需要自行判断。 也反反复复写了差不多一周的时间，希望对在这条路上和正在路上的朋友们起到一些作用。 大部分都只是谈了个思路，其实每一项单聊都能写很多。每个点都有推荐一本书籍，有更好建议欢迎留言讨论。 上文大部分的知识点都有维护在 GitHub 上，感兴趣的朋友可以自行查阅： https://github.com/crossoverJie/JCSprout]]></content>
      <categories>
        <category>Person</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Netty(三) 什么是 TCP 拆、粘包？如何解决？]]></title>
    <url>%2F2018%2F08%2F03%2Fnetty%2FNetty(3)TCP-Sticky%2F</url>
    <content type="text"><![CDATA[前言记得前段时间我们生产上的一个网关出现了故障。 这个网关逻辑非常简单，就是接收客户端的请求然后解析报文最后发送短信。 但这个请求并不是常见的 HTTP ，而是利用 Netty 自定义的协议。 有个前提是：网关是需要读取一段完整的报文才能进行后面的逻辑。 问题是有天突然发现网关解析报文出错，查看了客户端的发送日志也没发现问题，最后通过日志发现收到了许多不完整的报文，有些还多了。 于是想会不会是 TCP 拆、粘包带来的问题，最后利用 Netty 自带的拆包工具解决了该问题。 这便有了此文。 TCP 协议问题虽然解决了，但还是得想想原因，为啥会这样？打破砂锅问到底才是一个靠谱的程序员。 这就得从 TCP 这个协议说起了。 TCP 是一个面向字节流的协议，它是性质是流式的，所以它并没有分段。就像水流一样，你没法知道什么时候开始，什么时候结束。 所以他会根据当前的套接字缓冲区的情况进行拆包或是粘包。 下图展示了一个 TCP 协议传输的过程： 发送端的字节流都会先传入缓冲区，再通过网络传入到接收端的缓冲区中，最终由接收端获取。 当我们发送两个完整包到接收端的时候： 正常情况会接收到两个完整的报文。 但也有以下的情况： 接收到的是一个报文，它是由发送的两个报文组成的，这样对于应用程序来说就很难处理了（这样称为粘包）。 还有可能出现上面这样的虽然收到了两个包，但是里面的内容却是互相包含，对于应用来说依然无法解析（拆包）。 对于这样的问题只能通过上层的应用来解决，常见的方式有： 在报文末尾增加换行符表明一条完整的消息，这样在接收端可以根据这个换行符来判断消息是否完整。 将消息分为消息头、消息体。可以在消息头中声明消息的长度，根据这个长度来获取报文（比如 808 协议）。 规定好报文长度，不足的空位补齐，取的时候按照长度截取即可。 以上的这些方式我们在 Netty 的 pipline 中里加入对应的解码器都可以手动实现。 但其实 Netty 已经帮我们做好了，完全可以开箱即用。 比如： LineBasedFrameDecoder 可以基于换行符解决。 DelimiterBasedFrameDecoder可基于分隔符解决。 FixedLengthFrameDecoder可指定长度解决。 字符串拆、粘包下面来模拟一下最简单的字符串传输。 还是在之前的 https://github.com/crossoverJie/netty-action 进行演示。 在 Netty 客户端中加了一个入口可以循环发送 100 条字符串报文到接收端： 12345678910111213141516171819202122232425262728293031323334353637383940/** * 向服务端发消息 字符串 * @param stringReqVO * @return */@ApiOperation("客户端发送消息，字符串")@RequestMapping(value = "sendStringMsg", method = RequestMethod.POST)@ResponseBodypublic BaseResponse&lt;NULLBody&gt; sendStringMsg(@RequestBody StringReqVO stringReqVO)&#123; BaseResponse&lt;NULLBody&gt; res = new BaseResponse(); for (int i = 0; i &lt; 100; i++) &#123; heartbeatClient.sendStringMsg(stringReqVO.getMsg()) ; &#125; // 利用 actuator 来自增 counterService.increment(Constants.COUNTER_CLIENT_PUSH_COUNT); SendMsgResVO sendMsgResVO = new SendMsgResVO() ; sendMsgResVO.setMsg("OK") ; res.setCode(StatusEnum.SUCCESS.getCode()) ; res.setMessage(StatusEnum.SUCCESS.getMessage()) ; return res ;&#125;/** * 发送消息字符串 * * @param msg */public void sendStringMsg(String msg) &#123; ByteBuf message = Unpooled.buffer(msg.getBytes().length) ; message.writeBytes(msg.getBytes()) ; ChannelFuture future = channel.writeAndFlush(message); future.addListener((ChannelFutureListener) channelFuture -&gt; LOGGER.info("客户端手动发消息成功=&#123;&#125;", msg));&#125; 服务端直接打印即可： 12345@Overrideprotected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception &#123; LOGGER.info("收到msg=&#123;&#125;", msg);&#125; 顺便提一下，这里加的有一个字符串的解码器：.addLast(new StringDecoder()) 其实就是把消息解析为字符串。 1234@Overrideprotected void decode(ChannelHandlerContext ctx, ByteBuf msg, List&lt;Object&gt; out) throws Exception &#123; out.add(msg.toString(charset));&#125; 在 Swagger 中调用了客户端的接口用于给服务端发送了 100 次消息： 正常情况下接收端应该打印 100 次 hello 才对，但是查看日志会发现： 收到的内容有完整的、多的、少的、拼接的；这也就对应了上面提到的拆包、粘包。 该怎么解决呢？这便可采用之前提到的 LineBasedFrameDecoder 利用换行符解决。 利用 LineBasedFrameDecoder 解决问题LineBasedFrameDecoder 解码器使用非常简单，只需要在 pipline 链条上添加即可。 123//字符串解析,换行防拆包.addLast(new LineBasedFrameDecoder(1024)).addLast(new StringDecoder()) 构造函数中传入了 1024 是指报的长度最大不超过这个值，具体可以看下文的源码分析。 然后我们再进行一次测试看看结果： 注意，由于 LineBasedFrameDecoder 解码器是通过换行符来判断的，所以在发送时，一条完整的消息需要加上 \n。 最终的结果： 仔细观察日志，发现确实没有一条被拆、粘包。 LineBasedFrameDecoder 的原理目的达到了，来看看它的实现原理： 第一步主要就是 findEndOfLine 方法去找到当前报文中是否存在分隔符，存在就会返回分隔符所在的位置。 判断是否需要丢弃，默认为 false ，第一次走这个逻辑（下文会判断是否需要改为 true）。 如果报文中存在换行符，就会将数据截取到那个位置。 如果不存在换行符（有可能是拆包、粘包），就看当前报文的长度是否大于预设的长度。大于则需要缓存这个报文长度，并将 discarding 设为 true。 如果是需要丢弃时，判断是否找到了换行符，存在则需要丢弃掉之前记录的长度然后截取数据。 如果没有找到换行符，则将之前缓存的报文长度进行累加，用于下次抛弃。 从这个逻辑中可以看出就是寻找报文中是否包含换行符，并进行相应的截取。 由于是通过缓冲区读取的，所以即使这次没有换行符的数据，只要下一次的报文存在换行符，上一轮的数据也不会丢。 高效的编码方式 Google Protocol上面提到的其实就是在解码中进行操作，我们也可以自定义自己的拆、粘包工具。 编解码的主要目的就是为了可以编码成字节流用于在网络中传输、持久化存储。 Java 中也可以实现 Serializable 接口来实现序列化，但由于它性能等原因在一些 RPC 调用中用的很少。 而 Google Protocol 则是一个高效的序列化框架，下面来演示在 Netty 中如何使用。 安装首先第一步自然是安装： 在官网下载对应的包。 本地配置环境变量： 当执行 protoc --version 出现以下结果表明安装成功： 定义自己的协议格式接着是需要按照官方要求的语法定义自己的协议格式。 比如我这里需要定义一个输入输出的报文格式： BaseRequestProto.proto: 12345678910111213syntax = "proto2";package protocol;option java_package = "com.crossoverjie.netty.action.protocol";option java_outer_classname = "BaseRequestProto";message RequestProtocol &#123; required int32 requestId = 2; required string reqMsg = 1; &#125; BaseResponseProto.proto: 12345678910111213syntax = "proto2";package protocol;option java_package = "com.crossoverjie.netty.action.protocol";option java_outer_classname = "BaseResponseProto";message ResponseProtocol &#123; required int32 responseId = 2; required string resMsg = 1; &#125; 再通过 1protoc --java_out=/dev BaseRequestProto.proto BaseResponseProto.proto protoc 命令将刚才定义的协议格式转换为 Java 代码，并生成在 /dev 目录。 只需要将生成的代码拷贝到我们的项目中，同时引入依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;3.4.0&lt;/version&gt;&lt;/dependency&gt; 利用 Protocol 的编解码也非常简单： 1234567891011121314151617181920212223242526272829303132333435public class ProtocolUtil &#123; public static void main(String[] args) throws InvalidProtocolBufferException &#123; BaseRequestProto.RequestProtocol protocol = BaseRequestProto.RequestProtocol.newBuilder() .setRequestId(123) .setReqMsg("你好啊") .build(); byte[] encode = encode(protocol); BaseRequestProto.RequestProtocol parseFrom = decode(encode); System.out.println(protocol.toString()); System.out.println(protocol.toString().equals(parseFrom.toString())); &#125; /** * 编码 * @param protocol * @return */ public static byte[] encode(BaseRequestProto.RequestProtocol protocol)&#123; return protocol.toByteArray() ; &#125; /** * 解码 * @param bytes * @return * @throws InvalidProtocolBufferException */ public static BaseRequestProto.RequestProtocol decode(byte[] bytes) throws InvalidProtocolBufferException &#123; return BaseRequestProto.RequestProtocol.parseFrom(bytes); &#125;&#125; 利用 BaseRequestProto 来做一个演示，先编码再解码最后比较最终的结果是否相同。答案肯定是一致的。 利用 protoc 命令生成的 Java 文件里已经帮我们把编解码全部都封装好了，只需要简单调用就行了。 可以看出 Protocol 创建对象使用的是构建者模式，对使用者来说清晰易读，更多关于构建器的内容可以参考这里。 更多关于 Google Protocol 内容请查看官方开发文档。 结合 NettyNetty 已经自带了对 Google protobuf 的编解码器，也是只需要在 pipline 中添加即可。 server 端： 123456789101112131415// google Protobuf 编解码.addLast(new ProtobufDecoder(BaseRequestProto.RequestProtocol.getDefaultInstance())).addLast(new ProtobufEncoder())``` 客户端：```java// google Protobuf 编解码.addLast(new ProtobufDecoder(BaseResponseProto.ResponseProtocol.getDefaultInstance())).addLast(new ProtobufEncoder()) 稍微注意的是，在构建 ProtobufDecoder 时需要显式指定解码器需要解码成什么类型。 我这里服务端接收的是 BaseRequestProto，客户端收到的是服务端响应的 BaseResponseProto 所以就设置了对应的实例。 同样的提供了一个接口向服务端发送消息，当服务端收到了一个特殊指令时也会向客户端返回内容： 12345678910111213@Overrideprotected void channelRead0(ChannelHandlerContext ctx, BaseRequestProto.RequestProtocol msg) throws Exception &#123; LOGGER.info("收到msg=&#123;&#125;", msg.getReqMsg()); if (999 == msg.getRequestId())&#123; BaseResponseProto.ResponseProtocol responseProtocol = BaseResponseProto.ResponseProtocol.newBuilder() .setResponseId(1000) .setResMsg("服务端响应") .build(); ctx.writeAndFlush(responseProtocol) ; &#125;&#125; 在 swagger 中调用相关接口： 在日志可以看到服务端收到了消息，同时客户端也收到了返回： 虽说 Netty 封装了 Google Protobuf 相关的编解码工具，其实查看它的编码工具就会发现也是利用上文提到的 api 实现的。 Protocol 拆、粘包Google Protocol 的使用确实非常简单，但还是有值的注意的地方，比如它依然会有拆、粘包问题。 不妨模拟一下： 连续发送 100 次消息看服务端收到的怎么样： 会发现服务端在解码的时候报错，其实就是被拆、粘包了。 这点 Netty 自然也考虑到了，所以已经提供了相关的工具。 123//拆包解码.addLast(new ProtobufVarint32FrameDecoder()).addLast(new ProtobufVarint32LengthFieldPrepender()) 只需要在服务端和客户端加上这两个编解码工具即可，再来发送一百次试试。 查看日志发现没有出现一次异常，100 条信息全部都接收到了。 这个编解码工具可以简单理解为是在消息体中加了一个 32 位长度的整形字段，用于表明当前消息长度。 总结网络这块同样是计算机的基础，由于近期在做相关的工作所以接触的比较多，也算是给大学补课了。 后面会接着更新 Netty 相关的内容，最后会产出一个高性能的 HTTP 以及 RPC 框架，敬请期待。 上文相关的代码： https://github.com/crossoverJie/netty-action 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>拆包</tag>
        <tag>粘包</tag>
        <tag>protobuf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅的使用和理解线程池]]></title>
    <url>%2F2018%2F07%2F29%2Fjava-senior%2FThreadPool%2F</url>
    <content type="text"><![CDATA[前言平时接触过多线程开发的童鞋应该都或多或少了解过线程池，之前发布的《阿里巴巴 Java 手册》里也有一条： 可见线程池的重要性。 简单来说使用线程池有以下几个目的： 线程是稀缺资源，不能频繁的创建。 解耦作用；线程的创建于执行完全分开，方便维护。 应当将其放入一个池子中，可以给其他任务进行复用。 线程池原理谈到线程池就会想到池化技术，其中最核心的思想就是把宝贵的资源放到一个池子中；每次使用都从里面获取，用完之后又放回池子供其他人使用，有点吃大锅饭的意思。 那在 Java 中又是如何实现的呢？ 在 JDK 1.5 之后推出了相关的 api，常见的创建线程池方式有以下几种： Executors.newCachedThreadPool()：无限线程池。 Executors.newFixedThreadPool(nThreads)：创建固定大小的线程池。 Executors.newSingleThreadExecutor()：创建单个线程的线程池。 其实看这三种方式创建的源码就会发现： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 实际上还是利用 ThreadPoolExecutor 类实现的。 所以我们重点来看下 ThreadPoolExecutor 是怎么玩的。 首先是创建线程的 api： 1ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) 这几个核心参数的作用： corePoolSize 为线程池的基本大小。 maximumPoolSize 为线程池最大线程大小。 keepAliveTime 和 unit 则是线程空闲后的存活时间。 workQueue 用于存放任务的阻塞队列。 handler 当队列和最大线程池都满了之后的饱和策略。 了解了这几个参数再来看看实际的运用。 通常我们都是使用: 1threadPool.execute(new Job()); 这样的方式来提交一个任务到线程池中，所以核心的逻辑就是 execute() 函数了。 在具体分析之前先了解下线程池中所定义的状态，这些状态都和线程的执行密切相关： RUNNING 自然是运行状态，指可以接受任务执行队列里的任务 SHUTDOWN 指调用了 shutdown() 方法，不再接受新任务了，但是队列里的任务得执行完毕。 STOP 指调用了 shutdownNow() 方法，不再接受新任务，同时抛弃阻塞队列里的所有任务并中断所有正在执行任务。 TIDYING 所有任务都执行完毕，在调用 shutdown()/shutdownNow() 中都会尝试更新为这个状态。 TERMINATED 终止状态，当执行 terminated() 后会更新为这个状态。 用图表示为： 然后看看 execute() 方法是如何处理的： 获取当前线程池的状态。 当前线程数量小于 coreSize 时创建一个新的线程运行。 如果当前线程处于运行状态，并且写入阻塞队列成功。 双重检查，再次获取线程状态；如果线程状态变了（非运行状态）就需要从阻塞队列移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。 如果当前线程池为空就新创建一个线程并执行。 如果在第三步的判断为非运行状态，尝试新建线程，如果失败则执行拒绝策略。 这里借助《聊聊并发》的一张图来描述这个流程： 如何配置线程流程聊完了再来看看上文提到了几个核心参数应该如何配置呢？ 有一点是肯定的，线程池肯定是不是越大越好。 通常我们是需要根据这批任务执行的性质来确定的。 IO 密集型任务：由于线程并不是一直在运行，所以可以尽可能的多配置线程，比如 CPU 个数 * 2 CPU 密集型任务（大量复杂的运算）应当分配较少的线程，比如 CPU 个数相当的大小。 当然这些都是经验值，最好的方式还是根据实际情况测试得出最佳配置。 优雅的关闭线程池有运行任务自然也有关闭任务，从上文提到的 5 个状态就能看出如何来关闭线程池。 其实无非就是两个方法 shutdown()/shutdownNow()。 但他们有着重要的区别： shutdown() 执行后停止接受新任务，会把队列的任务执行完毕。 shutdownNow() 也是停止接受新任务，但会中断所有的任务，将线程池状态变为 stop。 两个方法都会中断线程，用户可自行判断是否需要响应中断。 shutdownNow() 要更简单粗暴，可以根据实际场景选择不同的方法。 我通常是按照以下方式关闭线程池的： 123456789101112long start = System.currentTimeMillis();for (int i = 0; i &lt;= 5; i++) &#123; pool.execute(new Job());&#125;pool.shutdown();while (!pool.awaitTermination(1, TimeUnit.SECONDS)) &#123; LOGGER.info("线程还在执行。。。");&#125;long end = System.currentTimeMillis();LOGGER.info("一共处理了【&#123;&#125;】", (end - start)); pool.awaitTermination(1, TimeUnit.SECONDS) 会每隔一秒钟检查一次是否执行完毕（状态为 TERMINATED），当从 while 循环退出时就表明线程池已经完全终止了。 SpringBoot 使用线程池2018 年了，SpringBoot 盛行；来看看在 SpringBoot 中应当怎么配置和使用线程池。 既然用了 SpringBoot ，那自然得发挥 Spring 的特性，所以需要 Spring 来帮我们管理线程池： 12345678910111213141516171819202122@Configurationpublic class TreadPoolConfig &#123; /** * 消费队列线程 * @return */ @Bean(value = "consumerQueueThreadPool") public ExecutorService buildConsumerQueueThreadPool()&#123; ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat("consumer-queue-thread-%d").build(); ExecutorService pool = new ThreadPoolExecutor(5, 5, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5),namedThreadFactory,new ThreadPoolExecutor.AbortPolicy()); return pool ; &#125;&#125; 使用时： 12345678910111213@Resource(name = "consumerQueueThreadPool")private ExecutorService consumerQueueThreadPool;@Overridepublic void execute() &#123; //消费队列 for (int i = 0; i &lt; 5; i++) &#123; consumerQueueThreadPool.execute(new ConsumerQueueThread()); &#125;&#125; 其实也挺简单，就是创建了一个线程池的 bean，在使用时直接从 Spring 中取出即可。 监控线程池谈到了 SpringBoot，也可利用它 actuator 组件来做线程池的监控。 线程怎么说都是稀缺资源，对线程池的监控可以知道自己任务执行的状况、效率等。 关于 actuator 就不再细说了，感兴趣的可以看看这篇，有详细整理过如何暴露监控端点。 其实 ThreadPool 本身已经提供了不少 api 可以获取线程状态： 很多方法看名字就知道其含义，只需要将这些信息暴露到 SpringBoot 的监控端点中，我们就可以在可视化页面查看当前的线程池状态了。 甚至我们可以继承线程池扩展其中的几个函数来自定义监控逻辑： 看这些名称和定义都知道，这是让子类来实现的。 可以在线程执行前、后、终止状态执行自定义逻辑。 线程池隔离 线程池看似很美好，但也会带来一些问题。 如果我们很多业务都依赖于同一个线程池,当其中一个业务因为各种不可控的原因消耗了所有的线程，导致线程池全部占满。 这样其他的业务也就不能正常运转了，这对系统的打击是巨大的。 比如我们 Tomcat 接受请求的线程池，假设其中一些响应特别慢，线程资源得不到回收释放；线程池慢慢被占满，最坏的情况就是整个应用都不能提供服务。 所以我们需要将线程池进行隔离。 通常的做法是按照业务进行划分： 比如下单的任务用一个线程池，获取数据的任务用另一个线程池。这样即使其中一个出现问题把线程池耗尽，那也不会影响其他的任务运行。 hystrix 隔离这样的需求 Hystrix 已经帮我们实现了。 Hystrix 是一款开源的容错插件，具有依赖隔离、系统容错降级等功能。 下面来看看 Hystrix 简单的应用： 首先需要定义两个线程池，分别用于执行订单、处理用户。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/** * Function:订单服务 * * @author crossoverJie * Date: 2018/7/28 16:43 * @since JDK 1.8 */public class CommandOrder extends HystrixCommand&lt;String&gt; &#123; private final static Logger LOGGER = LoggerFactory.getLogger(CommandOrder.class); private String orderName; public CommandOrder(String orderName) &#123; super(Setter.withGroupKey( //服务分组 HystrixCommandGroupKey.Factory.asKey("OrderGroup")) //线程分组 .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey("OrderPool")) //线程池配置 .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withCoreSize(10) .withKeepAliveTimeMinutes(5) .withMaxQueueSize(10) .withQueueSizeRejectionThreshold(10000)) .andCommandPropertiesDefaults( HystrixCommandProperties.Setter() .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.THREAD)) ) ; this.orderName = orderName; &#125; @Override public String run() throws Exception &#123; LOGGER.info("orderName=[&#123;&#125;]", orderName); TimeUnit.MILLISECONDS.sleep(100); return "OrderName=" + orderName; &#125;&#125;/** * Function:用户服务 * * @author crossoverJie * Date: 2018/7/28 16:43 * @since JDK 1.8 */public class CommandUser extends HystrixCommand&lt;String&gt; &#123; private final static Logger LOGGER = LoggerFactory.getLogger(CommandUser.class); private String userName; public CommandUser(String userName) &#123; super(Setter.withGroupKey( //服务分组 HystrixCommandGroupKey.Factory.asKey("UserGroup")) //线程分组 .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey("UserPool")) //线程池配置 .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withCoreSize(10) .withKeepAliveTimeMinutes(5) .withMaxQueueSize(10) .withQueueSizeRejectionThreshold(10000)) //线程池隔离 .andCommandPropertiesDefaults( HystrixCommandProperties.Setter() .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.THREAD)) ) ; this.userName = userName; &#125; @Override public String run() throws Exception &#123; LOGGER.info("userName=[&#123;&#125;]", userName); TimeUnit.MILLISECONDS.sleep(100); return "userName=" + userName; &#125;&#125; api 特别简洁易懂，具体详情请查看官方文档。 然后模拟运行： 12345678910111213141516171819public static void main(String[] args) throws Exception &#123; CommandOrder commandPhone = new CommandOrder("手机"); CommandOrder command = new CommandOrder("电视"); //阻塞方式执行 String execute = commandPhone.execute(); LOGGER.info("execute=[&#123;&#125;]", execute); //异步非阻塞方式 Future&lt;String&gt; queue = command.queue(); String value = queue.get(200, TimeUnit.MILLISECONDS); LOGGER.info("value=[&#123;&#125;]", value); CommandUser commandUser = new CommandUser("张三"); String name = commandUser.execute(); LOGGER.info("name=[&#123;&#125;]", name);&#125; 运行结果： 可以看到两个任务分成了两个线程池运行，他们之间互不干扰。 获取任务任务结果支持同步阻塞和异步非阻塞方式，可自行选择。 它的实现原理其实容易猜到： 利用一个 Map 来存放不同业务对应的线程池。 通过刚才的构造函数也能证明： 还要注意的一点是： 自定义的 Command 并不是一个单例，每次执行需要 new 一个实例，不然会报 This instance can only be executed once. Please instantiate a new instance. 异常。 总结池化技术确实在平时应用广泛，熟练掌握能提高不少效率。 文末的 hystrix 源码： https://github.com/crossoverJie/Java-Interview/tree/master/src/main/java/com/crossoverjie/hystrix 最后插播个小广告： Java-Interview 截止目前将近 8K star。 这次定个小目标：争取冲击 1W star。 感谢各位老铁的支持与点赞。 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>ThreadPool</tag>
        <tag>Hystirx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap? ConcurrentHashMap? 相信看完这篇没人能难住你！]]></title>
    <url>%2F2018%2F07%2F23%2Fjava-senior%2FConcurrentHashMap%2F</url>
    <content type="text"><![CDATA[前言Map 这样的 Key Value 在软件开发中是非常经典的结构，常用于在内存中存放数据。 本篇主要想讨论 ConcurrentHashMap 这样一个并发容器，在正式开始之前我觉得有必要谈谈 HashMap，没有它就不会有后面的 ConcurrentHashMap。 HashMap众所周知 HashMap 底层是基于 数组 + 链表 组成的，不过在 jdk1.7 和 1.8 中具体实现稍有不同。 Base 1.71.7 中的数据结构图： 先来看看 1.7 中的实现。 这是 HashMap 中比较核心的几个成员变量；看看分别是什么意思？ 初始化桶大小，因为底层是数组，所以这是数组默认的大小。 桶最大值。 默认的负载因子（0.75） table 真正存放数据的数组。 Map 存放数量的大小。 桶大小，可在初始化时显式指定。 负载因子，可在初始化时显式指定。 重点解释下负载因子： 由于给定的 HashMap 的容量大小是固定的，比如默认初始化： 123456789101112131415161718public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);&#125;public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init();&#125; 给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量达到了 16 * 0.75 = 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。 因此通常建议能提前预估 HashMap 的大小最好，尽量的减少扩容带来的性能损耗。 根据代码可以看到其实真正存放数据的是 transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; 这个数组，那么它又是如何定义的呢？ Entry 是 HashMap 中的一个内部类，从他的成员变量很容易看出： key 就是写入时的键。 value 自然就是值。 开始的时候就提到 HashMap 是由数组和链表组成，所以这个 next 就是用于实现链表结构。 hash 存放的是当前 key 的 hashcode。 知晓了基本结构，那来看看其中重要的写入、获取函数： put 方法12345678910111213141516171819202122public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null;&#125; 判断当前数组是否需要初始化。 如果 key 为空，则 put 一个空值进去。 根据 key 计算出 hashcode。 根据计算出的 hashcode 定位出所在桶。 如果桶是一个链表则需要遍历判断里面的 hashcode、key 是否和传入 key 相等，如果相等则进行覆盖，并返回原来的值。 如果桶是空的，说明当前位置没有数据存入；新增一个 Entry 对象写入当前位置。 123456789101112131415void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 当调用 addEntry 写入 Entry 时需要判断是否需要扩容。 如果需要就进行两倍扩充，并将当前的 key 重新 hash 并定位。 而在 createEntry 中会将当前位置的桶传入到新建的桶中，如果当前桶有值就会在位置形成链表。 get 方法再来看看 get 函数： 123456789101112131415161718192021222324public V get(Object key) &#123; if (key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; 首先也是根据 key 计算出 hashcode，然后定位到具体的桶中。 判断该位置是否为链表。 不是链表就根据 key、key 的 hashcode 是否相等来返回值。 为链表则需要遍历直到 key 及 hashcode 相等时候就返回值。 啥都没取到就直接返回 null 。 Base 1.8不知道 1.7 的实现大家看出需要优化的点没有？ 其实一个很明显的地方就是： 当 Hash 冲突严重时，在桶上形成的链表会变的越来越长，这样在查询时的效率就会越来越低；时间复杂度为 O(N)。 因此 1.8 中重点优化了这个查询效率。 1.8 HashMap 结构图： 先来看看几个核心的成员变量： 12345678910111213141516171819202122232425262728static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16/** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/** * The load factor used when none specified in constructor. */static final float DEFAULT_LOAD_FACTOR = 0.75f;static final int TREEIFY_THRESHOLD = 8;transient Node&lt;K,V&gt;[] table;/** * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). */transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;/** * The number of key-value mappings contained in this map. */transient int size; 和 1.7 大体上都差不多，还是有几个重要的区别： TREEIFY_THRESHOLD 用于判断是否需要将链表转换为红黑树的阈值。 HashEntry 修改为 Node。 Node 的核心组成其实也是和 1.7 中的 HashEntry 一样，存放的都是 key value hashcode next 等数据。 再来看看核心方法。 put 方法 看似要比 1.7 的复杂，我们一步步拆解： 判断当前桶是否为空，空的就需要初始化（resize 中会判断是否进行初始化）。 根据当前 key 的 hashcode 定位到具体的桶中并判断是否为空，为空表明没有 Hash 冲突就直接在当前位置创建一个新桶即可。 如果当前桶有值（ Hash 冲突），那么就要比较当前桶中的 key、key 的 hashcode 与写入的 key 是否相等，相等就赋值给 e,在第 8 步的时候会统一进行赋值及返回。 如果当前桶为红黑树，那就要按照红黑树的方式写入数据。 如果是个链表，就需要将当前的 key、value 封装成一个新节点写入到当前桶的后面（形成链表）。 接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。 如果在遍历过程中找到 key 相同时直接退出遍历。 如果 e != null 就相当于存在相同的 key,那就需要将值覆盖。 最后判断是否需要进行扩容。 get 方法12345678910111213141516171819202122232425public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; get 方法看起来就要简单许多了。 首先将 key hash 之后取得所定位的桶。 如果桶为空则直接返回 null 。 否则判断桶的第一个位置(有可能是链表、红黑树)的 key 是否为查询的 key，是就直接返回 value。 如果第一个不匹配，则判断它的下一个是红黑树还是链表。 红黑树就按照树的查找方式返回值。 不然就按照链表的方式遍历匹配返回值。 从这两个核心方法（get/put）可以看出 1.8 中对大链表做了优化，修改为红黑树之后查询效率直接提高到了 O(logn)。 但是 HashMap 原有的问题也都存在，比如在并发场景下使用时容易出现死循环。 123456789final HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();for (int i = 0; i &lt; 1000; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; map.put(UUID.randomUUID().toString(), ""); &#125; &#125;).start();&#125; 但是为什么呢？简单分析下。 看过上文的还记得在 HashMap 扩容的时候会调用 resize() 方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key 时，计算出的 index 正好是环形链表的下标就会出现死循环。 如下图： 遍历方式还有一个值得注意的是 HashMap 的遍历方式，通常有以下几种： 123456789101112Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; entryIterator = map.entrySet().iterator(); while (entryIterator.hasNext()) &#123; Map.Entry&lt;String, Integer&gt; next = entryIterator.next(); System.out.println("key=" + next.getKey() + " value=" + next.getValue()); &#125; Iterator&lt;String&gt; iterator = map.keySet().iterator(); while (iterator.hasNext())&#123; String key = iterator.next(); System.out.println("key=" + key + " value=" + map.get(key)); &#125; 强烈建议使用第一种 EntrySet 进行遍历。 第一种可以把 key value 同时取出，第二种还得需要通过 key 取一次 value，效率较低。 简单总结下 HashMap：无论是 1.7 还是 1.8 其实都能看出 JDK 没有对它做任何的同步操作，所以并发会出问题，甚至 1.7 中出现死循环导致系统不可用（1.8 已经修复死循环问题）。 因此 JDK 推出了专项专用的 ConcurrentHashMap ，该类位于 java.util.concurrent 包下，专门用于解决并发问题。 坚持看到这里的朋友算是已经把 ConcurrentHashMap 的基础已经打牢了，下面正式开始分析。 ConcurrentHashMapConcurrentHashMap 同样也分为 1.7 、1.8 版，两者在实现上略有不同。 Base 1.7先来看看 1.7 的实现，下面是他的结构图： 如图所示，是由 Segment 数组、HashEntry 组成，和 HashMap 一样，仍然是数组加链表。 它的核心成员变量： 1234567/** * Segment 数组，存放数据时首先需要定位到具体的 Segment 中。 */final Segment&lt;K,V&gt;[] segments;transient Set&lt;K&gt; keySet;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; Segment 是 ConcurrentHashMap 的一个内部类，主要的组成如下： 12345678910111213141516 static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; // 和 HashMap 中的 HashEntry 作用一样，真正存放数据的桶 transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor; &#125; 看看其中 HashEntry 的组成： 和 HashMap 非常类似，唯一的区别就是其中的核心数据如 value ，以及链表都是 volatile 修饰的，保证了获取时的可见性。 原理上来说：ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment。 下面也来看看核心的 put get 方法。 put 方法1234567891011public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); return s.put(key, hash, value, false);&#125; 首先是通过 key 定位到 Segment，之后在对应的 Segment 中进行具体的 put。 12345678910111213141516171819202122232425262728293031323334353637383940414243final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; else &#123; if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; 虽然 HashEntry 中的 value 是用 volatile 关键词修饰的，但是并不能保证并发的原子性，所以 put 操作时仍然需要加锁处理。 首先第一步的时候会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 scanAndLockForPut() 自旋获取锁。 尝试自旋获取锁。 如果重试的次数达到了 MAX_SCAN_RETRIES 则改为阻塞锁获取，保证能获取成功。 再结合图看看 put 的流程。 将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry。 遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value。 不为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容。 最后会解除在 1 中所获取当前 Segment 的锁。 get 方法1234567891011121314151617public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; get 逻辑比较简单： 只需要将 Key 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上。 由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值。 ConcurrentHashMap 的 get 方法是非常高效的，因为整个过程都不需要加锁。 Base 1.81.7 已经解决了并发问题，并且能支持 N 个 Segment 这么多次数的并发，但依然存在 HashMap 在 1.7 版本中的问题。 那就是查询遍历链表效率太低。 因此 1.8 做了一些数据结构上的调整。 首先来看下底层的组成结构： 看起来是不是和 1.8 HashMap 结构类似？ 其中抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。 也将 1.7 中存放数据的 HashEntry 改为 Node，但作用都是相同的。 其中的 val next 都用了 volatile 修饰，保证了可见性。 put 方法重点来看看 put 函数： 根据 key 计算出 hashcode 。 判断是否需要进行初始化。 f 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。 如果都不满足，则利用 synchronized 锁写入数据。 如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。 get 方法 根据计算出来的 hashcode 寻址，如果就在桶上那么直接返回值。 如果是红黑树那就按照树的方式获取值。 就不满足那就按照链表的方式遍历获取值。 1.8 在 1.7 的数据结构上做了大的改动，采用红黑树之后可以保证查询效率（O(logn)），甚至取消了 ReentrantLock 改为了 synchronized，这样可以看出在新版的 JDK 中对 synchronized 优化是很到位的。 总结看完了整个 HashMap 和 ConcurrentHashMap 在 1.7 和 1.8 中不同的实现方式相信大家对他们的理解应该会更加到位。 其实这块也是面试的重点内容，通常的套路是： 谈谈你理解的 HashMap，讲讲其中的 get put 过程。 1.8 做了什么优化？ 是线程安全的嘛？ 不安全会导致哪些问题？ 如何解决？有没有线程安全的并发容器？ ConcurrentHashMap 是如何实现的？ 1.7、1.8 实现有何不同？为什么这么做？ 这一串问题相信大家仔细看完都能怼回面试官。 除了面试会问到之外平时的应用其实也蛮多，像之前谈到的 Guava 中 Cache 的实现就是利用 ConcurrentHashMap 的思想。 同时也能学习 JDK 作者大牛们的优化思路以及并发解决方案。 其实写这篇的前提是源于 GitHub 上的一个 Issues，也希望大家能参与进来，共同维护好这个项目。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>concurrent</tag>
        <tag>ConcurrentHashMap</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Guava 源码分析（Cache 原理【二阶段】）]]></title>
    <url>%2F2018%2F07%2F16%2Fguava%2Fguava-cache-2%2F</url>
    <content type="text"><![CDATA[前言在上文「Guava 源码分析（Cache 原理）」中分析了 Guava Cache 的相关原理。 文末提到了回收机制、移除时间通知等内容，许多朋友也挺感兴趣，这次就这两个内容再来分析分析。 在开始之前先补习下 Java 自带的两个特性，Guava 中都有具体的应用。 Java 中的引用首先是 Java 中的引用。 在之前分享过 JVM 是根据可达性分析算法找出需要回收的对象，判断对象的存活状态都和引用有关。 在 JDK1.2 之前这点设计的非常简单：一个对象的状态只有引用和没被引用两种区别。 这样的划分对垃圾回收不是很友好，因为总有一些对象的状态处于这两之间。 因此 1.2 之后新增了四种状态用于更细粒度的划分引用关系： 强引用（Strong Reference）:这种对象最为常见，比如 A a = new A();这就是典型的强引用；这样的强引用关系是不能被垃圾回收的。 软引用（Soft Reference）:这样的引用表明一些有用但不是必要的对象，在将发生垃圾回收之前是需要将这样的对象再次回收。 弱引用（Weak Reference）:这是一种比软引用还弱的引用关系，也是存放非必须的对象。当垃圾回收时，无论当前内存是否足够，这样的对象都会被回收。 虚引用（Phantom Reference）:这是一种最弱的引用关系，甚至没法通过引用来获取对象，它唯一的作用就是在被回收时可以获得通知。 事件回调事件回调其实是一种常见的设计模式，比如之前讲过的 Netty 就使用了这样的设计。 这里采用一个 demo，试下如下功能： Caller 向 Notifier 提问。 提问方式是异步，接着做其他事情。 Notifier 收到问题执行计算然后回调 Caller 告知结果。 在 Java 中利用接口来实现回调，所以需要定义一个接口： 12345678public interface CallBackListener &#123; /** * 回调通知函数 * @param msg */ void callBackNotify(String msg) ;&#125; Caller 中调用 Notifier 执行提问，调用时将接口传递过去： 1234567891011121314151617181920212223242526272829303132333435public class Caller &#123; private final static Logger LOGGER = LoggerFactory.getLogger(Caller.class); private CallBackListener callBackListener ; private Notifier notifier ; private String question ; /** * 使用 */ public void call()&#123; LOGGER.info("开始提问"); //新建线程，达到异步效果 new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; notifier.execute(Caller.this,question); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); LOGGER.info("提问完毕，我去干其他事了"); &#125; //隐藏 getter/setter &#125; Notifier 收到提问，执行计算（耗时操作），最后做出响应（回调接口，告诉 Caller 结果）。 12345678910111213141516public class Notifier &#123; private final static Logger LOGGER = LoggerFactory.getLogger(Notifier.class); public void execute(Caller caller, String msg) throws InterruptedException &#123; LOGGER.info("收到消息=【&#123;&#125;】", msg); LOGGER.info("等待响应中。。。。。"); TimeUnit.SECONDS.sleep(2); caller.getCallBackListener().callBackNotify("我在北京！"); &#125;&#125; 模拟执行： 123456789101112131415public static void main(String[] args) &#123; Notifier notifier = new Notifier() ; Caller caller = new Caller() ; caller.setNotifier(notifier) ; caller.setQuestion("你在哪儿！"); caller.setCallBackListener(new CallBackListener() &#123; @Override public void callBackNotify(String msg) &#123; LOGGER.info("回复=【&#123;&#125;】" ,msg); &#125; &#125;); caller.call();&#125; 最后执行结果： 123452018-07-15 19:52:11.105 [main] INFO c.crossoverjie.guava.callback.Caller - 开始提问2018-07-15 19:52:11.118 [main] INFO c.crossoverjie.guava.callback.Caller - 提问完毕，我去干其他事了2018-07-15 19:52:11.117 [Thread-0] INFO c.c.guava.callback.Notifier - 收到消息=【你在哪儿！】2018-07-15 19:52:11.121 [Thread-0] INFO c.c.guava.callback.Notifier - 等待响应中。。。。。2018-07-15 19:52:13.124 [Thread-0] INFO com.crossoverjie.guava.callback.Main - 回复=【我在北京！】 这样一个模拟的异步事件回调就完成了。 Guava 的用法Guava 就是利用了上文的两个特性来实现了引用回收及移除通知。 引用可以在初始化缓存时利用： CacheBuilder.weakKeys() CacheBuilder.weakValues() CacheBuilder.softValues() 来自定义键和值的引用关系。 在上文的分析中可以看出 Cache 中的 ReferenceEntry 是类似于 HashMap 的 Entry 存放数据的。 来看看 ReferenceEntry 的定义： 1234567891011121314151617181920212223242526272829303132333435363738394041424344 interface ReferenceEntry&lt;K, V&gt; &#123; /** * Returns the value reference from this entry. */ ValueReference&lt;K, V&gt; getValueReference(); /** * Sets the value reference for this entry. */ void setValueReference(ValueReference&lt;K, V&gt; valueReference); /** * Returns the next entry in the chain. */ @Nullable ReferenceEntry&lt;K, V&gt; getNext(); /** * Returns the entry's hash. */ int getHash(); /** * Returns the key for this entry. */ @Nullable K getKey(); /* * Used by entries that use access order. Access entries are maintained in a doubly-linked list. * New entries are added at the tail of the list at write time; stale entries are expired from * the head of the list. */ /** * Returns the time that this entry was last accessed, in ns. */ long getAccessTime(); /** * Sets the entry access time in ns. */ void setAccessTime(long time);&#125; 包含了很多常用的操作，如值引用、键引用、访问时间等。 根据 ValueReference&lt;K, V&gt; getValueReference(); 的实现： 具有强引用和弱引用的不同实现。 key 也是相同的道理： 当使用这样的构造方式时，弱引用的 key 和 value 都会被垃圾回收。 当然我们也可以显式的回收： 1234567891011121314151617/** * Discards any cached value for key &#123;@code key&#125;. * 单个回收 */void invalidate(Object key);/** * Discards any cached values for keys &#123;@code keys&#125;. * * @since 11.0 */void invalidateAll(Iterable&lt;?&gt; keys);/** * Discards all entries in the cache. */void invalidateAll(); 回调改造了之前的例子： 1234567891011121314loadingCache = CacheBuilder.newBuilder() .expireAfterWrite(2, TimeUnit.SECONDS) .removalListener(new RemovalListener&lt;Object, Object&gt;() &#123; @Override public void onRemoval(RemovalNotification&lt;Object, Object&gt; notification) &#123; LOGGER.info("删除原因=&#123;&#125;，删除 key=&#123;&#125;,删除 value=&#123;&#125;",notification.getCause(),notification.getKey(),notification.getValue()); &#125; &#125;) .build(new CacheLoader&lt;Integer, AtomicLong&gt;() &#123; @Override public AtomicLong load(Integer key) throws Exception &#123; return new AtomicLong(0); &#125; &#125;); 执行结果： 1234562018-07-15 20:41:07.433 [main] INFO c.crossoverjie.guava.CacheLoaderTest - 当前缓存值=0,缓存大小=12018-07-15 20:41:07.442 [main] INFO c.crossoverjie.guava.CacheLoaderTest - 缓存的所有内容=&#123;1000=0&#125;2018-07-15 20:41:07.443 [main] INFO c.crossoverjie.guava.CacheLoaderTest - job running times=102018-07-15 20:41:10.461 [main] INFO c.crossoverjie.guava.CacheLoaderTest - 删除原因=EXPIRED，删除 key=1000,删除 value=12018-07-15 20:41:10.462 [main] INFO c.crossoverjie.guava.CacheLoaderTest - 当前缓存值=0,缓存大小=12018-07-15 20:41:10.462 [main] INFO c.crossoverjie.guava.CacheLoaderTest - 缓存的所有内容=&#123;1000=0&#125; 可以看出当缓存被删除的时候会回调我们自定义的函数，并告知删除原因。 那么 Guava 是如何实现的呢？ 根据 LocalCache 中的 getLiveValue() 中判断缓存过期时，跟着这里的调用关系就会一直跟到： removeValueFromChain() 中的： enqueueNotification() 方法会将回收的缓存（包含了 key，value）以及回收原因包装成之前定义的事件接口加入到一个本地队列中。 这样一看也没有回调我们初始化时候的事件啊。 不过用过队列的同学应该能猜出，既然这里写入队列，那就肯定就有消费。 我们回到获取缓存的地方： 在 finally 中执行了 postReadCleanup() 方法；其实在这里面就是对刚才的队列进行了消费： 一直跟进来就会发现这里消费了队列，将之前包装好的移除消息调用了我们自定义的事件，这样就完成了一次事件回调。 总结以上所有源码： https://github.com/crossoverJie/Java-Interview/blob/master/src/main/java/com/crossoverjie/guava/callback/Main.java 通过分析 Guava 的源码可以让我们学习到顶级的设计及实现方式，甚至自己也能尝试编写。 Guava 里还有很多强大的增强实现，值得我们再好好研究。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次线上问题排查所引发的思考]]></title>
    <url>%2F2018%2F07%2F08%2Fjava-senior%2FJVM-Troubleshoot%2F</url>
    <content type="text"><![CDATA[前言之前或多或少分享过一些内存模型、对象创建之类的内容，其实大部分人看完都是懵懵懂懂，也不知道这些的实际意义。 直到有一天你会碰到线上奇奇怪怪的问题，如： 线程执行一个任务迟迟没有返回，应用假死。 接口响应缓慢，甚至请求超时。 CPU 高负载运行。 这类问题并不像一个空指针、数组越界这样明显好查，这时就需要刚才提到的内存模型、对象创建、线程等相关知识结合在一起来排查问题了。 正好这次借助之前的一次生产问题来聊聊如何排查和解决问题。 生产现象首先看看问题的背景吧： 我这其实是一个定时任务，在固定的时间会开启 N 个线程并发的从 Redis 中获取数据进行运算。 业务逻辑非常简单，但应用一般涉及到多线程之后再简单的事情都要小心对待。 果不其然这次就出问题了。 现象:原本只需要执行几分钟的任务执行了几个小时都没退出。翻遍了所有的日志都没找到异常。 于是便开始定位问题之路。 定位问题既然没办法直接从日志中发现异常，那就只能看看应用到底在干嘛了。 最常见的工具就是 JDK 自带的那一套。 这次我使用了 jstack 来查看线程的执行情况，它的作用其实就是 dump 当前的线程堆栈。 当然在 dump 之前是需要知道我应用的 pid 的，可以使用 jps -v 这样的方式列出所有的 Java 进程。 当然如果知道关键字的话直接使用 ps aux|grep java 也是可以的。 拿到 pid=1523 了之后就可以利用 jstack 1523 &gt; 1523.log 这样的方式将 dump 文件输出到日志文件中。 如果应用简单不复杂，线程这些也比较少其实可以直接打开查看。 但复杂的应用导出来的日志文件也比较大还是建议用专业的分析工具。 我这里的日志比较少直接打开就可以了。 因为我清楚知道应用中开启的线程名称，所以直接根据线程名就可以在日志中找到相关的堆栈： 所以通常建议大家线程名字给的有意义，在排查问题时很有必要。 其实其他几个线程都和这里的堆栈类似，很明显的看出都是在做 Redis 连接。 于是我登录 Redis 查看了当前的连接数，发现已经非常高了。 这样 Redis 的响应自然也就变慢了。 接着利用 jps -v 列出了当前所以在跑的 Java 进程，果不其然有好几个应用都在查询 Redis，而且都是并发连接，问题自然就找到了。 解决办法 所以问题的主要原因是：大量的应用并发查询 Redis，导致 Redis 的性能降低。 既然找到了问题，那如何解决呢？ 减少同时查询 Redis 的应用，分开时段降低 Redis 的压力。 将 Redis 复制几个集群，各个应用分开查询。但是这样会涉及到数据的同步等运维操作，或者由程序了进行同步也会增加复杂度。 目前我们选择的是第一个方案，效果很明显。 本地模拟上文介绍的是线程相关问题，现在来分析下内存的问题。 以这个类为例： https://github.com/crossoverJie/Java-Interview/blob/master/src/main/java/com/crossoverjie/oom/heap/HeapOOM.java 123456789public class HeapOOM &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(10) ; while (true)&#123; list.add("1") ; &#125; &#125;&#125; 启动参数如下： 1234-Xms20m-Xmx20m-XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=/Users/xx/Documents 为了更快的突出内存问题将堆的最大内存固定在 20M，同时在 JVM 出现 OOM 的时候自动 dump 内存到 /Users/xx/Documents(不配路径则会生成在当前目录)。 执行之后果不其然出现了异常： 同时对应的内存 dump 文件也生成了。 内存分析这时就需要相应的工具进行分析了，最常用的自然就是 MAT 了。 我试了一个在线工具也不错（文件大了就不适合了）： http://heaphero.io/index.jsp 上传刚才生成的内存文件之后： 因为是内存溢出，所以主要观察下大对象： 也有相应提示，这个很有可能就是内存溢出的对象，点进去之后： 看到这个堆栈其实就很明显了： 在向 ArrayList 中不停的写入数据时，会导致频繁的扩容也就是数组复制这些过程，最终达到 20M 的上限导致内存溢出了。 更多建议上文说过，一旦使用了多线程，那就要格外小心。 以下是一些日常建议： 尽量不要在线程中做大量耗时的网络操作，如查询数据库（可以的话在一开始就将数据从从 DB 中查出准备好）。 尽可能的减少多线程竞争锁。可以将数据分段，各个线程分别读取。 多利用 CAS+自旋 的方式更新数据，减少锁的使用。 应用中加上 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp 参数，在内存溢出时至少可以拿到内存日志。 线程池监控。如线程池大小、队列大小、最大线程数等数据，可提前做好预估。 JVM 监控，可以看到堆内存的涨幅趋势，GC 曲线等数据，也可以提前做好准备。 总结线上问题定位需要综合技能，所以是需要一些基础技能。如线程、内存模型、Linux 等。 当然这些问题没有实操过都是纸上谈兵；如果第一次碰到线上问题，不要慌张，反而应该庆幸解决之后你又会习得一项技能。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>concurrent</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty(二) 从线程模型的角度看 Netty 为什么是高性能的？]]></title>
    <url>%2F2018%2F07%2F04%2Fnetty%2FNetty(2)Thread-model%2F</url>
    <content type="text"><![CDATA[前言在之前的 SpringBoot 整合长连接心跳机制 一文中认识了 Netty。 但其实只是能用，为什么要用 Netty？它有哪些优势？这些其实都不清楚。 本文就来从历史源头说道说道。 传统 IO在 Netty 以及 NIO 出现之前，我们写 IO 应用其实用的都是用 java.io.* 下所提供的包。 比如下面的伪代码： 123456789ServeSocket serverSocket = new ServeSocket(8080);Socket socket = serverSocket.accept() ;BufferReader in = .... ;String request ; while((request = in.readLine()) != null)&#123; new Thread(new Task()).start()&#125; 大概是这样，其实主要想表达的是：这样一个线程只能处理一个连接。 如果是 100 个客户端连接那就得开 100 个线程，1000 那就得 1000 个线程。 要知道线程资源非常宝贵，每次的创建都会带来消耗，而且每个线程还得为它分配对应的栈内存。 即便是我们给 JVM 足够的内存，大量线程所带来的上下文切换也是受不了的。 并且传统 IO 是阻塞模式，每一次的响应必须的是发起 IO 请求，处理请求完成再同时返回，直接的结果就是性能差，吞吐量低。 Reactor 模型因此业界常用的高性能 IO 模型是 Reactor。 它是一种异步、非阻塞的事件驱动模型。 通常也表现为以下三种方式： 单线程 从图中可以看出： 它是由一个线程来接收客户端的连接，并将该请求分发到对应的事件处理 handler 中，整个过程完全是异步非阻塞的；并且完全不存在共享资源的问题。所以理论上来说吞吐量也还不错。 但由于是一个线程，对多核 CPU 利用率不高，一旦有大量的客户端连接上来性能必然下降，甚至会有大量请求无法响应。最坏的情况是一旦这个线程哪里没有处理好进入了死循环那整个服务都将不可用！ 多线程 因此产生了多线程模型。 其实最大的改进就是将原有的事件处理改为了多线程。 可以基于 Java 自身的线程池实现，这样在大量请求的处理上性能提示是巨大的。 虽然如此，但理论上来说依然有一个地方是单点的；那就是处理客户端连接的线程。 因为大多数服务端应用或多或少在连接时都会处理一些业务，如鉴权之类的，当连接的客户端越来越多时这一个线程依然会存在性能问题。 于是又有了下面的线程模型。 主从多线程 该模型将客户端连接那一块的线程也改为多线程，称为主线程。 同时也是多个子线程来处理事件响应，这样无论是连接还是事件都是高性能的。 Netty 实现以上谈了这么多其实 Netty 的线程模型与之的类似。 我们回到之前 SpringBoot 整合长连接心跳机制TCP-Heartbeat/) 中的服务端代码： 1234567891011121314151617181920212223242526private EventLoopGroup boss = new NioEventLoopGroup();private EventLoopGroup work = new NioEventLoopGroup();/** * 启动 Netty * * @return * @throws InterruptedException */@PostConstructpublic void start() throws InterruptedException &#123; ServerBootstrap bootstrap = new ServerBootstrap() .group(boss, work) .channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(nettyPort)) //保持长连接 .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new HeartbeatInitializer()); ChannelFuture future = bootstrap.bind().sync(); if (future.isSuccess()) &#123; LOGGER.info("启动 Netty 成功"); &#125;&#125; 其实这里的 boss 就相当于 Reactor 模型中处理客户端连接的线程池。 work 自然就是处理事件的线程池了。 那么如何来实现上文的三种模式呢？其实也很简单： 单线程模型： 1234private EventLoopGroup group = new NioEventLoopGroup();ServerBootstrap bootstrap = new ServerBootstrap() .group(group) .childHandler(new HeartbeatInitializer()); 多线程模型： 12345private EventLoopGroup boss = new NioEventLoopGroup(1);private EventLoopGroup work = new NioEventLoopGroup();ServerBootstrap bootstrap = new ServerBootstrap() .group(boss,work) .childHandler(new HeartbeatInitializer()); 主从多线程： 12345private EventLoopGroup boss = new NioEventLoopGroup();private EventLoopGroup work = new NioEventLoopGroup();ServerBootstrap bootstrap = new ServerBootstrap() .group(boss,work) .childHandler(new HeartbeatInitializer()); 相信大家一看也明白。 总结其实看过了 Netty 的线程模型之后能否对我们平时做高性能应用带来点启发呢？ 我认为是可以的： 接口同步转异步处理。 回调通知结果。 多线程提高并发效率。 无非也就是这些，只是做了这些之后就会带来其他问题： 异步之后事务如何保证？ 回调失败的情况？ 多线程所带来的上下文切换、共享资源的问题。 这就是一个博弈的过程，想要做到一个尽量高效的应用是需要不断磨合试错的。 上文相关的代码： https://github.com/crossoverJie/netty-action 欢迎关注公众号一起交流：]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个学渣的阿里之路]]></title>
    <url>%2F2018%2F06%2F21%2Fpersonal%2FInterview-experience%2F</url>
    <content type="text"><![CDATA[前言最近有些朋友在面试阿里，加上 Java-Interview 项目的原因也有小伙伴和我讨论，近期也在负责部门的招聘，这让我想起年初那段长达三个月的奇葩面试经历🤣。 本来没想拿出来说的，毕竟最后也没成。 但由于那几个月的经历让我了解到了大厂的工作方式、对候选同学的考察重点以及面试官的套路等都有了全新的认识。 当然最重要的是这段时间的查漏补缺也让自己精进不少。 先交代下背景吧： 从去年 12 月到今年三月底，我前前后后面了阿里三个部门。 其中两个部门通过了技术面试，还有一个跪在了三面。 光看结果还不错，但整个流程堪称曲折。 下面我会尽量描述流程以及大致的面试题目大纲，希望对想要跳槽、正在面试的同学带来点灵感，帮助可能谈不上，但启发还是能有。 以下内容较长，请再次备好瓜子板凳。 A 部门首先是第一次机会，去年 12 月份有位大佬加我，后来才知道是一个部门的技术 Leader 在网上看到我的博客，问我想不想来阿里试试。 这时距离上次面阿里也过去一年多了，也想看看现在几斤几两，于是便同意了。 在推荐一周之后收到了杭州打来的电话，说来也巧，那时候我正在机场候机，距离登记还有大概一个小时，心想时间肯定够了。 那是我时隔一年多第一次面试，还是在机场这样嘈杂的环境里。多多少少还是有些紧张。 一面以下是我印象比较深刻的内容： 面试官： 谈谈你做过项目中印象较深或自认为做的比较好的地方？ 博主： 我觉得我在 XX 做的不错，用了 XX 需求实现 XX 功能，性能提高了 N 倍。 面试官： 你说使用到了 AOP ，能谈谈它的实现原理嘛？ 博主： 它是依靠动态代理实现的，动态代理又分为 JDK 自身的以及 CGLIB 。。。。 面试官： 嗯，能说说他们的不同及优缺点嘛？ 博主： JDK 是基于接口实现，而 CGLIB 继承代理类。。。 就是这样会一直问下去，如果聊的差不多了就开始问一些零散的问题： JMM 内存模型，如何划分的？分别存储什么内容？线程安全与否？ 类加载机制，谈到双亲委派模型后会问到哪些违反了双亲委派模型？为什么？为什么要双亲委派？好处是什么？ 平时怎么使用多线程？有哪些好处？线程池的几个核心参数的意义？ 线程间通信的方式？ HashMap 的原理？当谈到线程不安全时自然引申出 ConcurrentHashMap ，它的实现原理？ 分库分表如何设计？垂直拆分、水平拆分？ 业务 ID 的生成规则，有哪些方式？ SQL 调优？平时使用数据库有哪些注意点？ 当一个应用启动缓慢如何优化？ 大概是以上这些，当聊到倒数第二个时我已经登机了。最后不得不提前挂断，结束之前告诉我之后会换一个同事和我沟通，听到这样的回复一面应该是过了，后面也确实证实了这点。 二面大概过了一周，二面如期而至。 我听声音很熟，就尝试问下是不是之前一面的面试官，结果真是。 由于二面的面试官临时有事所以他来替一下。于是我赶紧问他能否把之前答的不好的再说说？的到了肯定的答复后开始了我的表演。 有了第一次的经验这一次自然也轻车熟路，原本感觉一切尽在掌握却被告知需要笔试突然被激醒。 笔试是一个在线平台，需要在网页中写代码，会有一个明确的题目： 从一个日志文件中根据关键字读取日志，记录出现的次数，最后按照次数排序打印。 在这过程中切记要和面试官多多交流，因为笔试有时间限制，别到最后发现题目理解错了，这就和高考作文写完发现方向错了一样要命。 而且在沟通过程中体现出你解题的思路，即使最终结果不对，但说不定思考的过程很符合面试官的胃口哦。这也和今年的高考改卷一样；过程正确得高分，只有结果得低分。 三面又过了差不多一周的时间接到了三面的电话，一般到了三面会是技术 Leader 之类的角色。 这个过程中不会过多强调技术细节，更多的考察软件能，比如团队协作、学习能力等。 但我记得也问了以下一些技术问题： 谈谈你所理解的 HTTP 协议？ 对 TCP 的理解？三次握手？滑动窗口？ 基本算法，Base64 等。 Java 内存模型，Happen Before 的理解。 一周之后我接到了 HR 助理的电话约了和 HRBP 以及产品技术负责人的视频面试。 但是我却没有面下去，具体原因得往下看。 B 部门在 A 部门三面完成后，我等了差不多一星期，这期间我却收到了一封邮件。 大概内容是他在 GitHub 上看到的我，他们的技术总监对我很感兴趣（我都不敢相信我的眼镜），问我想不想来阿里试试。 我对比了 A B 部门的区别发现 B 部门在做的事情上确实更加有诱惑力，之后我表达了有一个面试正在流程中的顾虑；对方表示可以私下和我快速的进行三面，如果一切没问题再交由我自行选择。至少对双方都是一个双赢嘛。 我想也不亏，并且对方很有诚意，就答应试试；于是便有了下面的面试： 一面面试官： 对 Java 锁的理解？ 博主： 我谈到了 synchronize，Lock 接口的应用。 面试官： 他们两者的区别以及优缺点呢？ 博主： synchronize 在 JDK1.6 之前称为重量锁，是通过进出对象监视器来实现同步的；1.6 之后做了 XX 优化。。。 而 ReentrantLock 是利用了一个巧妙数据结构实现的，并且加锁解锁是显式的。。。 之后又引申到分布式锁，光这块就聊了差不多半个小时。 之后又聊到了我的开源项目： 是如何想做这个项目的？ 已经有一些关注了后续是如何规划的？ 你今后的学习计划是什么？ 平时看哪些书？ 之后技术聊的不是很多，但对于个人发展却聊了不少。 关于锁相关的内容可以参考这里：ReentrantLock 实现原理 synchronize 关键字原理 二面隔了差不多一天的时间，二面很快就来了。 内容不是很多： 线程间通信的多种方式？ 限流算法？单机限流？分布式限流？ 提到了 Guava Cache ,了解它的实现原理嘛？ 如何定位一个线上问题？ CPU 高负载？OOM 排查等？ 聊完之后表示第二天应该会有三面。 三面三面的面试官应该是之前邮件中提到的那位总监大佬，以前应该也是一线的技术大牛；聊的问题不是很多： 谈谈对 Netty 的理解？ Netty 的线程模型？ 写一个 LRU 缓存。 笔试本以为技术面试完了，结果后面告知所有的面试流程都得有笔试了，于是又参与了一次笔试： 交替打印奇偶数 这个相对比较简单，基于锁、等待唤醒机制都是可以的。最后也告知笔试通过。 之后在推荐我的那位大佬的帮助下戏剧般的通过了整个技术轮（真的很感谢他的认可），并且得知这个消息是在我刚好和 A 部门约好视频面试时间之后。 也就意味着我必须拒掉一个部门！ 没看错，是我要拒掉一个。这对我来说确实太难了，我压根没想过还有两个机会摆在我面前。 最后凭着个人的爱好以及 B 部门的热情我很不好意思的拒掉了 A 部门。。。 HR 面在面这之前我从来没有面过这样大厂的 HR 流程，于是疯狂搜索，希望能弥补点经验。 也许这就是乐极生悲吧，我确实猜中了 HR 问的大部分问题，但遗憾的是最终依然没能通过。 后来我在想如果我没有拒掉 A ，会不会结局不一样了？ 但现实就是如此，没有那么多假设，并且每个人也得为自己的选择负责！ 大概的问题是： 为什么想来阿里？ 个人做的最成功最有挑战的事情是什么？ 工作中最难忘的经历？ 对加入我们团队有何期待？ C 部门HR 这关被 Pass 之后没多久我居然又收到了第三个部门的邀约。 说实话当时我是拒绝的，之前经历了将近两个月的时间却没能如愿我内心是崩溃的。 我向联系我的大佬表达了我的想法，他倒觉得我最后被 pass 的原因是个小问题，再尝试的话会有很大的几率通过。 我把这事给朋友说了之后也支持我再试试，反正也没啥损失嘛，而且面试的状态还在。 所以我又被打了鸡血，才有了下面的面试经过： 一面面试官： 服务化框架的选型和差异？ 博主： 一起探讨了 SpringCloud、Dubbo、Thrift 的差异，优缺点等。 面试官： 一致性 Hash 算法的原理？ 博主： 将数据 Hash 之后落到一个 0 ~ 2^32-1 构成的一个环上。。。。 面试官： 谈谈你理解的 Zookeeper？ 博主： 作为一个分布式协调器。。。 面试官： 如何处理 MQ 重复消费？ 博主： 业务幂等处理。。。。 面试官： 客户端负载算法？ 博主： 轮询、随机、一致性 Hash、故障转移、LRU 等。。 面试官： long 类型的赋值是否是原子的？ 博主： 不是。。。 面试官： volatile 关键字的原理及作用？happen Before？ 博主： 可见性、一致性。。 二面一面之后大概一周的时间接到了二面的电话： 原以为会像之前一样直接进入笔试，这次上来先简单聊了下： 谈谈对微服务的理解，好处以及弊端？ 分布式缓存的设计？热点缓存？ 之后才正式进入笔试流程： 这次主要考察设计能力，其实就是对设计模式的理解？能否应对后续的扩展性。 笔试完了之后也和面试官交流，原以为会是算法之类的测试，后来得知他能看到前几轮的笔试情况，特地挑的没有做过的方向。 所以大家也不用刻意去押题，总有你想不到的，平时多积累才是硬道理。 三面又过了两周左右，得到 HR 通知；希望能过去杭州参加现场面试。并且阿里包了来回的机票酒店等。 可见阿里对人才渴望还是舍得下成本的。 既然都这样了，就当成一次旅游所以去了一趟杭州。 现场面的时候有别于其他面试，是由两个面试官同时参与： 给一个场景，谈谈你的架构方式。 这就对平时的积累要求较高了。 还有一个印象较深的是： 在网页上点击一个按钮到服务器的整个流程，尽量完整。 其实之前看过，好像是 Google 的一个面试题。 完了之后让我回去等通知，没有见到 HR 我就知道凉了，果不其然。 总结看到这里的朋友应该都是老铁了，我也把上文提到的大多数面试题整理在了 GitHub： 厂库地址： https://github.com/crossoverJie/Java-Interview 最后总结下这将近四个月的面试心得： 一定要积极的推销自己，像在 A 部门的三面时，由于基础答得不是很好；所以最后我表达了自己的态度，对工作、技术的积极性。让面试官看到你的潜力值得一个 HC 名额。 面试过程中遇到自己的不会的可以主动提出，切不可不懂装懂，这一问就露馅。可以将面试官引导到自己擅长的领域。比如当时我正好研究了锁，所以和面试官一聊就是半小时这就是加分项。 平时要主动积累知识。写博客和参与开源项目就是很好的方式。 博客可以记录自己踩过的坑，加深印象，而且在写的过程中可以查漏补缺，最后把整个知识体系巩固的比较牢固，良好的内容还可以得到意想不到的收获，比如我第一次面试的机会。 GitHub 是开发者的一张名片，积极参与开源项目可以和全球大佬头脑风暴，并且在面试过程中绝对是一个加分利器。 面试官一般最后都会问你有什么要问我的？千万不要问一些公司福利待遇之类的问题。可以问下本次面试的表现？还有哪些需要完善的？从而知道自己答得如何也能补全自己。 还有一点：不要在某次面试失利后否定自己，有时真的不是自己能力不行。这个也讲缘分。 塞翁失马焉知非福 我就是个例子，虽然最后没能去成阿里，现在在公司也是一个部门的技术负责人，在我们城市还有个窝，温馨的家，和女朋友一起为想要的生活努力奋斗。 欢迎关注作者公众号于我交流🤗。]]></content>
      <categories>
        <category>Interview</category>
        <category>Person</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Guava 源码分析（Cache 原理）]]></title>
    <url>%2F2018%2F06%2F13%2Fguava%2Fguava-cache%2F</url>
    <content type="text"><![CDATA[前言Google 出的 Guava 是 Java 核心增强的库，应用非常广泛。 我平时用的也挺频繁，这次就借助日常使用的 Cache 组件来看看 Google 大牛们是如何设计的。 缓存 本次主要讨论缓存。 缓存在日常开发中举足轻重，如果你的应用对某类数据有着较高的读取频次，并且改动较小时那就非常适合利用缓存来提高性能。 缓存之所以可以提高性能是因为它的读取效率很高，就像是 CPU 的 L1、L2、L3 缓存一样，级别越高相应的读取速度也会越快。 但也不是什么好处都占，读取速度快了但是它的内存更小资源更宝贵，所以我们应当缓存真正需要的数据。 其实也就是典型的空间换时间。 下面谈谈 Java 中所用到的缓存。 JVM 缓存首先是 JVM 缓存，也可以认为是堆缓存。 其实就是创建一些全局变量，如 Map、List 之类的容器用于存放数据。 这样的优势是使用简单但是也有以下问题： 只能显式的写入，清除数据。 不能按照一定的规则淘汰数据，如 LRU，LFU，FIFO 等。 清除数据时的回调通知。 其他一些定制功能等。 Ehcache、Guava Cache所以出现了一些专门用作 JVM 缓存的开源工具出现了，如本文提到的 Guava Cache。 它具有上文 JVM 缓存不具有的功能，如自动清除数据、多种清除算法、清除回调等。 但也正因为有了这些功能，这样的缓存必然会多出许多东西需要额外维护，自然也就增加了系统的消耗。 分布式缓存刚才提到的两种缓存其实都是堆内缓存，只能在单个节点中使用，这样在分布式场景下就招架不住了。 于是也有了一些缓存中间件，如 Redis、Memcached，在分布式环境下可以共享内存。 具体不在本次的讨论范围。 Guava Cache 示例之所以想到 Guava 的 Cache，也是最近在做一个需求，大体如下： 从 Kafka 实时读取出应用系统的日志信息，该日志信息包含了应用的健康状况。如果在时间窗口 N 内发生了 X 次异常信息，相应的我就需要作出反馈（报警、记录日志等）。 对此 Guava 的 Cache 就非常适合，我利用了它的 N 个时间内不写入数据时缓存就清空的特点，在每次读取数据时判断异常信息是否大于 X 即可。 伪代码如下： 1234567891011121314151617181920212223242526272829303132@Value("$&#123;alert.in.time:2&#125;")private int time ;@Beanpublic LoadingCache buildCache()&#123; return CacheBuilder.newBuilder() .expireAfterWrite(time, TimeUnit.MINUTES) .build(new CacheLoader&lt;Long, AtomicLong&gt;() &#123; @Override public AtomicLong load(Long key) throws Exception &#123; return new AtomicLong(0); &#125; &#125;);&#125;/** * 判断是否需要报警 */public void checkAlert() &#123; try &#123; if (counter.get(KEY).incrementAndGet() &gt;= limit) &#123; LOGGER.info("***********报警***********"); //将缓存清空 counter.get(KEY).getAndSet(0L); &#125; &#125; catch (ExecutionException e) &#123; LOGGER.error("Exception", e); &#125;&#125; 首先是构建了 LoadingCache 对象，在 N 分钟内不写入数据时就回收缓存（当通过 Key 获取不到缓存时，默认返回 0）。 然后在每次消费时候调用 checkAlert() 方法进行校验，这样就可以达到上文的需求。 我们来设想下 Guava 它是如何实现过期自动清除数据，并且是可以按照 LRU 这样的方式清除的。 大胆假设下： 内部通过一个队列来维护缓存的顺序，每次访问过的数据移动到队列头部，并且额外开启一个线程来判断数据是否过期，过期就删掉。有点类似于我之前写过的 动手实现一个 LRU cache 胡适说过：大胆假设小心论证 下面来看看 Guava 到底是怎么实现。 原理分析看原理最好不过是跟代码一步步走了： 示例代码在这里： https://github.com/crossoverJie/Java-Interview/blob/master/src/main/java/com/crossoverjie/guava/CacheLoaderTest.java 为了能看出 Guava 是怎么删除过期数据的在获取缓存之前休眠了 5 秒钟，达到了超时条件。 最终会发现在 com.google.common.cache.LocalCache 类的 2187 行比较关键。 再跟进去之前第 2182 行会发现先要判断 count 是否大于 0，这个 count 保存的是当前缓存的数量，并用 volatile 修饰保证了可见性。 更多关于 volatile 的相关信息可以查看 你应该知道的 volatile 关键字 接着往下跟到： 2761 行，根据方法名称可以看出是判断当前的 Entry 是否过期，该 entry 就是通过 key 查询到的。 这里就很明显的看出是根据根据构建时指定的过期方式来判断当前 key 是否过期了。 如果过期就往下走，尝试进行过期删除（需要加锁，后面会具体讨论）。 到了这里也很清晰了： 获取当前缓存的总数量 自减一（前面获取了锁，所以线程安全） 删除并将更新的总数赋值到 count。 其实大体上就是这个流程，Guava 并没有按照之前猜想的另起一个线程来维护过期数据。 应该是以下原因： 新起线程需要资源消耗。 维护过期数据还要获取额外的锁，增加了消耗。 而在查询时候顺带做了这些事情，但是如果该缓存迟迟没有访问也会存在数据不能被回收的情况，不过这对于一个高吞吐的应用来说也不是问题。 总结最后再来总结下 Guava 的 Cache。 其实在上文跟代码时会发现通过一个 key 定位数据时有以下代码： 如果有看过 ConcurrentHashMap 的原理 应该会想到这其实非常类似。 其实 Guava Cache 为了满足并发场景的使用，核心的数据结构就是按照 ConcurrentHashMap 来的，这里也是一个 key 定位到一个具体位置的过程。 先找到 Segment，再找具体的位置，等于是做了两次 Hash 定位。 上文有一个假设是对的，它内部会维护两个队列 accessQueue,writeQueue 用于记录缓存顺序，这样才可以按照顺序淘汰数据（类似于利用 LinkedHashMap 来做 LRU 缓存）。 同时从上文的构建方式来看，它也是构建者模式来创建对象的。 因为作为一个给开发者使用的工具，需要有很多的自定义属性，利用构建则模式再合适不过了。 Guava 其实还有很多东西没谈到，比如它利用 GC 来回收内存，移除数据时的回调通知等。之后再接着讨论。 扫码关注微信公众号，第一时间获取消息。]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式工具的一次小升级⏫]]></title>
    <url>%2F2018%2F06%2F07%2Fdistributed-lock%2Fdistributed-lock-redis-update%2F</url>
    <content type="text"><![CDATA[前言之前在做 秒杀架构实践 时有提到对 distributed-redis-tool 的一次小升级，但是没有细说。 其实主要原因是： 秒杀时我做压测：由于集成了这个限流组件，并发又比较大，所以导致连接、断开 Redis 非常频繁。最终导致获取不了 Redis connection 的异常。 池化技术这就是一个典型的对稀缺资源使用不善导致的。 何为稀缺资源？常见的有： 线程 数据库连接 网络连接等 这些资源都有共同的特点：创建销毁成本较高。 这里涉及到的 Redis 连接也属于该类资源。 我们希望将这些稀有资源管理起来放到一个池子里，当需要时就从中获取，用完就放回去，不够用时就等待（或返回）。 这样我们只需要初始化并维护好这个池子，就能避免频繁的创建、销毁这些资源（也有资源长期未使用需要缩容的情况）。 通常我们称这项姿势为池化技术，如常见的： 线程池 各种资源的连接池等。 为此我将使用到 Redis 的 分布式锁、分布式限流 都升级为利用连接池来获取 Redis 的连接。 这里以分布式锁为例： 将使用的 api 修改为： 原有： 123456789101112131415161718@Configurationpublic class RedisLockConfig &#123; @Bean public RedisLock build()&#123; //Need to get Redis connection RedisLock redisLock = new RedisLock() ; HostAndPort hostAndPort = new HostAndPort("127.0.0.1",7000) ; JedisCluster jedisCluster = new JedisCluster(hostAndPort) ; RedisLock redisLock = new RedisLock.Builder(jedisCluster) .lockPrefix("lock_test") .sleepTime(100) .build(); return redisLock ; &#125;&#125; 现在：123456789101112131415161718@Configurationpublic class RedisLockConfig &#123; private Logger logger = LoggerFactory.getLogger(RedisLockConfig.class); @Autowired private JedisConnectionFactory jedisConnectionFactory; @Bean public RedisLock build() &#123; RedisLock redisLock = new RedisLock.Builder(jedisConnectionFactory,RedisToolsConstant.SINGLE) .lockPrefix("lock_") .sleepTime(100) .build(); return redisLock; &#125;&#125; 将以前的 Jedis 修改为 JedisConnectionFactory，后续的 Redis 连接就可通过这个对象获取。 并且显示的传入使用 RedisCluster 还是单机的 Redis。 所以在真正操作 Redis 时需要修改： 1234567891011121314151617181920212223242526272829303132333435public boolean tryLock(String key, String request) &#123; //get connection Object connection = getConnection(); String result ; if (connection instanceof Jedis)&#123; result = ((Jedis) connection).set(lockPrefix + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); ((Jedis) connection).close(); &#125;else &#123; result = ((JedisCluster) connection).set(lockPrefix + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); try &#123; ((JedisCluster) connection).close(); &#125; catch (IOException e) &#123; logger.error("IOException",e); &#125; &#125; if (LOCK_MSG.equals(result)) &#123; return true; &#125; else &#123; return false; &#125;&#125;//获取连接private Object getConnection() &#123; Object connection ; if (type == RedisToolsConstant.SINGLE)&#123; RedisConnection redisConnection = jedisConnectionFactory.getConnection(); connection = redisConnection.getNativeConnection(); &#125;else &#123; RedisClusterConnection clusterConnection = jedisConnectionFactory.getClusterConnection(); connection = clusterConnection.getNativeConnection() ; &#125; return connection;&#125; 最大的改变就是将原有操作 Redis 的对象（T extends JedisCommands）改为从连接池中获取。 由于使用了 org.springframework.data.redis.connection.jedis.JedisConnectionFactory 作为 Redis 连接池。 所以需要再使用时构件好这个对象： 1234567891011121314151617181920212223242526272829JedisPoolConfig config = new JedisPoolConfig();config.setMaxIdle(10);config.setMaxTotal(300);config.setMaxWaitMillis(10000);config.setTestOnBorrow(true);config.setTestOnReturn(true);RedisClusterConfiguration redisClusterConfiguration = new RedisClusterConfiguration();redisClusterConfiguration.addClusterNode(new RedisNode("10.19.13.51", 7000));//单机JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(config);//集群//JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(redisClusterConfiguration) ;jedisConnectionFactory.setHostName("47.98.194.60");jedisConnectionFactory.setPort(6379);jedisConnectionFactory.setPassword("");jedisConnectionFactory.setTimeout(100000);jedisConnectionFactory.afterPropertiesSet();//jedisConnectionFactory.setShardInfo(new JedisShardInfo("47.98.194.60", 6379));//JedisCluster jedisCluster = new JedisCluster(hostAndPort);HostAndPort hostAndPort = new HostAndPort("10.19.13.51", 7000);JedisCluster jedisCluster = new JedisCluster(hostAndPort);redisLock = new RedisLock.Builder(jedisConnectionFactory, RedisToolsConstant.SINGLE) .lockPrefix("lock_") .sleepTime(100) .build(); 看起比较麻烦，需要构建对象的较多。 但整合 Spring 使用时就要清晰许多。 配合 SpringSpring 很大的一个作用就是帮我们管理对象，所以像上文那些看似很复杂的对象都可以交由它来管理： 12345678910111213141516171819202122232425&lt;!-- jedis 配置 --&gt; &lt;bean id="JedispoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxIdle" value="$&#123;redis.maxIdle&#125;"/&gt; &lt;property name="maxTotal" value="$&#123;redis.maxTotal&#125;"/&gt; &lt;property name="maxWaitMillis" value="$&#123;redis.maxWait&#125;"/&gt; &lt;property name="testOnBorrow" value="$&#123;redis.testOnBorrow&#125;"/&gt; &lt;property name="testOnReturn" value="$&#123;redis.testOnBorrow&#125;"/&gt; &lt;/bean&gt; &lt;!-- redis服务器中心 --&gt; &lt;bean id="connectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;property name="poolConfig" ref="JedispoolConfig"/&gt; &lt;property name="port" value="$&#123;redis.port&#125;"/&gt; &lt;property name="hostName" value="$&#123;redis.host&#125;"/&gt; &lt;property name="password" value="$&#123;redis.password&#125;"/&gt; &lt;property name="timeout" value="$&#123;redis.timeout&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate"&gt; &lt;property name="connectionFactory" ref="connectionFactory"/&gt; &lt;property name="keySerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer"/&gt; &lt;/property&gt; &lt;property name="valueSerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer"/&gt; &lt;/property&gt; &lt;/bean&gt; 这个其实没多少好说的，就算是换成 SpringBoot 也是创建 JedispoolConfig,connectionFactory,redisTemplate 这些 bean 即可。 总结换为连接池之后再进行压测自然没有出现获取不了 Redis 连接的异常（并发达到一定的量也会出错）说明更新是很有必要的。 推荐有用到该组件的朋友都升级下，也欢迎提出 Issues 和 PR。 项目地址： https://github.com/crossoverJie/distributed-redis-tool]]></content>
      <categories>
        <category>Distributed Tools</category>
      </categories>
      <tags>
        <tag>Distributed Lock</tag>
        <tag>Distributed Limited</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记于 2018 年高考！]]></title>
    <url>%2F2018%2F06%2F06%2Fexam%2F2018-06-07-The-university-entrance-exam%2F</url>
    <content type="text"><![CDATA[2012/02/28 2012年二月二十八日。 这天学校举行了高考 100 天誓师大会，当时完全不知道意味着什么，只感觉现场热血沸腾、激情高涨，心里告诉自己就算只剩下 100 天我也能考上清华其次也是北大。 2012/06/03 2012年六月三日。 晚自习拿出前段时间刚拍的毕业合照，恨死摄影师，没有抓拍到我最帅的角度😡。 2012/06/04 2012年六月四日。 离校前的最后一晚，我们像往常每周的音乐晚自习一样，由音乐委员（@猪娅）带着大家唱可米小子的青春纪念册。 小红姐（班主任）特别的没来查岗。 心里想着，这就是青春嘛？也不过如此。 大家拿着热和的手机（才发的，平时会收）肆意的拍着照片： 那时没有美颜、没有修图，一切都是那么和谐。 2012/06/05 2012年六月五日。 是进津（江津）赶考，走时特地在六食堂买了一个包子，没想到是在学校最后一顿早餐。 车上大家有说有笑，嗯，就像是资深导游带的一个低价旅游团，每人心里充满了惊喜却不知即将面临什么。 2012/06/07 2012年六月七日。 大家在各自的考场奋笔疾书，用两天四场考试来为高中三年画上句号。 有的梦想进入理想的大学、和心仪的 TA 长相厮守，当然也有回家继承百万家产😂。 而我当时只想快速的结束这一切，高中三年，特别是高三这年真的是够了。每天做不完的卷子，背不完的诗词，还得想着为陈家老祖宗出一位正儿八经的大学生。 所以考试完全采用人卷合一的心态（能做就做，不会就过）快速的过完了这两天。 这些作文题目还看得懂嘛。。 2018/06/07 2018年六月七日。 高中学过许多关于时光飞逝的成语、古诗，但都没有亲身体会那么深刻！ 六年时间，红了樱桃，绿了芭蕉。 有的步入职场、升职加薪、求婚成功、穿上婚纱、组建家庭、初为人母。 每人都过着各自的生活，但一旦相见就有数不尽的话题（@江源），逃课打球、翻墙上网、暗恋女神、天天向上、作业卷子。 这句话送给高2012级10班的所有同学： 愿你出走半生，归来仍是少年 一大波图片即将袭来： 摆拍虽好，不要抽烟哦： 小红姐生日快乐，永远十八： 集体生日，年年十八： 状元书摊，不是第一不卖：]]></content>
      <categories>
        <category>小情绪</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Netty(一) SpringBoot 整合长连接心跳机制]]></title>
    <url>%2F2018%2F05%2F24%2Fnetty%2FNetty(1)TCP-Heartbeat%2F</url>
    <content type="text"><![CDATA[前言Netty 是一个高性能的 NIO 网络框架，本文基于 SpringBoot 以常见的心跳机制来认识 Netty。 最终能达到的效果： 客户端每隔 N 秒检测是否需要发送心跳。 服务端也每隔 N 秒检测是否需要发送心跳。 服务端可以主动 push 消息到客户端。 基于 SpringBoot 监控，可以查看实时连接以及各种应用信息。 效果如下： IdleStateHandlerNetty 可以使用 IdleStateHandler 来实现连接管理，当连接空闲时间太长（没有发送、接收消息）时则会触发一个事件，我们便可在该事件中实现心跳机制。 客户端心跳当客户端空闲了 N 秒没有给服务端发送消息时会自动发送一个心跳来维持连接。 核心代码代码如下： 12345678910111213141516171819202122232425262728293031323334public class EchoClientHandle extends SimpleChannelInboundHandler&lt;ByteBuf&gt; &#123; private final static Logger LOGGER = LoggerFactory.getLogger(EchoClientHandle.class); @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent)&#123; IdleStateEvent idleStateEvent = (IdleStateEvent) evt ; if (idleStateEvent.state() == IdleState.WRITER_IDLE)&#123; LOGGER.info("已经 10 秒没有发送信息！"); //向服务端发送消息 CustomProtocol heartBeat = SpringBeanFactory.getBean("heartBeat", CustomProtocol.class); ctx.writeAndFlush(heartBeat).addListener(ChannelFutureListener.CLOSE_ON_FAILURE) ; &#125; &#125; super.userEventTriggered(ctx, evt); &#125; @Override protected void channelRead0(ChannelHandlerContext channelHandlerContext, ByteBuf in) throws Exception &#123; //从服务端收到消息时被调用 LOGGER.info("客户端收到消息=&#123;&#125;",in.toString(CharsetUtil.UTF_8)) ; &#125;&#125; 实现非常简单，只需要在事件回调中发送一个消息即可。 由于整合了 SpringBoot ，所以发送的心跳信息是一个单例的 Bean。 123456789101112@Configurationpublic class HeartBeatConfig &#123; @Value("$&#123;channel.id&#125;") private long id ; @Bean(value = "heartBeat") public CustomProtocol heartBeat()&#123; return new CustomProtocol(id,"ping") ; &#125;&#125; 这里涉及到了自定义协议的内容，请继续查看下文。 当然少不了启动引导： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Componentpublic class HeartbeatClient &#123; private final static Logger LOGGER = LoggerFactory.getLogger(HeartbeatClient.class); private EventLoopGroup group = new NioEventLoopGroup(); @Value("$&#123;netty.server.port&#125;") private int nettyPort; @Value("$&#123;netty.server.host&#125;") private String host; private SocketChannel channel; @PostConstruct public void start() throws InterruptedException &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new CustomerHandleInitializer()) ; ChannelFuture future = bootstrap.connect(host, nettyPort).sync(); if (future.isSuccess()) &#123; LOGGER.info("启动 Netty 成功"); &#125; channel = (SocketChannel) future.channel(); &#125; &#125;public class CustomerHandleInitializer extends ChannelInitializer&lt;Channel&gt; &#123; @Override protected void initChannel(Channel ch) throws Exception &#123; ch.pipeline() //10 秒没发送消息 将IdleStateHandler 添加到 ChannelPipeline 中 .addLast(new IdleStateHandler(0, 10, 0)) .addLast(new HeartbeatEncode()) .addLast(new EchoClientHandle()) ; &#125;&#125; 所以当应用启动每隔 10 秒会检测是否发送过消息，不然就会发送心跳信息。 服务端心跳服务器端的心跳其实也是类似，也需要在 ChannelPipeline 中添加一个 IdleStateHandler 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class HeartBeatSimpleHandle extends SimpleChannelInboundHandler&lt;CustomProtocol&gt; &#123; private final static Logger LOGGER = LoggerFactory.getLogger(HeartBeatSimpleHandle.class); private static final ByteBuf HEART_BEAT = Unpooled.unreleasableBuffer(Unpooled.copiedBuffer(new CustomProtocol(123456L,"pong").toString(),CharsetUtil.UTF_8)); /** * 取消绑定 * @param ctx * @throws Exception */ @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; NettySocketHolder.remove((NioSocketChannel) ctx.channel()); &#125; @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123; if (evt instanceof IdleStateEvent)&#123; IdleStateEvent idleStateEvent = (IdleStateEvent) evt ; if (idleStateEvent.state() == IdleState.READER_IDLE)&#123; LOGGER.info("已经5秒没有收到信息！"); //向客户端发送消息 ctx.writeAndFlush(HEART_BEAT).addListener(ChannelFutureListener.CLOSE_ON_FAILURE) ; &#125; &#125; super.userEventTriggered(ctx, evt); &#125; @Override protected void channelRead0(ChannelHandlerContext ctx, CustomProtocol customProtocol) throws Exception &#123; LOGGER.info("收到customProtocol=&#123;&#125;", customProtocol); //保存客户端与 Channel 之间的关系 NettySocketHolder.put(customProtocol.getId(),(NioSocketChannel)ctx.channel()) ; &#125;&#125; 这里有点需要注意： 当有多个客户端连上来时，服务端需要区分开，不然响应消息就会发生混乱。 所以每当有个连接上来的时候，我们都将当前的 Channel 与连上的客户端 ID 进行关联（因此每个连上的客户端 ID 都必须唯一）。 这里采用了一个 Map 来保存这个关系，并且在断开连接时自动取消这个关联。 12345678910111213141516171819public class NettySocketHolder &#123; private static final Map&lt;Long, NioSocketChannel&gt; MAP = new ConcurrentHashMap&lt;&gt;(16); public static void put(Long id, NioSocketChannel socketChannel) &#123; MAP.put(id, socketChannel); &#125; public static NioSocketChannel get(Long id) &#123; return MAP.get(id); &#125; public static Map&lt;Long, NioSocketChannel&gt; getMAP() &#123; return MAP; &#125; public static void remove(NioSocketChannel nioSocketChannel) &#123; MAP.entrySet().stream().filter(entry -&gt; entry.getValue() == nioSocketChannel).forEach(entry -&gt; MAP.remove(entry.getKey())); &#125;&#125; 启动引导程序： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859Componentpublic class HeartBeatServer &#123; private final static Logger LOGGER = LoggerFactory.getLogger(HeartBeatServer.class); private EventLoopGroup boss = new NioEventLoopGroup(); private EventLoopGroup work = new NioEventLoopGroup(); @Value("$&#123;netty.server.port&#125;") private int nettyPort; /** * 启动 Netty * * @return * @throws InterruptedException */ @PostConstruct public void start() throws InterruptedException &#123; ServerBootstrap bootstrap = new ServerBootstrap() .group(boss, work) .channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(nettyPort)) //保持长连接 .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new HeartbeatInitializer()); ChannelFuture future = bootstrap.bind().sync(); if (future.isSuccess()) &#123; LOGGER.info("启动 Netty 成功"); &#125; &#125; /** * 销毁 */ @PreDestroy public void destroy() &#123; boss.shutdownGracefully().syncUninterruptibly(); work.shutdownGracefully().syncUninterruptibly(); LOGGER.info("关闭 Netty 成功"); &#125;&#125; public class HeartbeatInitializer extends ChannelInitializer&lt;Channel&gt; &#123; @Override protected void initChannel(Channel ch) throws Exception &#123; ch.pipeline() //五秒没有收到消息 将IdleStateHandler 添加到 ChannelPipeline 中 .addLast(new IdleStateHandler(5, 0, 0)) .addLast(new HeartbeatDecoder()) .addLast(new HeartBeatSimpleHandle()); &#125;&#125; 也是同样将IdleStateHandler 添加到 ChannelPipeline 中，也会有一个定时任务，每5秒校验一次是否有收到消息，否则就主动发送一次请求。 因为测试是有两个客户端连上所以有两个日志。 自定义协议上文其实都看到了：服务端与客户端采用的是自定义的 POJO 进行通讯的。 所以需要在客户端进行编码，服务端进行解码，也都只需要各自实现一个编解码器即可。 CustomProtocol： 1234567public class CustomProtocol implements Serializable&#123; private static final long serialVersionUID = 4671171056588401542L; private long id ; private String content ; //省略 getter/setter&#125; 客户端的编码器： 123456789public class HeartbeatEncode extends MessageToByteEncoder&lt;CustomProtocol&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, CustomProtocol msg, ByteBuf out) throws Exception &#123; out.writeLong(msg.getId()) ; out.writeBytes(msg.getContent().getBytes()) ; &#125;&#125; 也就是说消息的前八个字节为 header，剩余的全是 content。 服务端的解码器： 12345678910111213141516public class HeartbeatDecoder extends ByteToMessageDecoder &#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; long id = in.readLong() ; byte[] bytes = new byte[in.readableBytes()] ; in.readBytes(bytes) ; String content = new String(bytes) ; CustomProtocol customProtocol = new CustomProtocol() ; customProtocol.setId(id); customProtocol.setContent(content) ; out.add(customProtocol) ; &#125;&#125; 只需要按照刚才的规则进行解码即可。 实现原理其实联想到 IdleStateHandler 的功能，自然也能想到它实现的原理： 应该会存在一个定时任务的线程去处理这些消息。 来看看它的源码： 首先是构造函数: 12345678public IdleStateHandler( int readerIdleTimeSeconds, int writerIdleTimeSeconds, int allIdleTimeSeconds) &#123; this(readerIdleTimeSeconds, writerIdleTimeSeconds, allIdleTimeSeconds, TimeUnit.SECONDS);&#125; 其实就是初始化了几个数据： readerIdleTimeSeconds：一段时间内没有数据读取 writerIdleTimeSeconds：一段时间内没有数据发送 allIdleTimeSeconds：以上两种满足其中一个即可 因为 IdleStateHandler 也是一种 ChannelHandler，所以会在 channelActive 中初始化任务： 1234567891011121314151617181920212223242526272829303132333435@Overridepublic void channelActive(ChannelHandlerContext ctx) throws Exception &#123; // This method will be invoked only if this handler was added // before channelActive() event is fired. If a user adds this handler // after the channelActive() event, initialize() will be called by beforeAdd(). initialize(ctx); super.channelActive(ctx);&#125;private void initialize(ChannelHandlerContext ctx) &#123; // Avoid the case where destroy() is called before scheduling timeouts. // See: https://github.com/netty/netty/issues/143 switch (state) &#123; case 1: case 2: return; &#125; state = 1; initOutputChanged(ctx); lastReadTime = lastWriteTime = ticksInNanos(); if (readerIdleTimeNanos &gt; 0) &#123; readerIdleTimeout = schedule(ctx, new ReaderIdleTimeoutTask(ctx), readerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (writerIdleTimeNanos &gt; 0) &#123; writerIdleTimeout = schedule(ctx, new WriterIdleTimeoutTask(ctx), writerIdleTimeNanos, TimeUnit.NANOSECONDS); &#125; if (allIdleTimeNanos &gt; 0) &#123; allIdleTimeout = schedule(ctx, new AllIdleTimeoutTask(ctx), allIdleTimeNanos, TimeUnit.NANOSECONDS); &#125;&#125; 也就是会按照我们给定的时间初始化出定时任务。 接着在任务真正执行时进行判断： 1234567891011121314151617181920212223242526272829303132private final class ReaderIdleTimeoutTask extends AbstractIdleTask &#123; ReaderIdleTimeoutTask(ChannelHandlerContext ctx) &#123; super(ctx); &#125; @Override protected void run(ChannelHandlerContext ctx) &#123; long nextDelay = readerIdleTimeNanos; if (!reading) &#123; nextDelay -= ticksInNanos() - lastReadTime; &#125; if (nextDelay &lt;= 0) &#123; // Reader is idle - set a new timeout and notify the callback. readerIdleTimeout = schedule(ctx, this, readerIdleTimeNanos, TimeUnit.NANOSECONDS); boolean first = firstReaderIdleEvent; firstReaderIdleEvent = false; try &#123; IdleStateEvent event = newIdleStateEvent(IdleState.READER_IDLE, first); channelIdle(ctx, event); &#125; catch (Throwable t) &#123; ctx.fireExceptionCaught(t); &#125; &#125; else &#123; // Read occurred before the timeout - set a new timeout with shorter delay. readerIdleTimeout = schedule(ctx, this, nextDelay, TimeUnit.NANOSECONDS); &#125; &#125;&#125; 如果满足条件则会生成一个 IdleStateEvent 事件。 SpringBoot 监控由于整合了 SpringBoot 之后不但可以利用 Spring 帮我们管理对象，也可以利用它来做应用监控。 actuator 监控当我们为引入了: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 就开启了 SpringBoot 的 actuator 监控功能，他可以暴露出很多监控端点供我们使用。 如一些应用中的一些统计数据： 存在的 Beans： 更多信息请查看：https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-endpoints.html 但是如果我想监控现在我的服务端有多少客户端连上来了，分别的 ID 是多少？ 其实就是实时查看我内部定义的那个关联关系的 Map。 这就需要暴露自定义端点了。 自定义端点暴露的方式也很简单： 继承 AbstractEndpoint 并复写其中的 invoke 函数： 1234567891011121314151617public class CustomEndpoint extends AbstractEndpoint&lt;Map&lt;Long,NioSocketChannel&gt;&gt; &#123; /** * 监控端点的 访问地址 * @param id */ public CustomEndpoint(String id) &#123; //false 表示不是敏感端点 super(id, false); &#125; @Override public Map&lt;Long, NioSocketChannel&gt; invoke() &#123; return NettySocketHolder.getMAP(); &#125;&#125; 其实就是返回了 Map 中的数据。 再配置一个该类型的 Bean 即可： 12345678910111213@Configurationpublic class EndPointConfig &#123; @Value("$&#123;monitor.channel.map.key&#125;") private String channelMap; @Bean public CustomEndpoint buildEndPoint()&#123; CustomEndpoint customEndpoint = new CustomEndpoint(channelMap) ; return customEndpoint ; &#125;&#125; 这样我们就可以通过配置文件中的 monitor.channel.map.key 来访问了： 一个客户端连接时： 两个客户端连接时： 整合 SBA这样其实监控功能已经可以满足了，但能不能展示的更美观、并且多个应用也可以方便查看呢？ 有这样的开源工具帮我们做到了： https://github.com/codecentric/spring-boot-admin 简单来说我们可以利用该工具将 actuator 暴露出来的接口可视化并聚合的展示在页面中： 接入也很简单，首先需要引入依赖： 1234&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt;&lt;/dependency&gt; 并在配置文件中加入： 1234# 关闭健康检查权限management.security.enabled=false# SpringAdmin 地址spring.boot.admin.url=http://127.0.0.1:8888 在启动应用之前先讲 SpringBootAdmin 部署好： 这个应用就是一个纯粹的 SpringBoot ，只需要在主函数上加入 @EnableAdminServer 注解。 12345678910@SpringBootApplication@Configuration@EnableAutoConfiguration@EnableAdminServerpublic class AdminApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AdminApplication.class, args); &#125;&#125; 引入： 12345678910&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;1.5.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server-ui&lt;/artifactId&gt; &lt;version&gt;1.5.6&lt;/version&gt;&lt;/dependency&gt; 之后直接启动就行了。 这样我们在 SpringBootAdmin 的页面中就可以查看很多应用信息了。 更多内容请参考官方指南： http://codecentric.github.io/spring-boot-admin/1.5.6/ 自定义监控数据其实我们完全可以借助 actuator 以及这个可视化页面帮我们监控一些简单的度量信息。 比如我在客户端和服务端中写了两个 Rest 接口用于向对方发送消息。 只是想要记录分别发送了多少次： 客户端： 123456789101112131415161718192021222324252627282930313233343536@Controller@RequestMapping("/")public class IndexController &#123; /** * 统计 service */ @Autowired private CounterService counterService; @Autowired private HeartbeatClient heartbeatClient ; /** * 向服务端发消息 * @param sendMsgReqVO * @return */ @ApiOperation("客户端发送消息") @RequestMapping("sendMsg") @ResponseBody public BaseResponse&lt;SendMsgResVO&gt; sendMsg(@RequestBody SendMsgReqVO sendMsgReqVO)&#123; BaseResponse&lt;SendMsgResVO&gt; res = new BaseResponse(); heartbeatClient.sendMsg(new CustomProtocol(sendMsgReqVO.getId(),sendMsgReqVO.getMsg())) ; // 利用 actuator 来自增 counterService.increment(Constants.COUNTER_CLIENT_PUSH_COUNT); SendMsgResVO sendMsgResVO = new SendMsgResVO() ; sendMsgResVO.setMsg("OK") ; res.setCode(StatusEnum.SUCCESS.getCode()) ; res.setMessage(StatusEnum.SUCCESS.getMessage()) ; res.setDataBody(sendMsgResVO) ; return res ; &#125;&#125; 只要我们引入了 actuator 的包，那就可以直接注入 counterService ，利用它来帮我们记录数据。 当我们调用该接口时： 在监控页面中可以查询刚才的调用情况： 服务端主动 push 消息也是类似，只是需要在发送时候根据客户端的 ID 查询到具体的 Channel 发送： 总结以上就是一个简单 Netty 心跳示例，并演示了 SpringBoot 的监控，之后会继续更新 Netty 相关内容，欢迎关注及指正。 本文所有代码： https://github.com/crossoverJie/netty-action 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>TCP</tag>
        <tag>Heartbeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1K star+ 的项目是如何炼成的？]]></title>
    <url>%2F2018%2F05%2F15%2Fskill%2F1Kstar%2F</url>
    <content type="text"><![CDATA[前言首先标题党一下，其实这篇文章主要是记录我的第二个过 1K star 的项目 Java-Interview，顺便分享下其中的过程及经验。 需求选择Java-Interview之所以要做这个项目主要是当时我正在面阿里的两个部门，非常幸运的是技术面都过了。其中的过程真是让我受益匪浅更是印象深刻，所以就想把期间的问题记录下来，加上自己的理解希望能对其他朋友起到帮助。 正好那段时间也是传说中的金三银四，所以无形中也叫顺势而为吧😏。 SSM这个项目的历史就比较悠久了，我看了下第一次提交差不多是两年前。 从这个名字也可以看出当初还是一个刚入行没多久的小菜鸟，因为之前在学 Java 的时候真的走了很多冤枉路，所以从头开始记录到现在整个过程所学到的东西，踩过的坑。 由于是面向小白，入门简单，上手较快也取的了一定的关注。 其实从这两个项目可以看出选择一个方向是很重要的。 以及该项目解决了什么问题，长期的规划，受众是哪些都要考虑清楚(怎么有点像做产品😅，其实这就是你自己的产品)。 比如这两个项目的目标： Java-Interview：持续更新面试问题，希望能让面试者知其然也知其所以然。 SSM：博主从小白到现在实际开发所遇到的问题记录，以及实战经验，现在逐渐会分享一些难点以及底层。受众大多是小白。 文档很重要既然项目做出来是给人用的，那文档就显得至关重要了。 就像日常和前端怼接口时，有一个标准的文档输出比在白板上折腾半天要高的多。 其实仔细观察 GitHub 上热门的项目，会发现他们的文档几乎都有一些共同结构： 简单描述项目是干什么的。 快速启动。 最近更新。 Q/A 答疑。 项目截图。 主要目的就是要简单易读，快速上手。 然后把一些复杂的如系统设计、开发指南等可以放到 wiki 中。 切记不要什么东西都往 README.MD 中写，保持一个简洁的文档可以加分哦。 当然也可以在首页加入一些徽章如： 也能起到一些积极作用。 积极推荐代码质量这个就不多说了，这应该是最基本的要求。 俗话说：酒香不怕巷子深。 但对于做开源项目来说就不太适应了，当你幸辛苦苦做了一个自认为很不错的项目，结果一年过去了都无人问津，这不免会有点打击积极性。 所以适当的自我推荐就很有必要了。 上图是我博客、项目的主要流量来源。 下面是我自身体验比较优质的推荐渠道： 开发者头条：由于截图的时候没有新发文章，之前那篇秒杀架构实践发了之后博客 80% 的流量都是从头条过来的，而且质量很高，不得不点个赞。 并发编程网: 并发编程网是由阿里大牛清英(买了那本《并发编程的艺术》就被圈粉了)创办的，其中的文章质量普遍较高(导致也会有一点写作门槛)。由于网站的流量也比较高，只要你的文章质量不错肯定会得到好处。 掘金：掘金这两年也比较火，是专门做开发者内容的，也是网站流量不错。 开源中国：开源中国的博客也不错，自己也有代码托管，但我还是更喜欢用 GitHub，一般上了编辑推荐都会有不错的访问量。 V2EX：大名鼎鼎的 V 站，其实受众较少，正因为如此也形成了独有的文化，因此也是我每天比逛(摸鱼)的网站，由于受众大多是开发者所以也能得到很多有用的反馈。 大佬推荐：最快捷的方式其实就是口口相传，其中当然是大佬的效率最高。之前有个纯洁的微笑、程序猿DD 都投过稿，也能带来不错的流量。 简书:本来不想推荐简书的（之前的事件以及现在鸡汤太多），但是流量还可以，现在就纯粹当做博客备份的工具了。 坚持下来之后会发现：只要自己坚持、保证质量最后会形成自己的阅读圈子，到后面甚至会有其他朋友主动来找你分享，这些都是自我提升的过程。 不忘初心当初做的第一个开源项目就是 SSM，完全受够学习时找资料的痛苦，也得到了很多人的帮助，所以才有了该项目。 平时工作中或多或少都会用到开源项目，其实我们大部分人也写不出 Spring、Guava 这样的项目，只是再这过程中可以参与进去，收获也是非常丰富的。 两年前参与开源到现在有收到面试邀请、物质奖励这些都是正面积极的，可以鼓励我们接着做下去。 但最多的还是在这过程中结识了很多朋友，技术能力提升也很明显，这些都是保持自我可持续发展的必要条件。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十八) 秒杀架构实践]]></title>
    <url>%2F2018%2F05%2F07%2Fssm%2FSSM18-seconds-kill%2F</url>
    <content type="text"><![CDATA[前言之前在 Java-Interview 中提到过秒杀架构的设计，这次基于其中的理论简单实现了一下。 本次采用循序渐进的方式逐步提高性能达到并发秒杀的效果，文章较长请准备好瓜子板凳(liushuizhang😂)。 本文所有涉及的代码： https://github.com/crossoverJie/SSM https://github.com/crossoverJie/distributed-redis-tool 最终架构图： 先简单根据这个图谈下请求的流转，因为后面不管怎么改进这个都是没有变的。 前端请求进入 web 层，对应的代码就是 controller。 之后将真正的库存校验、下单等请求发往 Service 层（其中 RPC 调用依然采用的 dubbo，只是更新为最新版本，本次不会过多讨论 dubbo 相关的细节，有兴趣的可以查看 基于dubbo的分布式架构）。 Service 层再对数据进行落地，下单完成。 无限制其实抛开秒杀这个场景来说正常的一个下单流程可以简单分为以下几步： 校验库存 扣库存 创建订单 支付 基于上文的架构所以我们有了以下实现： 先看看实际项目的结构： 还是和以前一样： 提供出一个 API 用于 Service 层实现，以及 web 层消费。 web 层简单来说就是一个 SpringMVC。 Service 层则是真正的数据落地。 SSM-SECONDS-KILL-ORDER-CONSUMER 则是后文会提到的 Kafka 消费。 数据库也是只有简单的两张表模拟下单： 1234567891011121314151617CREATE TABLE `stock` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(50) NOT NULL DEFAULT '' COMMENT '名称', `count` int(11) NOT NULL COMMENT '库存', `sale` int(11) NOT NULL COMMENT '已售', `version` int(11) NOT NULL COMMENT '乐观锁，版本号', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;CREATE TABLE `stock_order` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `sid` int(11) NOT NULL COMMENT '库存ID', `name` varchar(30) NOT NULL DEFAULT '' COMMENT '商品名称', `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '创建时间', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=55 DEFAULT CHARSET=utf8; web 层 controller 实现: 12345678910111213141516171819@Autowiredprivate StockService stockService;@Autowiredprivate OrderService orderService;@RequestMapping("/createWrongOrder/&#123;sid&#125;")@ResponseBodypublic String createWrongOrder(@PathVariable int sid) &#123; logger.info("sid=[&#123;&#125;]", sid); int id = 0; try &#123; id = orderService.createWrongOrder(sid); &#125; catch (Exception e) &#123; logger.error("Exception",e); &#125; return String.valueOf(id);&#125; 其中 web 作为一个消费者调用看 OrderService 提供出来的 dubbo 服务。 Service 层，OrderService 实现： 首先是对 API 的实现(会在 API 提供出接口)： 1234567891011@Servicepublic class OrderServiceImpl implements OrderService &#123; @Resource(name = "DBOrderService") private com.crossoverJie.seconds.kill.service.OrderService orderService ; @Override public int createWrongOrder(int sid) throws Exception &#123; return orderService.createWrongOrder(sid); &#125;&#125; 这里只是简单调用了 DBOrderService 中的实现，DBOrderService 才是真正的数据落地，也就是写数据库了。 DBOrderService 实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546Transactional(rollbackFor = Exception.class)@Service(value = "DBOrderService")public class OrderServiceImpl implements OrderService &#123; @Resource(name = "DBStockService") private com.crossoverJie.seconds.kill.service.StockService stockService; @Autowired private StockOrderMapper orderMapper; @Override public int createWrongOrder(int sid) throws Exception&#123; //校验库存 Stock stock = checkStock(sid); //扣库存 saleStock(stock); //创建订单 int id = createOrder(stock); return id; &#125; private Stock checkStock(int sid) &#123; Stock stock = stockService.getStockById(sid); if (stock.getSale().equals(stock.getCount())) &#123; throw new RuntimeException("库存不足"); &#125; return stock; &#125; private int saleStock(Stock stock) &#123; stock.setSale(stock.getSale() + 1); return stockService.updateStockById(stock); &#125; private int createOrder(Stock stock) &#123; StockOrder order = new StockOrder(); order.setSid(stock.getId()); order.setName(stock.getName()); int id = orderMapper.insertSelective(order); return id; &#125; &#125; 预先初始化了 10 条库存。 手动调用下 createWrongOrder/1 接口发现： 库存表： 订单表： 一切看起来都没有问题，数据也正常。 但是当用 JMeter 并发测试时： 测试配置是：300个线程并发，测试两轮来看看数据库中的结果： 请求都响应成功，库存确实也扣完了，但是订单却生成了 124 条记录。 这显然是典型的超卖现象。 其实现在再去手动调用接口会返回库存不足，但为时晚矣。 乐观锁更新怎么来避免上述的现象呢？ 最简单的做法自然是乐观锁了，这里不过多讨论这个，不熟悉的朋友可以看下这篇。 来看看具体实现： 其实其他的都没怎么改，主要是 Service 层。 123456789101112131415161718192021@Overridepublic int createOptimisticOrder(int sid) throws Exception &#123; //校验库存 Stock stock = checkStock(sid); //乐观锁更新库存 saleStockOptimistic(stock); //创建订单 int id = createOrder(stock); return id;&#125;private void saleStockOptimistic(Stock stock) &#123; int count = stockService.updateStockByOptimistic(stock); if (count == 0)&#123; throw new RuntimeException("并发更新库存失败") ; &#125;&#125; 对应的 XML： 1234567891011&lt;update id="updateByOptimistic" parameterType="com.crossoverJie.seconds.kill.pojo.Stock"&gt; update stock &lt;set&gt; sale = sale + 1, version = version + 1, &lt;/set&gt; WHERE id = #&#123;id,jdbcType=INTEGER&#125; AND version = #&#123;version,jdbcType=INTEGER&#125;&lt;/update&gt; 同样的测试条件，我们再进行上面的测试 /createOptimisticOrder/1： 这次发现无论是库存订单都是 OK 的。 查看日志发现： 很多并发请求会响应错误，这就达到了效果。 提高吞吐量为了进一步提高秒杀时的吞吐量以及响应效率，这里的 web 和 Service 都进行了横向扩展。 web 利用 Nginx 进行负载。 Service 也是多台应用。 再用 JMeter 测试时可以直观的看到效果。 由于我是在阿里云的一台小水管服务器进行测试的，加上配置不高、应用都在同一台，所以并没有完全体现出性能上的优势（ Nginx 做负载转发时候也会增加额外的网络消耗）。 shell 脚本实现简单的 CI由于应用多台部署之后，手动发版测试的痛苦相信经历过的都有体会。 这次并没有精力去搭建完整的 CI CD，只是写了一个简单的脚本实现了自动化部署，希望对这方面没有经验的同学带来一点启发： 构建 web12345678910111213141516171819202122232425262728293031323334353637383940414243#!/bin/bash# 构建 web 消费者#read appnameappname=&quot;consumer&quot;echo &quot;input=&quot;$appnamePID=$(ps -ef | grep $appname | grep -v grep | awk &apos;&#123;print $2&#125;&apos;)# 遍历杀掉 pidfor var in $&#123;PID[@]&#125;;do echo &quot;loop pid= $var&quot; kill -9 $vardoneecho &quot;kill $appname success&quot;cd ..git pullcd SSM-SECONDS-KILLmvn -Dmaven.test.skip=true clean packageecho &quot;build war success&quot;cp /home/crossoverJie/SSM/SSM-SECONDS-KILL/SSM-SECONDS-KILL-WEB/target/SSM-SECONDS-KILL-WEB-2.2.0-SNAPSHOT.war /home/crossoverJie/tomcat/tomcat-dubbo-consumer-8083/webappsecho &quot;cp tomcat-dubbo-consumer-8083/webapps ok!&quot;cp /home/crossoverJie/SSM/SSM-SECONDS-KILL/SSM-SECONDS-KILL-WEB/target/SSM-SECONDS-KILL-WEB-2.2.0-SNAPSHOT.war /home/crossoverJie/tomcat/tomcat-dubbo-consumer-7083-slave/webappsecho &quot;cp tomcat-dubbo-consumer-7083-slave/webapps ok!&quot;sh /home/crossoverJie/tomcat/tomcat-dubbo-consumer-8083/bin/startup.shecho &quot;tomcat-dubbo-consumer-8083/bin/startup.sh success&quot;sh /home/crossoverJie/tomcat/tomcat-dubbo-consumer-7083-slave/bin/startup.shecho &quot;tomcat-dubbo-consumer-7083-slave/bin/startup.sh success&quot;echo &quot;start $appname success&quot; 构建 Service1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 构建服务提供者#read appnameappname=&quot;provider&quot;echo &quot;input=&quot;$appnamePID=$(ps -ef | grep $appname | grep -v grep | awk &apos;&#123;print $2&#125;&apos;)#if [ $? -eq 0 ]; then# echo &quot;process id:$PID&quot;#else# echo &quot;process $appname not exit&quot;# exit#fi# 遍历杀掉 pidfor var in $&#123;PID[@]&#125;;do echo &quot;loop pid= $var&quot; kill -9 $vardoneecho &quot;kill $appname success&quot;cd ..git pullcd SSM-SECONDS-KILLmvn -Dmaven.test.skip=true clean packageecho &quot;build war success&quot;cp /home/crossoverJie/SSM/SSM-SECONDS-KILL/SSM-SECONDS-KILL-SERVICE/target/SSM-SECONDS-KILL-SERVICE-2.2.0-SNAPSHOT.war /home/crossoverJie/tomcat/tomcat-dubbo-provider-8080/webappsecho &quot;cp tomcat-dubbo-provider-8080/webapps ok!&quot;cp /home/crossoverJie/SSM/SSM-SECONDS-KILL/SSM-SECONDS-KILL-SERVICE/target/SSM-SECONDS-KILL-SERVICE-2.2.0-SNAPSHOT.war /home/crossoverJie/tomcat/tomcat-dubbo-provider-7080-slave/webappsecho &quot;cp tomcat-dubbo-provider-7080-slave/webapps ok!&quot;sh /home/crossoverJie/tomcat/tomcat-dubbo-provider-8080/bin/startup.shecho &quot;tomcat-dubbo-provider-8080/bin/startup.sh success&quot;sh /home/crossoverJie/tomcat/tomcat-dubbo-provider-7080-slave/bin/startup.shecho &quot;tomcat-dubbo-provider-8080/bin/startup.sh success&quot;echo &quot;start $appname success&quot; 之后每当我有更新，只需要执行这两个脚本就可以帮我自动构建。 都是最基础的 Linux 命令，相信大家都看得明白。 乐观锁更新 + 分布式限流上文的结果看似没有问题，其实还差得远呢。 这里只是模拟了 300 个并发没有问题，但是当请求达到了 3000 ，3W，300W 呢？ 虽说可以横向扩展可以支撑更多的请求。 但是能不能利用最少的资源解决问题呢？ 其实仔细分析下会发现： 假设我的商品一共只有 10 个库存，那么无论你多少人来买其实最终也最多只有 10 人可以下单成功。 所以其中会有 99% 的请求都是无效的。 大家都知道：大多数应用数据库都是压倒骆驼的最后一根稻草。 通过 Druid 的监控来看看之前请求数据库的情况： 因为 Service 是两个应用。 数据库也有 20 多个连接。 怎么样来优化呢？其实很容易想到的就是分布式限流。 我们将并发控制在一个可控的范围之内，然后快速失败这样就能最大程度的保护系统。 distributed-redis-tool ⬆️v1.0.3为此还对 https://github.com/crossoverJie/distributed-redis-tool 进行了小小的升级。 因为加上该组件之后所有的请求都会经过 Redis，所以对 Redis 资源的使用也是要非常小心。 API 更新修改之后的 API 如下： 123456789101112131415161718192021@Configurationpublic class RedisLimitConfig &#123; private Logger logger = LoggerFactory.getLogger(RedisLimitConfig.class); @Value("$&#123;redis.limit&#125;") private int limit; @Autowired private JedisConnectionFactory jedisConnectionFactory; @Bean public RedisLimit build() &#123; RedisLimit redisLimit = new RedisLimit.Builder(jedisConnectionFactory, RedisToolsConstant.SINGLE) .limit(limit) .build(); return redisLimit; &#125;&#125; 这里构建器改用了 JedisConnectionFactory，所以得配合 Spring 来一起使用。 并在初始化时显示传入 Redis 是以集群方式部署还是单机（强烈建议集群，限流之后对 Redis 还是有一定的压力）。 限流实现既然 API 更新了，实现自然也要修改： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * limit traffic * @return if true */public boolean limit() &#123; //get connection Object connection = getConnection(); Object result = limitRequest(connection); if (FAIL_CODE != (Long) result) &#123; return true; &#125; else &#123; return false; &#125;&#125;private Object limitRequest(Object connection) &#123; Object result = null; String key = String.valueOf(System.currentTimeMillis() / 1000); if (connection instanceof Jedis)&#123; result = ((Jedis)connection).eval(script, Collections.singletonList(key), Collections.singletonList(String.valueOf(limit))); ((Jedis) connection).close(); &#125;else &#123; result = ((JedisCluster) connection).eval(script, Collections.singletonList(key), Collections.singletonList(String.valueOf(limit))); try &#123; ((JedisCluster) connection).close(); &#125; catch (IOException e) &#123; logger.error("IOException",e); &#125; &#125; return result;&#125;private Object getConnection() &#123; Object connection ; if (type == RedisToolsConstant.SINGLE)&#123; RedisConnection redisConnection = jedisConnectionFactory.getConnection(); connection = redisConnection.getNativeConnection(); &#125;else &#123; RedisClusterConnection clusterConnection = jedisConnectionFactory.getClusterConnection(); connection = clusterConnection.getNativeConnection() ; &#125; return connection;&#125; 如果是原生的 Spring 应用得采用 @SpringControllerLimit(errorCode = 200) 注解。 实际使用如下： web 端： 123456789101112131415161718/** * 乐观锁更新库存 限流 * @param sid * @return */@SpringControllerLimit(errorCode = 200)@RequestMapping("/createOptimisticLimitOrder/&#123;sid&#125;")@ResponseBodypublic String createOptimisticLimitOrder(@PathVariable int sid) &#123; logger.info("sid=[&#123;&#125;]", sid); int id = 0; try &#123; id = orderService.createOptimisticOrder(sid); &#125; catch (Exception e) &#123; logger.error("Exception",e); &#125; return String.valueOf(id);&#125; Service 端就没什么更新了，依然是采用的乐观锁更新数据库。 再压测看下效果 /createOptimisticLimitOrderByRedis/1： 首先是看结果没有问题，再看数据库连接以及并发请求数都有明显的下降。 乐观锁更新 + 分布式限流 + Redis 缓存其实仔细观察 Druid 监控数据发现这个 SQL 被多次查询： 其实这是实时查询库存的 SQL，主要是为了在每次下单之前判断是否还有库存。 这也是个优化点。 这种数据我们完全可以放在内存中，效率比在数据库要高很多。 由于我们的应用是分布式的，所以堆内缓存显然不合适，Redis 就非常适合。 这次主要改造的是 Service 层： 每次查询库存时走 Redis。 扣库存时更新 Redis。 需要提前将库存信息写入 Redis（手动或者程序自动都可以）。 主要代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Overridepublic int createOptimisticOrderUseRedis(int sid) throws Exception &#123; //检验库存，从 Redis 获取 Stock stock = checkStockByRedis(sid); //乐观锁更新库存 以及更新 Redis saleStockOptimisticByRedis(stock); //创建订单 int id = createOrder(stock); return id ;&#125;private Stock checkStockByRedis(int sid) throws Exception &#123; Integer count = Integer.parseInt(redisTemplate.opsForValue().get(RedisKeysConstant.STOCK_COUNT + sid)); Integer sale = Integer.parseInt(redisTemplate.opsForValue().get(RedisKeysConstant.STOCK_SALE + sid)); if (count.equals(sale))&#123; throw new RuntimeException("库存不足 Redis currentCount=" + sale); &#125; Integer version = Integer.parseInt(redisTemplate.opsForValue().get(RedisKeysConstant.STOCK_VERSION + sid)); Stock stock = new Stock() ; stock.setId(sid); stock.setCount(count); stock.setSale(sale); stock.setVersion(version); return stock;&#125; /** * 乐观锁更新数据库 还要更新 Redis * @param stock */private void saleStockOptimisticByRedis(Stock stock) &#123; int count = stockService.updateStockByOptimistic(stock); if (count == 0)&#123; throw new RuntimeException("并发更新库存失败") ; &#125; //自增 redisTemplate.opsForValue().increment(RedisKeysConstant.STOCK_SALE + stock.getId(),1) ; redisTemplate.opsForValue().increment(RedisKeysConstant.STOCK_VERSION + stock.getId(),1) ;&#125; 压测看看实际效果 /createOptimisticLimitOrderByRedis/1： 最后发现数据没问题，数据库的请求与并发也都下来了。 乐观锁更新 + 分布式限流 + Redis 缓存 + Kafka 异步最后的优化还是想如何来再次提高吞吐量以及性能的。 我们上文所有例子其实都是同步请求，完全可以利用同步转异步来提高性能啊。 这里我们将写订单以及更新库存的操作进行异步化，利用 Kafka 来进行解耦和队列的作用。 每当一个请求通过了限流到达了 Service 层通过了库存校验之后就将订单信息发给 Kafka ，这样一个请求就可以直接返回了。 消费程序再对数据进行入库落地。 因为异步了，所以最终需要采取回调或者是其他提醒的方式提醒用户购买完成。 这里代码较多就不贴了，消费程序其实就是把之前的 Service 层的逻辑重写了一遍，不过采用的是 SpringBoot。 感兴趣的朋友可以看下。 https://github.com/crossoverJie/SSM/tree/master/SSM-SECONDS-KILL/SSM-SECONDS-KILL-ORDER-CONSUMER 总结其实经过上面的一顿优化总结起来无非就是以下几点： 尽量将请求拦截在上游。 还可以根据 UID 进行限流。 最大程度的减少请求落到 DB。 多利用缓存。 同步操作异步化。 fail fast，尽早失败，保护应用。 码字不易，这应该是我写过字数最多的了，想想当年高中 800 字的作文都憋不出来😂，可想而知是有多难得了。 以上内容欢迎讨论。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>SSM</category>
        <category>Distributed Tools</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Kafka</tag>
        <tag>Redis</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(七)分布式限流]]></title>
    <url>%2F2018%2F04%2F28%2Fsbc%2Fsbc7-Distributed-Limit%2F</url>
    <content type="text"><![CDATA[前言本文接着上文应用限流进行讨论。 之前谈到的限流方案只能针对于单个 JVM 有效，也就是单机应用。而对于现在普遍的分布式应用也得有一个分布式限流的方案。 基于此尝试写了这个组件： https://github.com/crossoverJie/distributed-redis-tool DEMO以下采用的是 https://github.com/crossoverJie/springboot-cloud 来做演示。 在 Order 应用提供的接口中采取了限流。首先是配置了限流工具的 Bean: 12345678910111213141516171819202122@Configurationpublic class RedisLimitConfig &#123; @Value("$&#123;redis.limit&#125;") private int limit; @Autowired private JedisConnectionFactory jedisConnectionFactory; @Bean public RedisLimit build() &#123; RedisClusterConnection clusterConnection = jedisConnectionFactory.getClusterConnection(); JedisCluster jedisCluster = (JedisCluster) clusterConnection.getNativeConnection(); RedisLimit redisLimit = new RedisLimit.Builder&lt;&gt;(jedisCluster) .limit(limit) .build(); return redisLimit; &#125;&#125; 接着在 Controller 使用组件： 123456789101112131415161718192021222324252627@Autowiredprivate RedisLimit redisLimit ;@Override@CheckReqNopublic BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) &#123; BaseResponse&lt;OrderNoResVO&gt; res = new BaseResponse(); //限流 boolean limit = redisLimit.limit(); if (!limit)&#123; res.setCode(StatusEnum.REQUEST_LIMIT.getCode()); res.setMessage(StatusEnum.REQUEST_LIMIT.getMessage()); return res ; &#125; res.setReqNo(orderNoReq.getReqNo()); if (null == orderNoReq.getAppId())&#123; throw new SBCException(StatusEnum.FAIL); &#125; OrderNoResVO orderNoRes = new OrderNoResVO() ; orderNoRes.setOrderId(DateUtil.getLongTime()); res.setCode(StatusEnum.SUCCESS.getCode()); res.setMessage(StatusEnum.SUCCESS.getMessage()); res.setDataBody(orderNoRes); return res ;&#125; 为了方便使用，也提供了注解: 1234567@Override@ControllerLimitpublic BaseResponse&lt;OrderNoResVO&gt; getOrderNoLimit(@RequestBody OrderNoReqVO orderNoReq) &#123; BaseResponse&lt;OrderNoResVO&gt; res = new BaseResponse(); // 业务逻辑 return res ;&#125; 该注解拦截了 http 请求，会再请求达到阈值时直接返回。 普通方法也可使用: 12@CommonLimitpublic void doSomething()&#123;&#125; 会在调用达到阈值时抛出异常。 为了模拟并发，在 User 应用中开启了 10 个线程调用 Order(限流次数为5) 接口(也可使用专业的并发测试工具 JMeter 等)。 1234567891011121314151617181920212223242526272829303132333435363738394041@Overridepublic BaseResponse&lt;UserResVO&gt; getUserByFeign(@RequestBody UserReqVO userReq) &#123; //调用远程服务 OrderNoReqVO vo = new OrderNoReqVO(); vo.setAppId(1L); vo.setReqNo(userReq.getReqNo()); for (int i = 0; i &lt; 10; i++) &#123; executorService.execute(new Worker(vo, orderServiceClient)); &#125; UserRes userRes = new UserRes(); userRes.setUserId(123); userRes.setUserName("张三"); userRes.setReqNo(userReq.getReqNo()); userRes.setCode(StatusEnum.SUCCESS.getCode()); userRes.setMessage("成功"); return userRes;&#125;private static class Worker implements Runnable &#123; private OrderNoReqVO vo; private OrderServiceClient orderServiceClient; public Worker(OrderNoReqVO vo, OrderServiceClient orderServiceClient) &#123; this.vo = vo; this.orderServiceClient = orderServiceClient; &#125; @Override public void run() &#123; BaseResponse&lt;OrderNoResVO&gt; orderNo = orderServiceClient.getOrderNoCommonLimit(vo); logger.info("远程返回:" + JSON.toJSONString(orderNo)); &#125;&#125; 为了验证分布式效果启动了两个 Order 应用。 效果如下： 实现原理实现原理其实很简单。既然要达到分布式全局限流的效果，那自然需要一个第三方组件来记录请求的次数。 其中 Redis 就非常适合这样的场景。 每次请求时将当前时间(精确到秒)作为 Key 写入到 Redis 中，超时时间设置为 2 秒，Redis 将该 Key 的值进行自增。 当达到阈值时返回错误。 写入 Redis 的操作用 Lua 脚本来完成，利用 Redis 的单线程机制可以保证每个 Redis 请求的原子性。 Lua 脚本如下: 123456789101112131415161718--lua 下标从 1 开始-- 限流 keylocal key = KEYS[1]-- 限流大小local limit = tonumber(ARGV[1])-- 获取当前流量大小local curentLimit = tonumber(redis.call('get', key) or "0")if curentLimit + 1 &gt; limit then -- 达到限流大小 返回 return 0;else -- 没有达到阈值 value + 1 redis.call("INCRBY", key, 1) redis.call("EXPIRE", key, 2) return curentLimit + 1end Java 中的调用逻辑: 123456789101112131415161718public boolean limit() &#123; String key = String.valueOf(System.currentTimeMillis() / 1000); Object result = null; if (jedis instanceof Jedis) &#123; result = ((Jedis) this.jedis).eval(script, Collections.singletonList(key), Collections.singletonList(String.valueOf(limit))); &#125; else if (jedis instanceof JedisCluster) &#123; result = ((JedisCluster) this.jedis).eval(script, Collections.singletonList(key), Collections.singletonList(String.valueOf(limit))); &#125; else &#123; //throw new RuntimeException("instance is error") ; return false; &#125; if (FAIL_CODE != (Long) result) &#123; return true; &#125; else &#123; return false; &#125;&#125; 所以只需要在需要限流的地方调用该方法对返回值进行判断即可达到限流的目的。 当然这只是利用 Redis 做了一个粗暴的计数器，如果想实现类似于上文中的令牌桶算法可以基于 Lua 自行实现。 Builder 构建器在设计这个组件时想尽量的提供给使用者清晰、可读性、不易出错的 API。 比如第一步，如何构建一个限流对象。 最常用的方式自然就是构造函数，如果有多个域则可以采用重叠构造器的方式: 123public A()&#123;&#125;public A(int a)&#123;&#125;public A(int a,int b)&#123;&#125; 缺点也是显而易见的：如果参数过多会导致难以阅读，甚至如果参数类型一致的情况下客户端颠倒了顺序，但不会引起警告从而出现难以预测的结果。 第二种方案可以采用 JavaBean 模式，利用 setter 方法进行构建: 123A a = new A();a.setA(a);a.setB(b); 这种方式清晰易读，但却容易让对象处于不一致的状态，使对象处于线程不安全的状态。 所以这里采用了第三种创建对象的方式，构建器： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class RedisLimit &#123; private JedisCommands jedis; private int limit = 200; private static final int FAIL_CODE = 0; /** * lua script */ private String script; private RedisLimit(Builder builder) &#123; this.limit = builder.limit ; this.jedis = builder.jedis ; buildScript(); &#125; /** * limit traffic * @return if true */ public boolean limit() &#123; String key = String.valueOf(System.currentTimeMillis() / 1000); Object result = null; if (jedis instanceof Jedis) &#123; result = ((Jedis) this.jedis).eval(script, Collections.singletonList(key), Collections.singletonList(String.valueOf(limit))); &#125; else if (jedis instanceof JedisCluster) &#123; result = ((JedisCluster) this.jedis).eval(script, Collections.singletonList(key), Collections.singletonList(String.valueOf(limit))); &#125; else &#123; //throw new RuntimeException("instance is error") ; return false; &#125; if (FAIL_CODE != (Long) result) &#123; return true; &#125; else &#123; return false; &#125; &#125; /** * read lua script */ private void buildScript() &#123; script = ScriptUtil.getScript("limit.lua"); &#125; /** * the builder * @param &lt;T&gt; */ public static class Builder&lt;T extends JedisCommands&gt;&#123; private T jedis = null ; private int limit = 200; public Builder(T jedis)&#123; this.jedis = jedis ; &#125; public Builder limit(int limit)&#123; this.limit = limit ; return this; &#125; public RedisLimit build()&#123; return new RedisLimit(this) ; &#125; &#125;&#125; 这样客户端在使用时: 123RedisLimit redisLimit = new RedisLimit.Builder&lt;&gt;(jedisCluster) .limit(limit) .build(); 更加的简单直接，并且避免了将创建过程分成了多个子步骤。 这在有多个构造参数，但又不是必选字段时很有作用。 因此顺便将分布式锁的构建器方式也一并更新了： https://github.com/crossoverJie/distributed-redis-tool#features 更多内容可以参考 Effective Java API从上文可以看出，使用过程就是调用 limit 方法。 12345//限流 boolean limit = redisLimit.limit(); if (!limit)&#123; //具体限流逻辑 &#125; 为了减少侵入性，也为了简化客户端提供了两种注解方式。 @ControllerLimit该注解可以作用于 @RequestMapping 修饰的接口中，并会在限流后提供限流响应。 实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Componentpublic class WebIntercept extends WebMvcConfigurerAdapter &#123; private static Logger logger = LoggerFactory.getLogger(WebIntercept.class); @Autowired private RedisLimit redisLimit; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new CustomInterceptor()) .addPathPatterns("/**"); &#125; private class CustomInterceptor extends HandlerInterceptorAdapter &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (redisLimit == null) &#123; throw new NullPointerException("redisLimit is null"); &#125; if (handler instanceof HandlerMethod) &#123; HandlerMethod method = (HandlerMethod) handler; ControllerLimit annotation = method.getMethodAnnotation(ControllerLimit.class); if (annotation == null) &#123; //skip return true; &#125; boolean limit = redisLimit.limit(); if (!limit) &#123; logger.warn("request has bean limit"); response.sendError(500, "request limit"); return false; &#125; &#125; return true; &#125; &#125;&#125; 其实就是实现了 SpringMVC 中的拦截器，并在拦截过程中判断是否有使用注解，从而调用限流逻辑。 前提是应用需要扫描到该类，让 Spring 进行管理。 1@ComponentScan(value = "com.crossoverjie.distributed.intercept") @CommonLimit当然也可以在普通方法中使用。实现原理则是 Spring AOP (SpringMVC 的拦截器本质也是 AOP)。 12345678910111213141516171819202122232425262728@Aspect@Component@EnableAspectJAutoProxy(proxyTargetClass = true)public class CommonAspect &#123; private static Logger logger = LoggerFactory.getLogger(CommonAspect.class); @Autowired private RedisLimit redisLimit ; @Pointcut("@annotation(com.crossoverjie.distributed.annotation.CommonLimit)") private void check()&#123;&#125; @Before("check()") public void before(JoinPoint joinPoint) throws Exception &#123; if (redisLimit == null) &#123; throw new NullPointerException("redisLimit is null"); &#125; boolean limit = redisLimit.limit(); if (!limit) &#123; logger.warn("request has bean limit"); throw new RuntimeException("request has bean limit") ; &#125; &#125;&#125; 很简单，也是在拦截过程中调用限流。 当然使用时也得扫描到该包: 1@ComponentScan(value = "com.crossoverjie.distributed.intercept") 总结限流在一个高并发大流量的系统中是保护应用的一个利器，成熟的方案也很多，希望对刚了解这一块的朋友提供一些思路。 以上所有的源码： https://github.com/crossoverJie/distributed-redis-tool https://github.com/crossoverJie/springboot-cloud 感兴趣的朋友可以点个 Star 或是提交 PR。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>sbc</category>
        <category>Distributed Tools</category>
      </categories>
      <tags>
        <tag>Distributed Limited</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【译】对于初学者什么是最好的编程语言？]]></title>
    <url>%2F2018%2F04%2F12%2Ftranslation%2Ftranslation-What%20Is%20The%20Best%20Programming%20Language%20to%20Start%2F</url>
    <content type="text"><![CDATA[原文链接Python？Java？Ruby？JavaScript？有非常多的选择。选择一种编程语言开始你的编码之旅不应该是一件艰巨的任务。 事实上：你将要学习的语言并不是特别重要，更重要的是学习编程的理念。对于任何编程语言来说知识的可传递性都是至关重要的。 我学习的第一门语言是 Java，学习了循环，while 循环，条件，函数，面向对象编程和许多编程理念。 然而，选择一门能在编程领域轻松找到工作的语言是更好的选择。对于初学者来说，我这里有一份列表推荐给你： PythonPython 在美国大学里是最受欢迎的入门型语言。 就像 JavaScript 一样，Python 也非常灵活，现在被用于构建生物信息学的 web 应用。我强烈推荐你学习 Python，它是很棒的入门选择。 JavaJava 是企业环境中使用最多的语言，根据 TIOBE 统计 Java 长年占据编程语言榜首。同时 Java 是强类型地静态语言，可以更容易地去描述一些编程理念。 Java 作为最常使用的语言，你可以很轻松地在这段编程之旅中找到 Java 的相关课程和指南来获得帮助。你还可以使用 Java 构建服务端应用、Android APP 等应用程序。 RubyRuby 是我最喜欢的编程语言，它编写简单，容易理解并且使用顺手。 就像 JavaScript 一样，它学起来简单但是不易掌握。Ruby 在很多公司中被广泛应用，比如 Airbnb, EBANX, Shopify, Twitter, GitHub 等等。它还有一个超赞的 7*24 小时的在线社区随时提供帮助。Ruby 以 Ruby on Rails 框架著称，它可以帮你很轻松的构建整个 web 应用。 JavaScriptJavaScript 是我用过的最灵活的语言之一。 你能用它构建控制台程序，桌面软件，手机 APP，前端开发，后端开发等等。它是一个很不错的编程语言，简单易学但难以掌握。 我建议你学习并掌握 JavaScript ，但不是作为第一门语言。 对于初学者来说 JavaScript 很难调试并且不容易学习编程理念比如异步，原型，面向对象等等。 不要纠结语言你需要通过选择一门语言来学习编程理念，当你学完之后你将花费较小的学习曲线来学习任何其他的语言。 如果你想要学习如何学习一门新语言的话，可以阅读我的文章 “How to Learn a New Programming Language or Framework”，将会非常有用。]]></content>
      <categories>
        <category>翻译</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[动手实现一个 LRU cache]]></title>
    <url>%2F2018%2F04%2F07%2Falgorithm%2FLRU-cache%2F</url>
    <content type="text"><![CDATA[前言LRU 是 Least Recently Used 的简写，字面意思则是最近最少使用。 通常用于缓存的淘汰策略实现，由于缓存的内存非常宝贵，所以需要根据某种规则来剔除数据保证内存不被撑满。 如常用的 Redis 就有以下几种策略： 策略 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 no-envicition 禁止驱逐数据 摘抄自:https://github.com/CyC2018/Interview-Notebook/blob/master/notes/Redis.md#%E5%8D%81%E4%B8%89%E6%95%B0%E6%8D%AE%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5 实现一之前也有接触过一道面试题，大概需求是： 实现一个 LRU 缓存，当缓存数据达到 N 之后需要淘汰掉最近最少使用的数据。 N 小时之内没有被访问的数据也需要淘汰掉。 以下是我的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323public class LRUAbstractMap extends java.util.AbstractMap &#123; private final static Logger LOGGER = LoggerFactory.getLogger(LRUAbstractMap.class); /** * 检查是否超期线程 */ private ExecutorService checkTimePool ; /** * map 最大size */ private final static int MAX_SIZE = 1024 ; private final static ArrayBlockingQueue&lt;Node&gt; QUEUE = new ArrayBlockingQueue&lt;&gt;(MAX_SIZE) ; /** * 默认大小 */ private final static int DEFAULT_ARRAY_SIZE =1024 ; /** * 数组长度 */ private int arraySize ; /** * 数组 */ private Object[] arrays ; /** * 判断是否停止 flag */ private volatile boolean flag = true ; /** * 超时时间 */ private final static Long EXPIRE_TIME = 60 * 60 * 1000L ; /** * 整个 Map 的大小 */ private volatile AtomicInteger size ; public LRUAbstractMap() &#123; arraySize = DEFAULT_ARRAY_SIZE; arrays = new Object[arraySize] ; //开启一个线程检查最先放入队列的值是否超期 executeCheckTime(); &#125; /** * 开启一个线程检查最先放入队列的值是否超期 设置为守护线程 */ private void executeCheckTime() &#123; ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat("check-thread-%d") .setDaemon(true) .build(); checkTimePool = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;&gt;(1),namedThreadFactory,new ThreadPoolExecutor.AbortPolicy()); checkTimePool.execute(new CheckTimeThread()) ; &#125; @Override public Set&lt;Entry&gt; entrySet() &#123; return super.keySet(); &#125; @Override public Object put(Object key, Object value) &#123; int hash = hash(key); int index = hash % arraySize ; Node currentNode = (Node) arrays[index] ; if (currentNode == null)&#123; arrays[index] = new Node(null,null, key, value); //写入队列 QUEUE.offer((Node) arrays[index]) ; sizeUp(); &#125;else &#123; Node cNode = currentNode ; Node nNode = cNode ; //存在就覆盖 if (nNode.key == key)&#123; cNode.val = value ; &#125; while (nNode.next != null)&#123; //key 存在 就覆盖 简单判断 if (nNode.key == key)&#123; nNode.val = value ; break ; &#125;else &#123; //不存在就新增链表 sizeUp(); Node node = new Node(nNode,null,key,value) ; //写入队列 QUEUE.offer(currentNode) ; cNode.next = node ; &#125; nNode = nNode.next ; &#125; &#125; return null ; &#125; @Override public Object get(Object key) &#123; int hash = hash(key) ; int index = hash % arraySize ; Node currentNode = (Node) arrays[index] ; if (currentNode == null)&#123; return null ; &#125; if (currentNode.next == null)&#123; //更新时间 currentNode.setUpdateTime(System.currentTimeMillis()); //没有冲突 return currentNode ; &#125; Node nNode = currentNode ; while (nNode.next != null)&#123; if (nNode.key == key)&#123; //更新时间 currentNode.setUpdateTime(System.currentTimeMillis()); return nNode ; &#125; nNode = nNode.next ; &#125; return super.get(key); &#125; @Override public Object remove(Object key) &#123; int hash = hash(key) ; int index = hash % arraySize ; Node currentNode = (Node) arrays[index] ; if (currentNode == null)&#123; return null ; &#125; if (currentNode.key == key)&#123; sizeDown(); arrays[index] = null ; //移除队列 QUEUE.poll(); return currentNode ; &#125; Node nNode = currentNode ; while (nNode.next != null)&#123; if (nNode.key == key)&#123; sizeDown(); //在链表中找到了 把上一个节点的 next 指向当前节点的下一个节点 nNode.pre.next = nNode.next ; nNode = null ; //移除队列 QUEUE.poll(); return nNode; &#125; nNode = nNode.next ; &#125; return super.remove(key); &#125; /** * 增加size */ private void sizeUp()&#123; //在put值时候认为里边已经有数据了 flag = true ; if (size == null)&#123; size = new AtomicInteger() ; &#125; int size = this.size.incrementAndGet(); if (size &gt;= MAX_SIZE) &#123; //找到队列头的数据 Node node = QUEUE.poll() ; if (node == null)&#123; throw new RuntimeException("data error") ; &#125; //移除该 key Object key = node.key ; remove(key) ; lruCallback() ; &#125; &#125; /** * 数量减小 */ private void sizeDown()&#123; if (QUEUE.size() == 0)&#123; flag = false ; &#125; this.size.decrementAndGet() ; &#125; @Override public int size() &#123; return size.get() ; &#125; /** * 链表 */ private class Node&#123; private Node next ; private Node pre ; private Object key ; private Object val ; private Long updateTime ; public Node(Node pre,Node next, Object key, Object val) &#123; this.pre = pre ; this.next = next; this.key = key; this.val = val; this.updateTime = System.currentTimeMillis() ; &#125; public void setUpdateTime(Long updateTime) &#123; this.updateTime = updateTime; &#125; public Long getUpdateTime() &#123; return updateTime; &#125; @Override public String toString() &#123; return "Node&#123;" + "key=" + key + ", val=" + val + '&#125;'; &#125; &#125; /** * copy HashMap 的 hash 实现 * @param key * @return */ public int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; private void lruCallback()&#123; LOGGER.debug("lruCallback"); &#125; private class CheckTimeThread implements Runnable&#123; @Override public void run() &#123; while (flag)&#123; try &#123; Node node = QUEUE.poll(); if (node == null)&#123; continue ; &#125; Long updateTime = node.getUpdateTime() ; if ((updateTime - System.currentTimeMillis()) &gt;= EXPIRE_TIME)&#123; remove(node.key) ; &#125; &#125; catch (Exception e) &#123; LOGGER.error("InterruptedException"); &#125; &#125; &#125; &#125;&#125; 感兴趣的朋友可以直接从: https://github.com/crossoverJie/Java-Interview/blob/master/src/main/java/com/crossoverjie/actual/LRUAbstractMap.java 下载代码本地运行。 代码看着比较多，其实实现的思路还是比较简单： 采用了与 HashMap 一样的保存数据方式，只是自己手动实现了一个简易版。 内部采用了一个队列来保存每次写入的数据。 写入的时候判断缓存是否大于了阈值 N，如果满足则根据队列的 FIFO 特性将队列头的数据删除。因为队列头的数据肯定是最先放进去的。 再开启了一个守护线程用于判断最先放进去的数据是否超期（因为就算超期也是最先放进去的数据最有可能满足超期条件。） 设置为守护线程可以更好的表明其目的（最坏的情况下，如果是一个用户线程最终有可能导致程序不能正常退出，因为该线程一直在运行，守护线程则不会有这个情况。） 以上代码大体功能满足了，但是有一个致命问题。 就是最近最少使用没有满足，删除的数据都是最先放入的数据。 不过其中的 put get 流程算是一个简易的 HashMap 实现，可以对 HashMap 加深一些理解。 实现二因此如何来实现一个完整的 LRU 缓存呢，这次不考虑过期时间的问题。 其实从上一个实现也能想到一些思路： 要记录最近最少使用，那至少需要一个有序的集合来保证写入的顺序。 在使用了数据之后能够更新它的顺序。 基于以上两点很容易想到一个常用的数据结构：链表。 每次写入数据时将数据放入链表头结点。 使用数据时候将数据移动到头结点。 缓存数量超过阈值时移除链表尾部数据。 因此有了以下实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211public class LRUMap&lt;K, V&gt; &#123; private final Map&lt;K, V&gt; cacheMap = new HashMap&lt;&gt;(); /** * 最大缓存大小 */ private int cacheSize; /** * 节点大小 */ private int nodeCount; /** * 头结点 */ private Node&lt;K, V&gt; header; /** * 尾结点 */ private Node&lt;K, V&gt; tailer; public LRUMap(int cacheSize) &#123; this.cacheSize = cacheSize; //头结点的下一个结点为空 header = new Node&lt;&gt;(); header.next = null; //尾结点的上一个结点为空 tailer = new Node&lt;&gt;(); tailer.tail = null; //双向链表 头结点的上结点指向尾结点 header.tail = tailer; //尾结点的下结点指向头结点 tailer.next = header; &#125; public void put(K key, V value) &#123; cacheMap.put(key, value); //双向链表中添加结点 addNode(key, value); &#125; public V get(K key)&#123; Node&lt;K, V&gt; node = getNode(key); //移动到头结点 moveToHead(node) ; return cacheMap.get(key); &#125; private void moveToHead(Node&lt;K,V&gt; node)&#123; //如果是最后的一个节点 if (node.tail == null)&#123; node.next.tail = null ; tailer = node.next ; nodeCount -- ; &#125; //如果是本来就是头节点 不作处理 if (node.next == null)&#123; return ; &#125; //如果处于中间节点 if (node.tail != null &amp;&amp; node.next != null)&#123; //它的上一节点指向它的下一节点 也就删除当前节点 node.tail.next = node.next ; nodeCount -- ; &#125; //最后在头部增加当前节点 //注意这里需要重新 new 一个对象，不然原本的node 还有着下面的引用，会造成内存溢出。 node = new Node&lt;&gt;(node.getKey(),node.getValue()) ; addHead(node) ; &#125; /** * 链表查询 效率较低 * @param key * @return */ private Node&lt;K,V&gt; getNode(K key)&#123; Node&lt;K,V&gt; node = tailer ; while (node != null)&#123; if (node.getKey().equals(key))&#123; return node ; &#125; node = node.next ; &#125; return null ; &#125; /** * 写入头结点 * @param key * @param value */ private void addNode(K key, V value) &#123; Node&lt;K, V&gt; node = new Node&lt;&gt;(key, value); //容量满了删除最后一个 if (cacheSize == nodeCount) &#123; //删除尾结点 delTail(); &#125; //写入头结点 addHead(node); &#125; /** * 添加头结点 * * @param node */ private void addHead(Node&lt;K, V&gt; node) &#123; //写入头结点 header.next = node; node.tail = header; header = node; nodeCount++; //如果写入的数据大于2个 就将初始化的头尾结点删除 if (nodeCount == 2) &#123; tailer.next.next.tail = null; tailer = tailer.next.next; &#125; &#125; private void delTail() &#123; //把尾结点从缓存中删除 cacheMap.remove(tailer.getKey()); //删除尾结点 tailer.next.tail = null; tailer = tailer.next; nodeCount--; &#125; private class Node&lt;K, V&gt; &#123; private K key; private V value; Node&lt;K, V&gt; tail; Node&lt;K, V&gt; next; public Node(K key, V value) &#123; this.key = key; this.value = value; &#125; public Node() &#123; &#125; public K getKey() &#123; return key; &#125; public void setKey(K key) &#123; this.key = key; &#125; public V getValue() &#123; return value; &#125; public void setValue(V value) &#123; this.value = value; &#125; &#125; @Override public String toString() &#123; StringBuilder sb = new StringBuilder() ; Node&lt;K,V&gt; node = tailer ; while (node != null)&#123; sb.append(node.getKey()).append(":") .append(node.getValue()) .append("--&gt;") ; node = node.next ; &#125; return sb.toString(); &#125;&#125; 源码：https://github.com/crossoverJie/Java-Interview/blob/master/src/main/java/com/crossoverjie/actual/LRUMap.java 实际效果，写入时： 1234567891011121314151617181920 @Test public void put() throws Exception &#123; LRUMap&lt;String,Integer&gt; lruMap = new LRUMap(3) ; lruMap.put("1",1) ; lruMap.put("2",2) ; lruMap.put("3",3) ; System.out.println(lruMap.toString()); lruMap.put("4",4) ; System.out.println(lruMap.toString()); lruMap.put("5",5) ; System.out.println(lruMap.toString()); &#125;//输出：1:1--&gt;2:2--&gt;3:3--&gt;2:2--&gt;3:3--&gt;4:4--&gt;3:3--&gt;4:4--&gt;5:5--&gt; 使用时： 12345678910111213141516171819202122 @Test public void get() throws Exception &#123; LRUMap&lt;String,Integer&gt; lruMap = new LRUMap(3) ; lruMap.put("1",1) ; lruMap.put("2",2) ; lruMap.put("3",3) ; System.out.println(lruMap.toString()); System.out.println("=============="); Integer integer = lruMap.get("1"); System.out.println(integer); System.out.println("=============="); System.out.println(lruMap.toString()); &#125; //输出1:1--&gt;2:2--&gt;3:3--&gt;==============1==============2:2--&gt;3:3--&gt;1:1--&gt; 实现思路和上文提到的一致，说下重点： 数据是直接利用 HashMap 来存放的。 内部使用了一个双向链表来存放数据，所以有一个头结点 header，以及尾结点 tailer。 每次写入头结点，删除尾结点时都是依赖于 header tailer，如果看着比较懵建议自己实现一个链表熟悉下，或结合下文的对象关系图一起理解。 使用数据移动到链表头时，第一步是需要在双向链表中找到该节点。这里就体现出链表的问题了。查找效率很低，最差需要 O(N)。之后依赖于当前节点进行移动。 在写入头结点时有判断链表大小等于 2 时需要删除初始化的头尾结点。这是因为初始化时候生成了两个双向节点，没有数据只是为了形成一个数据结构。当真实数据进来之后需要删除以方便后续的操作（这点可以继续优化）。 以上的所有操作都是线程不安全的，需要使用者自行控制。 下面是对象关系图： 初始化时 写入数据时12LRUMap&lt;String,Integer&gt; lruMap = new LRUMap(3) ;lruMap.put("1",1) ; 1lruMap.put("2",2) ; 1lruMap.put("3",3) ; 1lruMap.put("4",4) ; 获取数据时数据和上文一样： 1Integer integer = lruMap.get("2"); 通过以上几张图应该是很好理解数据是如何存放的了。 实现三其实如果对 Java 的集合比较熟悉的话，会发现上文的结构和 LinkedHashMap 非常类似。 对此不太熟悉的朋友可以先了解下 LinkedHashMap 底层分析 。 所以我们完全可以借助于它来实现： 123456789101112131415161718192021222324252627282930313233343536373839public class LRULinkedMap&lt;K,V&gt; &#123; /** * 最大缓存大小 */ private int cacheSize; private LinkedHashMap&lt;K,V&gt; cacheMap ; public LRULinkedMap(int cacheSize) &#123; this.cacheSize = cacheSize; cacheMap = new LinkedHashMap(16,0.75F,true)&#123; @Override protected boolean removeEldestEntry(Map.Entry eldest) &#123; if (cacheSize + 1 == cacheMap.size())&#123; return true ; &#125;else &#123; return false ; &#125; &#125; &#125;; &#125; public void put(K key,V value)&#123; cacheMap.put(key,value) ; &#125; public V get(K key)&#123; return cacheMap.get(key) ; &#125; public Collection&lt;Map.Entry&lt;K, V&gt;&gt; getAll() &#123; return new ArrayList&lt;Map.Entry&lt;K, V&gt;&gt;(cacheMap.entrySet()); &#125;&#125; 源码：https://github.com/crossoverJie/Java-Interview/blob/master/src/main/java/com/crossoverjie/actual/LRULinkedMap.java 这次就比较简洁了，也就几行代码（具体的逻辑 LinkedHashMap 已经帮我们实现好了） 实际效果: 123456789101112131415161718192021 @Test public void put() throws Exception &#123; LRULinkedMap&lt;String,Integer&gt; map = new LRULinkedMap(3) ; map.put("1",1); map.put("2",2); map.put("3",3); for (Map.Entry&lt;String, Integer&gt; e : map.getAll())&#123; System.out.print(e.getKey() + " : " + e.getValue() + "\t"); &#125; System.out.println(""); map.put("4",4); for (Map.Entry&lt;String, Integer&gt; e : map.getAll())&#123; System.out.print(e.getKey() + " : " + e.getValue() + "\t"); &#125; &#125; //输出1 : 1 2 : 2 3 : 3 2 : 2 3 : 3 4 : 4 使用时： 123456789101112131415161718192021222324 @Test public void get() throws Exception &#123; LRULinkedMap&lt;String,Integer&gt; map = new LRULinkedMap(4) ; map.put("1",1); map.put("2",2); map.put("3",3); map.put("4",4); for (Map.Entry&lt;String, Integer&gt; e : map.getAll())&#123; System.out.print(e.getKey() + " : " + e.getValue() + "\t"); &#125; System.out.println(""); map.get("1") ; for (Map.Entry&lt;String, Integer&gt; e : map.getAll())&#123; System.out.print(e.getKey() + " : " + e.getValue() + "\t"); &#125; &#125;&#125;//输出1 : 1 2 : 2 3 : 3 4 : 4 2 : 2 3 : 3 4 : 4 1 : 1 LinkedHashMap 内部也有维护一个双向队列，在初始化时也会给定一个缓存大小的阈值。初始化时自定义是否需要删除最近不常使用的数据，如果是则会按照实现二中的方式管理数据。 其实主要代码就是重写了 LinkedHashMap 的 removeEldestEntry 方法: 123protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; 它默认是返回 false，也就是不会管有没有超过阈值。 所以我们自定义大于了阈值时返回 true，这样 LinkedHashMap 就会帮我们删除最近最少使用的数据。 总结以上就是对 LRU 缓存的实现，了解了这些至少在平时使用时可以知其所以然。 当然业界使用较多的还有 guava 的实现，并且它还支持多种过期策略。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>算法</category>
        <category>LRU cache</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于 Redis 的分布式锁]]></title>
    <url>%2F2018%2F03%2F29%2Fdistributed-lock%2Fdistributed-lock-redis%2F</url>
    <content type="text"><![CDATA[前言分布式锁在分布式应用中应用广泛，想要搞懂一个新事物首先得了解它的由来，这样才能更加的理解甚至可以举一反三。 首先谈到分布式锁自然也就联想到分布式应用。 在我们将应用拆分为分布式应用之前的单机系统中，对一些并发场景读取公共资源时如扣库存，卖车票之类的需求可以简单的使用同步或者是加锁就可以实现。 但是应用分布式了之后系统由以前的单进程多线程的程序变为了多进程多线程，这时使用以上的解决方案明显就不够了。 因此业界常用的解决方案通常是借助于一个第三方组件并利用它自身的排他性来达到多进程的互斥。如： 基于 DB 的唯一索引。 基于 ZK 的临时有序节点。 基于 Redis 的 NX EX 参数。 这里主要基于 Redis 进行讨论。 实现既然是选用了 Redis，那么它就得具有排他性才行。同时它最好也有锁的一些基本特性： 高性能(加、解锁时高性能) 可以使用阻塞锁与非阻塞锁。 不能出现死锁。 可用性(不能出现节点 down 掉后加锁失败)。 这里利用 Redis set key 时的一个 NX 参数可以保证在这个 key 不存在的情况下写入成功。并且再加上 EX 参数可以让该 key 在超时之后自动删除。 所以利用以上两个特性可以保证在同一时刻只会有一个进程获得锁，并且不会出现死锁(最坏的情况就是超时自动删除 key)。 加锁实现代码如下： 12345678910111213private static final String SET_IF_NOT_EXIST = "NX";private static final String SET_WITH_EXPIRE_TIME = "PX";public boolean tryLock(String key, String request) &#123; String result = this.jedis.set(LOCK_PREFIX + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); if (LOCK_MSG.equals(result))&#123; return true ; &#125;else &#123; return false ; &#125;&#125; 注意这里使用的 jedis 的 1String set(String key, String value, String nxxx, String expx, long time); api。 该命令可以保证 NX EX 的原子性。 一定不要把两个命令(NX EX)分开执行，如果在 NX 之后程序出现问题就有可能产生死锁。 阻塞锁同时也可以实现一个阻塞锁： 123456789101112131415161718192021222324252627282930//一直阻塞public void lock(String key, String request) throws InterruptedException &#123; for (;;)&#123; String result = this.jedis.set(LOCK_PREFIX + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); if (LOCK_MSG.equals(result))&#123; break ; &#125; //防止一直消耗 CPU Thread.sleep(DEFAULT_SLEEP_TIME) ; &#125;&#125; //自定义阻塞时间 public boolean lock(String key, String request,int blockTime) throws InterruptedException &#123; while (blockTime &gt;= 0)&#123; String result = this.jedis.set(LOCK_PREFIX + key, request, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, 10 * TIME); if (LOCK_MSG.equals(result))&#123; return true ; &#125; blockTime -= DEFAULT_SLEEP_TIME ; Thread.sleep(DEFAULT_SLEEP_TIME) ; &#125; return false ;&#125; 解锁解锁也很简单，其实就是把这个 key 删掉就万事大吉了，比如使用 del key 命令。 但现实往往没有那么 easy。 如果进程 A 获取了锁设置了超时时间，但是由于执行周期较长导致到了超时时间之后锁就自动释放了。这时进程 B 获取了该锁执行很快就释放锁。这样就会出现进程 B 将进程 A 的锁释放了。 所以最好的方式是在每次解锁时都需要判断锁是否是自己的。 这时就需要结合加锁机制一起实现了。 加锁时需要传递一个参数，将该参数作为这个 key 的 value，这样每次解锁时判断 value 是否相等即可。 所以解锁代码就不能是简单的 del了。 1234567891011121314151617181920public boolean unlock(String key,String request)&#123; //lua script String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end"; Object result = null ; if (jedis instanceof Jedis)&#123; result = ((Jedis)this.jedis).eval(script, Collections.singletonList(LOCK_PREFIX + key), Collections.singletonList(request)); &#125;else if (jedis instanceof JedisCluster)&#123; result = ((JedisCluster)this.jedis).eval(script, Collections.singletonList(LOCK_PREFIX + key), Collections.singletonList(request)); &#125;else &#123; //throw new RuntimeException("instance is error") ; return false ; &#125; if (UNLOCK_MSG.equals(result))&#123; return true ; &#125;else &#123; return false ; &#125;&#125; 这里使用了一个 lua 脚本来判断 value 是否相等，相等才执行 del 命令。 使用 lua 也可以保证这里两个操作的原子性。 因此上文提到的四个基本特性也能满足了： 使用 Redis 可以保证性能。 阻塞锁与非阻塞锁见上文。 利用超时机制解决了死锁。 Redis 支持集群部署提高了可用性。 使用我自己有撸了一个完整的实现，并且已经用于了生产，有兴趣的朋友可以开箱使用: maven 依赖： 12345&lt;dependency&gt; &lt;groupId&gt;top.crossoverjie.opensource&lt;/groupId&gt; &lt;artifactId&gt;distributed-redis-lock&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 配置 bean : 1234567891011121314@Configurationpublic class RedisLockConfig &#123; @Bean public RedisLock build()&#123; RedisLock redisLock = new RedisLock() ; HostAndPort hostAndPort = new HostAndPort("127.0.0.1",7000) ; JedisCluster jedisCluster = new JedisCluster(hostAndPort) ; // Jedis 或 JedisCluster 都可以 redisLock.setJedisCluster(jedisCluster) ; return redisLock ; &#125;&#125; 使用： 123456789101112131415161718192021@Autowiredprivate RedisLock redisLock ;public void use() &#123; String key = "key"; String request = UUID.randomUUID().toString(); try &#123; boolean locktest = redisLock.tryLock(key, request); if (!locktest) &#123; System.out.println("locked error"); return; &#125; //do something &#125; finally &#123; redisLock.unlock(key,request) ; &#125;&#125; 使用很简单。这里主要是想利用 Spring 来帮我们管理 RedisLock 这个单例的 bean，所以在释放锁的时候需要手动(因为整个上下文只有一个 RedisLock 实例)的传入 key 以及 request(api 看起来不是特别优雅)。 也可以在每次使用锁的时候 new 一个 RedisLock 传入 key 以及 request，这样倒是在解锁时很方便。但是需要自行管理 RedisLock 的实例。各有优劣吧。 项目源码在： https://github.com/crossoverJie/distributed-lock-redis 欢迎讨论。 单测在做这个项目的时候让我不得不想提一下单测。 因为这个应用是强依赖于第三方组件的(Redis)，但是在单测中我们需要排除掉这种依赖。比如其他伙伴 fork 了该项目想在本地跑一遍单测，结果运行不起来： 有可能是 Redis 的 ip、端口和单测里的不一致。 Redis 自身可能也有问题。 也有可能是该同学的环境中并没有 Redis。 所以最好是要把这些外部不稳定的因素排除掉，单测只测我们写好的代码。 于是就可以引入单测利器 Mock 了。 它的想法很简答，就是要把你所依赖的外部资源统统屏蔽掉。如：数据库、外部接口、外部文件等等。 使用方式也挺简单，可以参考该项目的单测： 12345678910111213141516@Testpublic void tryLock() throws Exception &#123; String key = "test"; String request = UUID.randomUUID().toString(); Mockito.when(jedisCluster.set(Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyLong())).thenReturn("OK"); boolean locktest = redisLock.tryLock(key, request); System.out.println("locktest=" + locktest); Assert.assertTrue(locktest); //check Mockito.verify(jedisCluster).set(Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyString(), Mockito.anyLong());&#125; 这里只是简单演示下，可以的话下次仔细分析分析。 它的原理其实也挺简单，debug 的话可以很直接的看出来： 这里我们所依赖的 JedisCluster 其实是一个 cglib 代理对象。所以也不难想到它是如何工作的。 比如这里我们需要用到 JedisCluster 的 set 函数并需要它的返回值。 Mock 就将该对象代理了，并在实际执行 set 方法后给你返回了一个你自定义的值。 这样我们就可以随心所欲的测试了，完全把外部依赖所屏蔽了。 总结至此一个基于 Redis 的分布式锁完成，但是依然有些问题。 如在 key 超时之后业务并没有执行完毕但却自动释放锁了，这样就会导致并发问题。 就算 Redis 是集群部署的，如果每个节点都只是 master 没有 slave，那么 master 宕机时该节点上的所有 key 在那一时刻都相当于是释放锁了，这样也会出现并发问题。就算是有 slave 节点，但如果在数据同步到 salve 之前 master 宕机也是会出现上面的问题。 感兴趣的朋友还可以参考 Redisson 的实现。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Distributed Tools</category>
      </categories>
      <tags>
        <tag>Distributed Lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Bean 生命周期]]></title>
    <url>%2F2018%2F03%2F21%2Fspring%2Fspring-bean-lifecycle%2F</url>
    <content type="text"><![CDATA[前言Spring Bean 的生命周期在整个 Spring 中占有很重要的位置，掌握这些可以加深对 Spring 的理解。 首先看下生命周期图： 再谈生命周期之前有一点需要先明确： Spring 只帮我们管理单例模式 Bean 的完整生命周期，对于 prototype 的 bean ，Spring 在创建好交给使用者之后则不会再管理后续的生命周期。 注解方式在 bean 初始化时会经历几个阶段，首先可以使用注解 @PostConstruct, @PreDestroy 来在 bean 的创建和销毁阶段进行调用: 1234567891011121314@Componentpublic class AnnotationBean &#123; private final static Logger LOGGER = LoggerFactory.getLogger(AnnotationBean.class); @PostConstruct public void start()&#123; LOGGER.info("AnnotationBean start"); &#125; @PreDestroy public void destroy()&#123; LOGGER.info("AnnotationBean destroy"); &#125;&#125; InitializingBean, DisposableBean 接口还可以实现 InitializingBean,DisposableBean 这两个接口，也是在初始化以及销毁阶段调用： 12345678910111213@Servicepublic class SpringLifeCycleService implements InitializingBean,DisposableBean&#123; private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycleService.class); @Override public void afterPropertiesSet() throws Exception &#123; LOGGER.info("SpringLifeCycleService start"); &#125; @Override public void destroy() throws Exception &#123; LOGGER.info("SpringLifeCycleService destroy"); &#125;&#125; 自定义初始化和销毁方法也可以自定义方法用于在初始化、销毁阶段调用: 123456789101112131415161718192021222324@Configurationpublic class LifeCycleConfig &#123; @Bean(initMethod = "start", destroyMethod = "destroy") public SpringLifeCycle create()&#123; SpringLifeCycle springLifeCycle = new SpringLifeCycle() ; return springLifeCycle ; &#125;&#125;public class SpringLifeCycle&#123; private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycle.class); public void start()&#123; LOGGER.info("SpringLifeCycle start"); &#125; public void destroy()&#123; LOGGER.info("SpringLifeCycle destroy"); &#125;&#125; 以上是在 SpringBoot 中可以这样配置，如果是原始的基于 XML 也是可以使用: 12&lt;bean class="com.crossoverjie.spring.SpringLifeCycle" init-method="start" destroy-method="destroy"&gt;&lt;/bean&gt; 来达到同样的效果。 实现 *Aware 接口*Aware 接口可以用于在初始化 bean 时获得 Spring 中的一些对象，如获取 Spring 上下文等。 123456789101112@Componentpublic class SpringLifeCycleAware implements ApplicationContextAware &#123; private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycleAware.class); private ApplicationContext applicationContext ; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext ; LOGGER.info("SpringLifeCycleAware start"); &#125;&#125; 这样在 springLifeCycleAware 这个 bean 初始化会就会调用 setApplicationContext 方法，并可以获得 applicationContext 对象。 BeanPostProcessor 增强处理器实现 BeanPostProcessor 接口，Spring 中所有 bean 在做初始化时都会调用该接口中的两个方法，可以用于对一些特殊的 bean 进行处理： 12345678910111213141516171819202122232425262728293031323334@Componentpublic class SpringLifeCycleProcessor implements BeanPostProcessor &#123; private final static Logger LOGGER = LoggerFactory.getLogger(SpringLifeCycleProcessor.class); /** * 预初始化 初始化之前调用 * @param bean * @param beanName * @return * @throws BeansException */ @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if ("annotationBean".equals(beanName))&#123; LOGGER.info("SpringLifeCycleProcessor start beanName=&#123;&#125;",beanName); &#125; return bean; &#125; /** * 后初始化 bean 初始化完成调用 * @param bean * @param beanName * @return * @throws BeansException */ @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if ("annotationBean".equals(beanName))&#123; LOGGER.info("SpringLifeCycleProcessor end beanName=&#123;&#125;",beanName); &#125; return bean; &#125;&#125; 执行之后观察结果： 123456789101112131415018-03-21 00:40:24.856 [restartedMain] INFO c.c.s.p.SpringLifeCycleProcessor - SpringLifeCycleProcessor start beanName=annotationBean2018-03-21 00:40:24.860 [restartedMain] INFO c.c.spring.annotation.AnnotationBean - AnnotationBean start2018-03-21 00:40:24.861 [restartedMain] INFO c.c.s.p.SpringLifeCycleProcessor - SpringLifeCycleProcessor end beanName=annotationBean2018-03-21 00:40:24.864 [restartedMain] INFO c.c.s.aware.SpringLifeCycleAware - SpringLifeCycleAware start2018-03-21 00:40:24.867 [restartedMain] INFO c.c.s.service.SpringLifeCycleService - SpringLifeCycleService start2018-03-21 00:40:24.887 [restartedMain] INFO c.c.spring.SpringLifeCycle - SpringLifeCycle start2018-03-21 00:40:25.062 [restartedMain] INFO o.s.b.d.a.OptionalLiveReloadServer - LiveReload server is running on port 357292018-03-21 00:40:25.122 [restartedMain] INFO o.s.j.e.a.AnnotationMBeanExporter - Registering beans for JMX exposure on startup2018-03-21 00:40:25.140 [restartedMain] INFO com.crossoverjie.Application - Started Application in 2.309 seconds (JVM running for 3.681)2018-03-21 00:40:25.143 [restartedMain] INFO com.crossoverjie.Application - start ok!2018-03-21 00:40:25.153 [Thread-8] INFO o.s.c.a.AnnotationConfigApplicationContext - Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@3913adad: startup date [Wed Mar 21 00:40:23 CST 2018]; root of context hierarchy2018-03-21 00:40:25.155 [Thread-8] INFO o.s.j.e.a.AnnotationMBeanExporter - Unregistering JMX-exposed beans on shutdown2018-03-21 00:40:25.156 [Thread-8] INFO c.c.spring.SpringLifeCycle - SpringLifeCycle destroy2018-03-21 00:40:25.156 [Thread-8] INFO c.c.s.service.SpringLifeCycleService - SpringLifeCycleService destroy2018-03-21 00:40:25.156 [Thread-8] INFO c.c.spring.annotation.AnnotationBean - AnnotationBean destroy 直到 Spring 上下文销毁时则会调用自定义的销毁方法以及实现了 DisposableBean 的 destroy() 方法。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解线程通信]]></title>
    <url>%2F2018%2F03%2F16%2Fjava-senior%2Fthread-communication%2F</url>
    <content type="text"><![CDATA[前言开发中不免会遇到需要所有子线程执行完毕通知主线程处理某些逻辑的场景。 或者是线程 A 在执行到某个条件通知线程 B 执行某个操作。 可以通过以下几种方式实现： 等待通知机制 等待通知模式是 Java 中比较经典的线程通信方式。 两个线程通过对同一对象调用等待 wait() 和通知 notify() 方法来进行通讯。 如两个线程交替打印奇偶数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class TwoThreadWaitNotify &#123; private int start = 1; private boolean flag = false; public static void main(String[] args) &#123; TwoThreadWaitNotify twoThread = new TwoThreadWaitNotify(); Thread t1 = new Thread(new OuNum(twoThread)); t1.setName("A"); Thread t2 = new Thread(new JiNum(twoThread)); t2.setName("B"); t1.start(); t2.start(); &#125; /** * 偶数线程 */ public static class OuNum implements Runnable &#123; private TwoThreadWaitNotify number; public OuNum(TwoThreadWaitNotify number) &#123; this.number = number; &#125; @Override public void run() &#123; while (number.start &lt;= 100) &#123; synchronized (TwoThreadWaitNotify.class) &#123; System.out.println("偶数线程抢到锁了"); if (number.flag) &#123; System.out.println(Thread.currentThread().getName() + "+-+偶数" + number.start); number.start++; number.flag = false; TwoThreadWaitNotify.class.notify(); &#125;else &#123; try &#123; TwoThreadWaitNotify.class.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; &#125; /** * 奇数线程 */ public static class JiNum implements Runnable &#123; private TwoThreadWaitNotify number; public JiNum(TwoThreadWaitNotify number) &#123; this.number = number; &#125; @Override public void run() &#123; while (number.start &lt;= 100) &#123; synchronized (TwoThreadWaitNotify.class) &#123; System.out.println("奇数线程抢到锁了"); if (!number.flag) &#123; System.out.println(Thread.currentThread().getName() + "+-+奇数" + number.start); number.start++; number.flag = true; TwoThreadWaitNotify.class.notify(); &#125;else &#123; try &#123; TwoThreadWaitNotify.class.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; &#125;&#125; 输出结果： 12345678t2+-+奇数93t1+-+偶数94t2+-+奇数95t1+-+偶数96t2+-+奇数97t1+-+偶数98t2+-+奇数99t1+-+偶数100 这里的线程 A 和线程 B 都对同一个对象 TwoThreadWaitNotify.class 获取锁，A 线程调用了同步对象的 wait() 方法释放了锁并进入 WAITING 状态。 B 线程调用了 notify() 方法，这样 A 线程收到通知之后就可以从 wait() 方法中返回。 这里利用了 TwoThreadWaitNotify.class 对象完成了通信。 有一些需要注意: wait() 、nofify() 、nofityAll() 调用的前提都是获得了对象的锁(也可称为对象监视器)。 调用 wait() 方法后线程会释放锁，进入 WAITING 状态，该线程也会被移动到等待队列中。 调用 notify() 方法会将等待队列中的线程移动到同步队列中，线程状态也会更新为 BLOCKED 从 wait() 方法返回的前提是调用 notify() 方法的线程释放锁，wait() 方法的线程获得锁。 等待通知有着一个经典范式： 线程 A 作为消费者： 获取对象的锁。 进入 while(判断条件)，并调用 wait() 方法。 当条件满足跳出循环执行具体处理逻辑。 线程 B 作为生产者: 获取对象锁。 更改与线程 A 共用的判断条件。 调用 notify() 方法。 伪代码如下: 1234567891011121314//Thread Asynchronized(Object)&#123; while(条件)&#123; Object.wait(); &#125; //do something&#125;//Thread Bsynchronized(Object)&#123; 条件=false;//改变条件 Object.notify();&#125; join() 方法1234567891011121314151617181920212223242526272829303132333435private static void join() throws InterruptedException &#123; Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;) ; Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running2"); try &#123; Thread.sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;) ; t1.start(); t2.start(); //等待线程1终止 t1.join(); //等待线程2终止 t2.join(); LOGGER.info("main over");&#125; 输出结果: 1232018-03-16 20:21:30.967 [Thread-1] INFO c.c.actual.ThreadCommunication - running22018-03-16 20:21:30.967 [Thread-0] INFO c.c.actual.ThreadCommunication - running2018-03-16 20:21:34.972 [main] INFO c.c.actual.ThreadCommunication - main over 在 t1.join() 时会一直阻塞到 t1 执行完毕，所以最终主线程会等待 t1 和 t2 线程执行完毕。 其实从源码可以看出，join() 也是利用的等待通知机制： 核心逻辑: 123while (isAlive()) &#123; wait(0);&#125; 在 join 线程完成后会调用 notifyAll() 方法，是在 JVM 实现中调用，所以这里看不出来。 volatile 共享内存因为 Java 是采用共享内存的方式进行线程通信的，所以可以采用以下方式用主线程关闭 A 线程: 1234567891011121314151617181920212223242526272829public class Volatile implements Runnable&#123; private static volatile boolean flag = true ; @Override public void run() &#123; while (flag)&#123; System.out.println(Thread.currentThread().getName() + "正在运行。。。"); &#125; System.out.println(Thread.currentThread().getName() +"执行完毕"); &#125; public static void main(String[] args) throws InterruptedException &#123; Volatile aVolatile = new Volatile(); new Thread(aVolatile,"thread A").start(); System.out.println("main 线程正在运行") ; TimeUnit.MILLISECONDS.sleep(100) ; aVolatile.stopThread(); &#125; private void stopThread()&#123; flag = false ; &#125;&#125; 输出结果：12345thread A正在运行。。。thread A正在运行。。。thread A正在运行。。。thread A正在运行。。。thread A执行完毕 这里的 flag 存放于主内存中，所以主线程和线程 A 都可以看到。 flag 采用 volatile 修饰主要是为了内存可见性，更多内容可以查看这里。 CountDownLatch 并发工具CountDownLatch 可以实现 join 相同的功能，但是更加的灵活。 12345678910111213141516171819202122232425private static void countDownLatch() throws Exception&#123; int thread = 3 ; long start = System.currentTimeMillis(); final CountDownLatch countDown = new CountDownLatch(thread); for (int i= 0 ;i&lt;thread ; i++)&#123; new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("thread run"); try &#123; Thread.sleep(2000); countDown.countDown(); LOGGER.info("thread end"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; countDown.await(); long stop = System.currentTimeMillis(); LOGGER.info("main over total time=&#123;&#125;",stop-start);&#125; 输出结果: 12345672018-03-16 20:19:44.126 [Thread-0] INFO c.c.actual.ThreadCommunication - thread run2018-03-16 20:19:44.126 [Thread-2] INFO c.c.actual.ThreadCommunication - thread run2018-03-16 20:19:44.126 [Thread-1] INFO c.c.actual.ThreadCommunication - thread run2018-03-16 20:19:46.136 [Thread-2] INFO c.c.actual.ThreadCommunication - thread end2018-03-16 20:19:46.136 [Thread-1] INFO c.c.actual.ThreadCommunication - thread end2018-03-16 20:19:46.136 [Thread-0] INFO c.c.actual.ThreadCommunication - thread end2018-03-16 20:19:46.136 [main] INFO c.c.actual.ThreadCommunication - main over total time=2012 CountDownLatch 也是基于 AQS(AbstractQueuedSynchronizer) 实现的，更多实现参考 ReentrantLock 实现原理 初始化一个 CountDownLatch 时告诉并发的线程，然后在每个线程处理完毕之后调用 countDown() 方法。 该方法会将 AQS 内置的一个 state 状态 -1 。 最终在主线程调用 await() 方法，它会阻塞直到 state == 0 的时候返回。 CyclicBarrier 并发工具123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private static void cyclicBarrier() throws Exception &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(3) ; new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("thread run"); try &#123; cyclicBarrier.await() ; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; LOGGER.info("thread end do something"); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("thread run"); try &#123; cyclicBarrier.await() ; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; LOGGER.info("thread end do something"); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("thread run"); try &#123; Thread.sleep(5000); cyclicBarrier.await() ; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; LOGGER.info("thread end do something"); &#125; &#125;).start(); LOGGER.info("main thread");&#125; CyclicBarrier 中文名叫做屏障或者是栅栏，也可以用于线程间通信。 它可以等待 N 个线程都达到某个状态后继续运行的效果。 首先初始化线程参与者。 调用 await() 将会在所有参与者线程都调用之前等待。 直到所有参与者都调用了 await() 后，所有线程从 await() 返回继续后续逻辑。 运行结果: 12345672018-03-18 22:40:00.731 [Thread-0] INFO c.c.actual.ThreadCommunication - thread run2018-03-18 22:40:00.731 [Thread-1] INFO c.c.actual.ThreadCommunication - thread run2018-03-18 22:40:00.731 [Thread-2] INFO c.c.actual.ThreadCommunication - thread run2018-03-18 22:40:00.731 [main] INFO c.c.actual.ThreadCommunication - main thread2018-03-18 22:40:05.741 [Thread-0] INFO c.c.actual.ThreadCommunication - thread end do something2018-03-18 22:40:05.741 [Thread-1] INFO c.c.actual.ThreadCommunication - thread end do something2018-03-18 22:40:05.741 [Thread-2] INFO c.c.actual.ThreadCommunication - thread end do something 可以看出由于其中一个线程休眠了五秒，所有其余所有的线程都得等待这个线程调用 await() 。 该工具可以实现 CountDownLatch 同样的功能，但是要更加灵活。甚至可以调用 reset() 方法重置 CyclicBarrier (需要自行捕获 BrokenBarrierException 处理) 然后重新执行。 线程响应中断12345678910111213141516171819202122232425public class StopThread implements Runnable &#123; @Override public void run() &#123; while ( !Thread.currentThread().isInterrupted()) &#123; // 线程执行具体逻辑 System.out.println(Thread.currentThread().getName() + "运行中。。"); &#125; System.out.println(Thread.currentThread().getName() + "退出。。"); &#125; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(new StopThread(), "thread A"); thread.start(); System.out.println("main 线程正在运行") ; TimeUnit.MILLISECONDS.sleep(10) ; thread.interrupt(); &#125;&#125; 输出结果: 123thread A运行中。。thread A运行中。。thread A退出。。 可以采用中断线程的方式来通信，调用了 thread.interrupt() 方法其实就是将 thread 中的一个标志属性置为了 true。 并不是说调用了该方法就可以中断线程，如果不对这个标志进行响应其实是没有什么作用(这里对这个标志进行了判断)。 但是如果抛出了 InterruptedException 异常，该标志就会被 JVM 重置为 false。 线程池 awaitTermination() 方法如果是用线程池来管理线程，可以使用以下方式来让主线程等待线程池中所有任务执行完毕: 1234567891011121314151617181920212223242526272829303132private static void executorService() throws Exception&#123; BlockingQueue&lt;Runnable&gt; queue = new LinkedBlockingQueue&lt;&gt;(10) ; ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(5,5,1, TimeUnit.MILLISECONDS,queue) ; poolExecutor.execute(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); poolExecutor.execute(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running2"); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); poolExecutor.shutdown(); while (!poolExecutor.awaitTermination(1,TimeUnit.SECONDS))&#123; LOGGER.info("线程还在执行。。。"); &#125; LOGGER.info("main over");&#125; 输出结果: 123452018-03-16 20:18:01.273 [pool-1-thread-2] INFO c.c.actual.ThreadCommunication - running22018-03-16 20:18:01.273 [pool-1-thread-1] INFO c.c.actual.ThreadCommunication - running2018-03-16 20:18:02.273 [main] INFO c.c.actual.ThreadCommunication - 线程还在执行。。。2018-03-16 20:18:03.278 [main] INFO c.c.actual.ThreadCommunication - 线程还在执行。。。2018-03-16 20:18:04.278 [main] INFO c.c.actual.ThreadCommunication - main over 使用这个 awaitTermination() 方法的前提需要关闭线程池，如调用了 shutdown() 方法。 调用了 shutdown() 之后线程池会停止接受新任务，并且会平滑的关闭线程池中现有的任务。 管道通信12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static void piped() throws IOException &#123; //面向于字符 PipedInputStream 面向于字节 PipedWriter writer = new PipedWriter(); PipedReader reader = new PipedReader(); //输入输出流建立连接 writer.connect(reader); Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running"); try &#123; for (int i = 0; i &lt; 10; i++) &#123; writer.write(i+""); Thread.sleep(10); &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; try &#123; writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; LOGGER.info("running2"); int msg = 0; try &#123; while ((msg = reader.read()) != -1) &#123; LOGGER.info("msg=&#123;&#125;", (char) msg); &#125; &#125; catch (Exception e) &#123; &#125; &#125; &#125;); t1.start(); t2.start();&#125; 输出结果: 1234567891011122018-03-16 19:56:43.014 [Thread-0] INFO c.c.actual.ThreadCommunication - running2018-03-16 19:56:43.014 [Thread-1] INFO c.c.actual.ThreadCommunication - running22018-03-16 19:56:43.130 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=02018-03-16 19:56:43.132 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=12018-03-16 19:56:43.132 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=22018-03-16 19:56:43.133 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=32018-03-16 19:56:43.133 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=42018-03-16 19:56:43.133 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=52018-03-16 19:56:43.133 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=62018-03-16 19:56:43.134 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=72018-03-16 19:56:43.134 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=82018-03-16 19:56:43.134 [Thread-1] INFO c.c.actual.ThreadCommunication - msg=9 Java 虽说是基于内存通信的，但也可以使用管道通信。 需要注意的是，输入流和输出流需要首先建立连接。这样线程 B 就可以收到线程 A 发出的消息了。 实际开发中可以灵活根据需求选择最适合的线程通信方式。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你应该知道的 volatile 关键字]]></title>
    <url>%2F2018%2F03%2F09%2Fvolatile%2F</url>
    <content type="text"><![CDATA[前言不管是在面试还是实际开发中 volatile 都是一个应该掌握的技能。 首先来看看为什么会出现这个关键字。 内存可见性由于 Java 内存模型(JMM)规定，所有的变量都存放在主内存中，而每个线程都有着自己的工作内存(高速缓存)。 线程在工作时，需要将主内存中的数据拷贝到工作内存中。这样对数据的任何操作都是基于工作内存(效率提高)，并且不能直接操作主内存以及其他线程工作内存中的数据，之后再将更新之后的数据刷新到主内存中。 这里所提到的主内存可以简单认为是堆内存，而工作内存则可以认为是栈内存。 如下图所示： 所以在并发运行时可能会出现线程 B 所读取到的数据是线程 A 更新之前的数据。 显然这肯定是会出问题的，因此 volatile 的作用出现了： 当一个变量被 volatile 修饰时，任何线程对它的写操作都会立即刷新到主内存中，并且会强制让缓存了该变量的线程中的数据清空，必须从主内存重新读取最新数据。 volatile 修饰之后并不是让线程直接从主内存中获取数据，依然需要将变量拷贝到工作内存中。 内存可见性的应用当我们需要在两个线程间依据主内存通信时，通信的那个变量就必须的用 volatile 来修饰： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Volatile implements Runnable&#123; private static volatile boolean flag = true ; @Override public void run() &#123; while (flag)&#123; &#125; System.out.println(Thread.currentThread().getName() +"执行完毕"); &#125; public static void main(String[] args) throws InterruptedException &#123; Volatile aVolatile = new Volatile(); new Thread(aVolatile,"thread A").start(); System.out.println("main 线程正在运行") ; Scanner sc = new Scanner(System.in); while(sc.hasNext())&#123; String value = sc.next(); if(value.equals("1"))&#123; new Thread(new Runnable() &#123; @Override public void run() &#123; aVolatile.stopThread(); &#125; &#125;).start(); break ; &#125; &#125; System.out.println("主线程退出了！"); &#125; private void stopThread()&#123; flag = false ; &#125;&#125; 主线程在修改了标志位使得线程 A 立即停止，如果没有用 volatile 修饰，就有可能出现延迟。 但这里有个误区，这样的使用方式容易给人的感觉是： 对 volatile 修饰的变量进行并发操作是线程安全的。 这里要重点强调，volatile 并不能保证线程安全性！ 如下程序: 1234567891011121314151617181920212223242526272829303132public class VolatileInc implements Runnable&#123; private static volatile int count = 0 ; //使用 volatile 修饰基本数据内存不能保证原子性 //private static AtomicInteger count = new AtomicInteger() ; @Override public void run() &#123; for (int i=0;i&lt;10000 ;i++)&#123; count ++ ; //count.incrementAndGet() ; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; VolatileInc volatileInc = new VolatileInc() ; Thread t1 = new Thread(volatileInc,"t1") ; Thread t2 = new Thread(volatileInc,"t2") ; t1.start(); //t1.join(); t2.start(); //t2.join(); for (int i=0;i&lt;10000 ;i++)&#123; count ++ ; //count.incrementAndGet(); &#125; System.out.println("最终Count="+count); &#125;&#125; 当我们三个线程(t1,t2,main)同时对一个 int 进行累加时会发现最终的值都会小于 30000。 这是因为虽然 volatile 保证了内存可见性，每个线程拿到的值都是最新值，但 count ++ 这个操作并不是原子的，这里面涉及到获取值、自增、赋值的操作并不能同时完成。 所以想到达到线程安全可以使这三个线程串行执行(其实就是单线程，没有发挥多线程的优势)。 也可以使用 synchronize 或者是锁的方式来保证原子性。 还可以用 Atomic 包中 AtomicInteger 来替换 int，它利用了 CAS 算法来保证了原子性。 指令重排内存可见性只是 volatile 的其中一个语义，它还可以防止 JVM 进行指令重排优化。 举一个伪代码: 123int a=10 ;//1int b=20 ;//2int c= a+b ;//3 一段特别简单的代码，理想情况下它的执行顺序是：1&gt;2&gt;3。但有可能经过 JVM 优化之后的执行顺序变为了 2&gt;1&gt;3。 可以发现不管 JVM 怎么优化，前提都是保证单线程中最终结果不变的情况下进行的。 可能这里还看不出有什么问题，那看下一段伪代码: 12345678910111213141516171819private static Map&lt;String,String&gt; value ;private static volatile boolean flag = fasle ;//以下方法发生在线程 A 中 初始化 Mappublic void initMap()&#123; //耗时操作 value = getMapValue() ;//1 flag = true ;//2&#125;//发生在线程 B中 等到 Map 初始化成功进行其他操作public void doSomeThing()&#123; while(!flag)&#123; sleep() ; &#125; //dosomething doSomeThing(value);&#125; 这里就能看出问题了，当 flag 没有被 volatile 修饰时，JVM 对 1 和 2 进行重排，导致 value 都还没有被初始化就有可能被线程 B 使用了。 所以加上 volatile 之后可以防止这样的重排优化，保证业务的正确性。 指令重排的的应用一个经典的使用场景就是双重懒加载的单例模式了: 12345678910111213141516171819public class Singleton &#123; private static volatile Singleton singleton; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; //防止指令重排 singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 这里的 volatile 关键字主要是为了防止指令重排。 如果不用 ，singleton = new Singleton();，这段代码其实是分为三步： 分配内存空间。(1) 初始化对象。(2) 将 singleton 对象指向分配的内存地址。(3) 加上 volatile 是为了让以上的三步操作顺序执行，反之有可能第二步在第三步之前被执行就有可能某个线程拿到的单例对象是还没有初始化的，以致于报错。 总结volatile 在 Java 并发中用的很多，比如像 Atomic 包中的 value、以及 AbstractQueuedLongSynchronizer 中的 state 都是被定义为 volatile 来用于保证内存可见性。 将这块理解透彻对我们编写并发程序时可以提供很大帮助。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>volatile</tag>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedHashMap 底层分析]]></title>
    <url>%2F2018%2F02%2F06%2FLinkedHashMap%2F</url>
    <content type="text"><![CDATA[众所周知 HashMap 是一个无序的 Map，因为每次根据 key 的 hashcode 映射到 Entry 数组上，所以遍历出来的顺序并不是写入的顺序。 因此 JDK 推出一个基于 HashMap 但具有顺序的 LinkedHashMap 来解决有排序需求的场景。 它的底层是继承于 HashMap 实现的，由一个双向链表所构成。 LinkedHashMap 的排序方式有两种： 根据写入顺序排序。 根据访问顺序排序。 其中根据访问顺序排序时，每次 get 都会将访问的值移动到链表末尾，这样重复操作就能的到一个按照访问顺序排序的链表。 数据结构1234567891011@Testpublic void test()&#123; Map&lt;String, Integer&gt; map = new LinkedHashMap&lt;String, Integer&gt;(); map.put("1",1) ; map.put("2",2) ; map.put("3",3) ; map.put("4",4) ; map.put("5",5) ; System.out.println(map.toString());&#125; 调试可以看到 map 的组成： 打开源码可以看到： 123456789101112131415161718192021/** * The head of the doubly linked list. */private transient Entry&lt;K,V&gt; header;/** * The iteration ordering method for this linked hash map: &lt;tt&gt;true&lt;/tt&gt; * for access-order, &lt;tt&gt;false&lt;/tt&gt; for insertion-order. * * @serial */private final boolean accessOrder;private static class Entry&lt;K,V&gt; extends HashMap.Entry&lt;K,V&gt; &#123; // These fields comprise the doubly linked list used for iteration. Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, HashMap.Entry&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; 其中 Entry 继承于 HashMap 的 Entry，并新增了上下节点的指针，也就形成了双向链表。 还有一个 header 的成员变量，是这个双向链表的头结点。 上边的 demo 总结成一张图如下： 第一个类似于 HashMap 的结构，利用 Entry 中的 next 指针进行关联。 下边则是 LinkedHashMap 如何达到有序的关键。 就是利用了头节点和其余的各个节点之间通过 Entry 中的 after 和 before 指针进行关联。 其中还有一个 accessOrder 成员变量，默认是 false，默认按照插入顺序排序，为 true 时按照访问顺序排序，也可以调用: 123456public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; 这个构造方法可以显示的传入 accessOrder。 构造方法LinkedHashMap 的构造方法: 1234public LinkedHashMap() &#123; super(); accessOrder = false;&#125; 其实就是调用的 HashMap 的构造方法: HashMap 实现： 123456789101112131415public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; //HashMap 只是定义了改方法，具体实现交给了 LinkedHashMap init();&#125; 可以看到里面有一个空的 init()，具体是由 LinkedHashMap 来实现的： 12345@Overridevoid init() &#123; header = new Entry&lt;&gt;(-1, null, null, null); header.before = header.after = header;&#125; 其实也就是对 header 进行了初始化。 put 方法看 LinkedHashMap 的 put() 方法之前先看看 HashMap 的 put 方法： 123456789101112131415161718192021222324252627282930313233343536373839404142public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; //空实现，交给 LinkedHashMap 自己实现 e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // LinkedHashMap 对其重写 addEntry(hash, key, value, i); return null;&#125;// LinkedHashMap 对其重写void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;// LinkedHashMap 对其重写void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 主体的实现都是借助于 HashMap 来完成的，只是对其中的 recordAccess(), addEntry(), createEntry() 进行了重写。 LinkedHashMap 的实现： 1234567891011121314151617181920212223242526272829303132333435363738 //就是判断是否是根据访问顺序排序，如果是则需要将当前这个 Entry 移动到链表的末尾 void recordAccess(HashMap&lt;K,V&gt; m) &#123; LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; if (lm.accessOrder) &#123; lm.modCount++; remove(); addBefore(lm.header); &#125; &#125; //调用了 HashMap 的实现，并判断是否需要删除最少使用的 Entry(默认不删除) void addEntry(int hash, K key, V value, int bucketIndex) &#123; super.addEntry(hash, key, value, bucketIndex); // Remove eldest entry if instructed Entry&lt;K,V&gt; eldest = header.after; if (removeEldestEntry(eldest)) &#123; removeEntryForKey(eldest.key); &#125;&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old); //就多了这一步，将新增的 Entry 加入到 header 双向链表中 table[bucketIndex] = e; e.addBefore(header); size++;&#125; //写入到双向链表中 private void addBefore(Entry&lt;K,V&gt; existingEntry) &#123; after = existingEntry; before = existingEntry.before; before.after = this; after.before = this; &#125; get 方法LinkedHashMap 的 get() 方法也重写了： 123456789101112131415161718192021public V get(Object key) &#123; Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key); if (e == null) return null; //多了一个判断是否是按照访问顺序排序，是则将当前的 Entry 移动到链表头部。 e.recordAccess(this); return e.value;&#125;void recordAccess(HashMap&lt;K,V&gt; m) &#123; LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; if (lm.accessOrder) &#123; lm.modCount++; //删除 remove(); //添加到头部 addBefore(lm.header); &#125;&#125; clear() 清空就要比较简单了： 12345//只需要把指针都指向自己即可，原本那些 Entry 没有引用之后就会被 JVM 自动回收。public void clear() &#123; super.clear(); header.before = header.after = header;&#125; 总结总的来说 LinkedHashMap 其实就是对 HashMap 进行了拓展，使用了双向链表来保证了顺序性。 因为是继承与 HashMap 的，所以一些 HashMap 存在的问题 LinkedHashMap 也会存在，比如不支持并发等。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>LinkedHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock 实现原理]]></title>
    <url>%2F2018%2F01%2F25%2FReentrantLock%2F</url>
    <content type="text"><![CDATA[使用 synchronize 来做同步处理时，锁的获取和释放都是隐式的，实现的原理是通过编译后加上不同的机器指令来实现。 而 ReentrantLock 就是一个普通的类，它是基于 AQS(AbstractQueuedSynchronizer)来实现的。 是一个重入锁：一个线程获得了锁之后仍然可以反复的加锁，不会出现自己阻塞自己的情况。 AQS 是 Java 并发包里实现锁、同步的一个重要的基础框架。 锁类型ReentrantLock 分为公平锁和非公平锁，可以通过构造方法来指定具体类型： 123456789//默认非公平锁public ReentrantLock() &#123; sync = new NonfairSync();&#125;//公平锁public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 默认一般使用非公平锁，它的效率和吞吐量都比公平锁高的多(后面会分析具体原因)。 获取锁通常的使用方式如下: 1234567891011private ReentrantLock lock = new ReentrantLock();public void run() &#123; lock.lock(); try &#123; //do bussiness &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125;&#125; 公平锁获取锁首先看下获取锁的过程： 123public void lock() &#123; sync.lock();&#125; 可以看到是使用 sync的方法，而这个方法是一个抽象方法，具体是由其子类(FairSync)来实现的，以下是公平锁的实现: 12345678910 final void lock() &#123; acquire(1); &#125; //AbstractQueuedSynchronizer 中的 acquire() public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 第一步是尝试获取锁(tryAcquire(arg)),这个也是由其子类实现： 1234567891011121314151617181920 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125; 首先会判断 AQS 中的 state 是否等于 0，0 表示目前没有其他线程获得锁，当前线程就可以尝试获取锁。 注意:尝试之前会利用 hasQueuedPredecessors() 方法来判断 AQS 的队列中中是否有其他线程，如果有则不会尝试获取锁(这是公平锁特有的情况)。 如果队列中没有线程就利用 CAS 来将 AQS 中的 state 修改为1，也就是获取锁，获取成功则将当前线程置为获得锁的独占线程(setExclusiveOwnerThread(current))。 如果 state 大于 0 时，说明锁已经被获取了，则需要判断获取锁的线程是否为当前线程(ReentrantLock 支持重入)，是则需要将 state + 1，并将值更新。 写入队列如果 tryAcquire(arg) 获取锁失败，则需要用 addWaiter(Node.EXCLUSIVE) 将当前线程写入队列中。 写入之前需要将当前线程包装为一个 Node 对象(addWaiter(Node.EXCLUSIVE))。 AQS 中的队列是由 Node 节点组成的双向链表实现的。 包装代码: 1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 首先判断队列是否为空，不为空时则将封装好的 Node 利用 CAS 写入队尾，如果出现并发写入失败就需要调用 enq(node); 来写入了。 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 这个处理逻辑就相当于自旋加上 CAS 保证一定能写入队列。 挂起等待线程写入队列之后需要将当前线程挂起(利用acquireQueued(addWaiter(Node.EXCLUSIVE), arg))： 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 首先会根据 node.predecessor() 获取到上一个节点是否为头节点，如果是则尝试获取一次锁，获取成功就万事大吉了。 如果不是头节点，或者获取锁失败，则会根据上一个节点的 waitStatus 状态来处理(shouldParkAfterFailedAcquire(p, node))。 waitStatus 用于记录当前节点的状态，如节点取消、节点等待等。 shouldParkAfterFailedAcquire(p, node) 返回当前线程是否需要挂起，如果需要则调用 parkAndCheckInterrupt()： 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 他是利用 LockSupport 的 part 方法来挂起当前线程的，直到被唤醒。 非公平锁获取锁公平锁与非公平锁的差异主要在获取锁： 公平锁就相当于买票，后来的人需要排到队尾依次买票，不能插队。 而非公平锁则没有这些规则，是抢占模式，每来一个人不会去管队列如何，直接尝试获取锁。 非公平锁:1234567final void lock() &#123; //直接尝试获取锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 公平锁:123final void lock() &#123; acquire(1);&#125; 还要一个重要的区别是在尝试获取锁时tryAcquire(arg)，非公平锁是不需要判断队列中是否还有其他线程，也是直接尝试获取锁： 12345678910111213141516171819final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //没有 !hasQueuedPredecessors() 判断 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 释放锁公平锁和非公平锁的释放流程都是一样的： 12345678910111213141516171819202122232425262728public void unlock() &#123; sync.release(1);&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) //唤醒被挂起的线程 unparkSuccessor(h); return true; &#125; return false;&#125;//尝试释放锁protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 首先会判断当前线程是否为获得锁的线程，由于是重入锁所以需要将 state 减到 0 才认为完全释放锁。 释放之后需要调用 unparkSuccessor(h) 来唤醒被挂起的线程。 总结由于公平锁需要关心队列的情况，得按照队列里的先后顺序来获取锁(会造成大量的线程上下文切换)，而非公平锁则没有这个限制。 所以也就能解释非公平锁的效率会被公平锁更高。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ReentrantLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象的创建与内存分配]]></title>
    <url>%2F2018%2F01%2F18%2FnewObject%2F</url>
    <content type="text"><![CDATA[创建对象当 JVM 收到一个 new 指令时，会检查指令中的参数在常量池是否有这个符号的引用，还会检查该类是否已经被加载过了，如果没有的话则要进行一次类加载。 接着就是分配内存了，通常有两种方式： 指针碰撞 空闲列表 使用指针碰撞的前提是堆内存是完全工整的，用过的内存和没用的内存各在一边每次分配的时候只需要将指针向空闲内存一方移动一段和内存大小相等区域即可。 当堆中已经使用的内存和未使用的内存互相交错时，指针碰撞的方式就行不通了，这时就需要采用空闲列表的方式。虚拟机会维护一个空闲的列表，用于记录哪些内存是可以进行分配的，分配时直接从可用内存中直接分配即可。 堆中的内存是否工整是有垃圾收集器来决定的，如果带有压缩功能的垃圾收集器就是采用指针碰撞的方式来进行内存分配的。 分配内存时也会出现并发问题: 这样可以在创建对象的时候使用 CAS 这样的乐观锁来保证。 也可以将内存分配安排在每个线程独有的空间进行，每个线程首先在堆内存中分配一小块内存，称为本地分配缓存(TLAB : Thread Local Allocation Buffer)。 分配内存时，只需要在自己的分配缓存中分配即可，由于这个内存区域是线程私有的，所以不会出现并发问题。 可以使用 -XX:+/-UseTLAB 参数来设定 JVM 是否开启 TLAB 。 内存分配之后需要对该对象进行设置，如对象头。对象头的一些应用可以查看 Synchronize 关键字原理。 对象访问一个对象被创建之后自然是为了使用，在 Java 中是通过栈来引用堆内存中的对象来进行操作的。 对于我们常用的 HotSpot 虚拟机来说，这样引用关系是通过直接指针来关联的。 如图: 这样的好处就是：在 Java 里进行频繁的对象访问可以提升访问速度(相对于使用句柄池来说)。 内存分配Eden 区分配简单的来说对象都是在堆内存中分配的，往细一点看则是优先在 Eden 区分配。 这里就涉及到堆内存的划分了，为了方便垃圾回收，JVM 将对内存分为新生代和老年代。 而新生代中又会划分为 Eden 区，from Survivor、to Survivor 区。 其中 Eden 和 Survivor 区的比例默认是 8:1:1，当然也支持参数调整 -XX:SurvivorRatio=8。 当在 Eden 区分配内存不足时，则会发生 minorGC ，由于 Java 对象多数是朝生夕灭的特性，所以 minorGC 通常会比较频繁，效率也比较高。 当发生 minorGC 时，JVM 会根据复制算法将存活的对象拷贝到另一个未使用的 Survivor 区，如果 Survivor 区内存不足时，则会使用分配担保策略将对象移动到老年代中。 谈到 minorGC 时，就不得不提到 fullGC(majorGC) ，这是指发生在老年代的 GC ，不论是效率还是速度都比 minorGC 慢的多，回收时还会发生 stop the world 使程序发生停顿，所以应当尽量避免发生 fullGC 。 老年代分配也有一些情况会导致对象直接在老年代分配，比如当分配一个大对象时(大的数组，很长的字符串)，由于 Eden 区没有足够大的连续空间来分配时，会导致提前触发一次 GC，所以尽量别频繁的创建大对象。 因此 JVM 会根据一个阈值来判断大于该阈值对象直接分配到老年代，这样可以避免在新生代频繁的发生 GC。 对于一些在新生代的老对象 JVM 也会根据某种机制移动到老年代中。 JVM 是根据记录对象年龄的方式来判断该对象是否应该移动到老年代，根据新生代的复制算法，当一个对象被移动到 Survivor 区之后 JVM 就给该对象的年龄记为1，每当熬过一次 minorGC 后对象的年龄就 +1 ，直到达到阈值(默认为15)就移动到老年代中。 可以使用 -XX:MaxTenuringThreshold=15 来配置这个阈值。 总结虽说这些内容略显枯燥，但当应用发生不正常的 GC 时，可以方便更快的定位问题。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[synchronized 关键字原理]]></title>
    <url>%2F2018%2F01%2F14%2FSynchronize%2F</url>
    <content type="text"><![CDATA[众所周知 synchronized 关键字是解决并发问题常用解决方案，有以下三种使用方式: 同步普通方法，锁的是当前对象。 同步静态方法，锁的是当前 Class 对象。 同步块，锁的是 () 中的对象。 实现原理：JVM 是通过进入、退出对象监视器( Monitor )来实现对方法、同步块的同步的。 具体实现是在编译之后在同步方法调用前加入一个 monitor.enter 指令，在退出方法和异常处插入 monitor.exit 的指令。 其本质就是对一个对象监视器( Monitor )进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。 而对于没有获取到锁的线程将会阻塞到方法入口处，直到获取锁的线程 monitor.exit 之后才能尝试继续获取锁。 流程图如下: 通过一段代码来演示: 12345public static void main(String[] args) &#123; synchronized (Synchronize.class)&#123; System.out.println("Synchronize"); &#125;&#125; 使用 javap -c Synchronize 可以查看编译之后的具体信息。 123456789101112131415161718192021222324252627282930public class com.crossoverjie.synchronize.Synchronize &#123; public com.crossoverjie.synchronize.Synchronize(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: ldc #2 // class com/crossoverjie/synchronize/Synchronize 2: dup 3: astore_1 **4: monitorenter** 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: ldc #4 // String Synchronize 10: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 13: aload_1 **14: monitorexit** 15: goto 23 18: astore_2 19: aload_1 20: monitorexit 21: aload_2 22: athrow 23: return Exception table: from to target type 5 15 18 any 18 21 18 any&#125; 可以看到在同步块的入口和出口分别有 monitorenter,monitorexit指令。 锁优化synchronized 很多都称之为重量锁，JDK1.6 中对 synchronized 进行了各种优化，为了能减少获取和释放锁带来的消耗引入了偏向锁和轻量锁。 轻量锁当代码进入同步块时，如果同步对象为无锁状态时，当前线程会在栈帧中创建一个锁记录(Lock Record)区域，同时将锁对象的对象头中 Mark Word 拷贝到锁记录中，再尝试使用 CAS 将 Mark Word 更新为指向锁记录的指针。 如果更新成功，当前线程就获得了锁。 如果更新失败 JVM 会先检查锁对象的 Mark Word 是否指向当前线程的锁记录。 如果是则说明当前线程拥有锁对象的锁，可以直接进入同步块。 不是则说明有其他线程抢占了锁，如果存在多个线程同时竞争一把锁，轻量锁就会膨胀为重量锁。 解锁轻量锁的解锁过程也是利用 CAS 来实现的，会尝试锁记录替换回锁对象的 Mark Word 。如果替换成功则说明整个同步操作完成，失败则说明有其他线程尝试获取锁，这时就会唤醒被挂起的线程(此时已经膨胀为重量锁) 轻量锁能提升性能的原因： 认为大多数锁在整个同步周期都不存在竞争，所以使用 CAS 比使用互斥开销更少。但如果锁竞争激烈，轻量锁就不但有互斥的开销，还有 CAS 的开销，甚至比重量锁更慢。 偏向锁为了进一步的降低获取锁的代价，JDK1.6 之后还引入了偏向锁。 偏向锁的特征是:锁不存在多线程竞争，并且应由一个线程多次获得锁。 当线程访问同步块时，会使用 CAS 将线程 ID 更新到锁对象的 Mark Word 中，如果更新成功则获得偏向锁，并且之后每次进入这个对象锁相关的同步块时都不需要再次获取锁了。 释放锁当有另外一个线程获取这个锁时，持有偏向锁的线程就会释放锁，释放时会等待全局安全点(这一时刻没有字节码运行)，接着会暂停拥有偏向锁的线程，根据锁对象目前是否被锁来判定将对象头中的 Mark Word 设置为无锁或者是轻量锁状态。 偏向锁可以提高带有同步却没有竞争的程序性能，但如果程序中大多数锁都存在竞争时，那偏向锁就起不到太大作用。可以使用 -XX:-userBiasedLocking=false 来关闭偏向锁，并默认进入轻量锁。 其他优化适应性自旋在使用 CAS 时，如果操作失败，CAS 会自旋再次尝试。由于自旋是需要消耗 CPU 资源的，所以如果长期自旋就白白浪费了 CPU。JDK1.6加入了适应性自旋: 如果某个锁自旋很少成功获得，那么下一次就会减少自旋。 总结synchronized 现在已经不像以前那么重了，拿 1.8 中的 ConcurrentHashMap 就可以看出，里面大量的使用了 synchronized 来进行同步。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>Java 进阶</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>synchronize</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一致性 Hash 算法分析]]></title>
    <url>%2F2018%2F01%2F08%2FConsistent-Hash%2F</url>
    <content type="text"><![CDATA[当我们在做数据库分库分表或者是分布式缓存时，不可避免的都会遇到一个问题: 如何将数据均匀的分散到各个节点中，并且尽量的在加减节点时能使受影响的数据最少。 Hash 取模随机放置就不说了，会带来很多问题。通常最容易想到的方案就是 hash 取模了。 可以将传入的 Key 按照 index = hash(key) % N 这样来计算出需要存放的节点。其中 hash 函数是一个将字符串转换为正整数的哈希映射方法，N 就是节点的数量。 这样可以满足数据的均匀分配，但是这个算法的容错性和扩展性都较差。 比如增加或删除了一个节点时，所有的 Key 都需要重新计算，显然这样成本较高，为此需要一个算法满足分布均匀同时也要有良好的容错性和拓展性。 一致 Hash 算法一致 Hash 算法是将所有的哈希值构成了一个环，其范围在 0 ~ 2^32-1。如下图： 之后将各个节点散列到这个环上，可以用节点的 IP、hostname 这样的唯一性字段作为 Key 进行 hash(key)，散列之后如下： 之后需要将数据定位到对应的节点上，使用同样的 hash 函数 将 Key 也映射到这个环上。 这样按照顺时针方向就可以把 k1 定位到 N1节点，k2 定位到 N3节点，k3 定位到 N2节点。 容错性这时假设 N1 宕机了： 依然根据顺时针方向，k2 和 k3 保持不变，只有 k1 被重新映射到了 N3。这样就很好的保证了容错性，当一个节点宕机时只会影响到少少部分的数据。 拓展性当新增一个节点时: 在 N2 和 N3 之间新增了一个节点 N4 ，这时会发现受印象的数据只有 k3，其余数据也是保持不变，所以这样也很好的保证了拓展性。 虚拟节点到目前为止该算法依然也有点问题: 当节点较少时会出现数据分布不均匀的情况： 这样会导致大部分数据都在 N1 节点，只有少量的数据在 N2 节点。 为了解决这个问题，一致哈希算法引入了虚拟节点。将每一个节点都进行多次 hash，生成多个节点放置在环上称为虚拟节点: 计算时可以在 IP 后加上编号来生成哈希值。 这样只需要在原有的基础上多一步由虚拟节点映射到实际节点的步骤即可让少量节点也能满足均匀性。 号外最近在总结一些 Java 相关的知识点，感兴趣的朋友可以一起维护。 地址: https://github.com/crossoverJie/Java-Interview]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[sbc(六) Zuul GateWay 网关应用]]></title>
    <url>%2F2017%2F11%2F28%2Fsbc6%2F</url>
    <content type="text"><![CDATA[前言看过之前SBC系列的小伙伴应该都可以搭建一个高可用、分布式的微服务了。 目前的结构图应该如下所示: 各个微服务之间都不存在单点，并且都注册于 Eureka ，基于此进行服务的注册于发现，再通过 Ribbon 进行服务调用，并具有客户端负载功能。 一切看起来都比较美好，但这里却忘了一个重要的细节： 当我们需要对外提供服务时怎么处理？ 这当然也能实现，无非就是将我们具体的微服务地址加端口暴露出去即可。 那又如何来实现负载呢？ 简单！可以通过 Nginx F5 之类的工具进行负载。 但是如果系统庞大，服务拆分的足够多那又有谁来维护这些路由关系呢？ 当然这是运维的活，不过这时候运维可能就要发飙了！ 并且还有一系列的问题: 服务调用之间的一些鉴权、签名校验怎么做？ 由于服务端地址较多，客户端请求难以维护。 针对于这一些问题 SpringCloud 全家桶自然也有对应的解决方案: Zuul。当我们系统整合 Zuul 网关之后架构图应该如下所示: 我们在所有的请求进来之前抽出一层网关应用，将服务提供的所有细节都进行了包装，这样所有的客户端都是和网关进行交互，简化了客户端开发。 同时具有如下功能: Zuul 注册于 Eureka 并集成了 Ribbon 所以自然也是可以从注册中心获取到服务列表进行客户端负载。 功能丰富的路由功能，解放运维。 具有过滤器，所以鉴权、验签都可以集成。 基于此我们来看看之前的架构中如何集成 Zuul 。 集成 Zuul为此我新建了一个项目 sbc-gateway-zuul 就是一个基础的 SpringBoot 结构。其中加入了 Zuul 的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 由于需要将网关也注册到 Eureka 中，所以自然也需要: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; 紧接着配置一些项目基本信息: 12345678# 项目配置spring.application.name=sbc-gateway-zuulserver.context-path=/server.port=8383# eureka地址eureka.client.serviceUrl.defaultZone=http://node1:8888/eureka/eureka.instance.prefer-ip-address=true 在启动类中加入开启 Zuul 的注解，一个网关应用就算是搭好了。 123456@SpringBootApplication//开启zuul代理@EnableZuulProxypublic class SbcGateWayZuulApplication &#123;&#125; 启动 Eureka 和网关看到已经注册成功那就大功告成了: 路由路由是网关的核心功能之一，可以使系统有一个统一的对外接口，下面来看看具体的应用。 传统路由传统路由非常简单，和 Nginx 类似，由开发、运维人员来维护请求地址和对应服务的映射关系，类似于: 12zuul.routes.user-service.path=/user-service/**zuul.routes.user-sercice.url=http://localhost:8080/ 这样当我们访问 http://localhost:8383/user-service/getUserInfo/1 网关就会自动给我们路由到 http://localhost:8080/getUserInfo/1 上。 可见只要我们维护好这个映射关系即可自由的配置路由信息(user-sercice 可自定义)，但是很明显这种方式不管是对运维还是开发都不友好。由于实际这种方式用的不多就再过多展开。 服务路由对此 Zuul 提供了一种基于服务的路由方式。我们只需要维护请求地址与服务 ID 之间的映射关系即可，并且由于集成了 Ribbon , Zuul 还可以在路由的时候通过 Eureka 实现负载调用。 具体配置： 12zuul.routes.sbc-user.path=/api/user/**zuul.routes.sbc-user.serviceId=sbc-user 这样当输入 http://localhost:8383/api/user/getUserInfo/1 时就会路由到注册到 Eureka 中服务 ID 为 sbc-user 的服务节点，如果有多节点就会按照 Ribbon 的负载算法路由到其中一台上。 以上配置还可以简写为: 12# 服务路由 简化配置zuul.routes.sbc-user=/api/user/** 这样让我们访问 http://127.0.0.1:8383/api/user/userService/getUserByHystrix 时候就会根据负载算法帮我们路由到 sbc-user 应用上，如下图所示: 启动了两个 sbc-user 服务。 请求结果: 一次路由就算完成了。 在上面的配置中有看到 /api/user/** 这样的通配符配置，具体有以下三种配置需要了解: ? 只能匹配任意的单个字符，如 /api/user/? 就只能匹配 /api/user/x /api/user/y /api/user/z 这样的路径。 * 只能匹配任意字符，如 /api/user/* 就只能匹配 /api/user/x /api/user/xy /api/user/xyz。 ** 可以匹配任意字符、任意层级。结合了以上两种通配符的特点，如 /api/user/** 则可以匹配 /api/user/x /api/user/x/y /api/user/x/y/zzz这样的路径，最简单粗暴！ 谈到通配符匹配就不得不提到一个问题，如上面的 sbc-user 服务由于后期迭代更新，将 sbc-user 中的一部分逻辑抽成了另一个服务 sbc-user-pro。新应用的路由规则是 /api/user/pro/**,如果我们按照: 12zuul.routes.sbc-user=/api/user/**zuul.routes.sbc-user-pro=/api/user/pro/** 进行配置的话，我们想通过 /api/user/pro/ 来访问 sbc-user-pro 应用，却由于满足第一个路由规则，所以会被 Zuul 路由到 sbc-user 这个应用上，这显然是不对的。该怎么解决这个问题呢？ 翻看路由源码 org.springframework.cloud.netflix.zuul.filters.SimpleRouteLocator 中的 locateRoutes() 方法: 1234567891011/** * Compute a map of path pattern to route. The default is just a static map from the * &#123;@link ZuulProperties&#125;, but subclasses can add dynamic calculations. */protected Map&lt;String, ZuulRoute&gt; locateRoutes() &#123; LinkedHashMap&lt;String, ZuulRoute&gt; routesMap = new LinkedHashMap&lt;String, ZuulRoute&gt;(); for (ZuulRoute route : this.properties.getRoutes().values()) &#123; routesMap.put(route.getPath(), route); &#125; return routesMap;&#125; 发现路由规则是遍历配置文件并放入 LinkedHashMap 中，由于 LinkedHashMap 是有序的，所以为了达到上文的效果，配置文件的加载顺序非常重要，因此我们只需要将优先匹配的路由规则放前即可解决。 过滤器过滤器可以说是整个 Zuul 最核心的功能，包括上文提到路由功能也是由过滤器来实现的。 摘抄官方的解释: Zuul 的核心就是一系列的过滤器，他能够在整个 HTTP 请求、响应过程中执行各样的操作。 其实总结下来就是四个特征: 过滤类型 过滤顺序 执行条件 具体实现 其实就是 ZuulFilter 接口中所定义的四个接口: 1234567String filterType();int filterOrder();boolean shouldFilter();Object run(); 官方流程图(生命周期): 简单理解下就是: 当一个请求进来时，首先是进入 pre 过滤器，可以做一些鉴权，记录调试日志等操作。之后进入 routing 过滤器进行路由转发，转发可以使用 Apache HttpClient 或者是 Ribbon 。post 过滤器呢则是处理服务响应之后的数据，可以进行一些包装来返回客户端。 error 则是在有异常发生时才会调用，相当于是全局异常拦截器。 自定义过滤器接下来实现一个文初所提到的鉴权操作: 新建一个 RequestFilter 类继承与 ZuulFilter 接口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Function: 请求拦截 * * @author crossoverJie * Date: 2017/11/20 00:33 * @since JDK 1.8 */public class RequestFilter extends ZuulFilter &#123; private Logger logger = LoggerFactory.getLogger(RequestFilter.class) ; /** * 请求路由之前被拦截 实现 pre 拦截器 * @return */ @Override public String filterType() &#123; return "pre"; &#125; @Override public int filterOrder() &#123; return 0; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() &#123; RequestContext currentContext = RequestContext.getCurrentContext(); HttpServletRequest request = currentContext.getRequest(); String token = request.getParameter("token"); if (StringUtil.isEmpty(token))&#123; logger.warn("need token"); //过滤请求 currentContext.setSendZuulResponse(false); currentContext.setResponseStatusCode(400); return null ; &#125; logger.info("token =&#123;&#125;",token) ; return null; &#125;&#125; 非常 easy，就简单校验下请求中是否包含 token，不包含就返回 401 code。 不但如此，还需要将该类加入到 Spring 进行管理: 新建了 FilterConf 类: 123456789@Configuration@Componentpublic class FilterConf &#123; @Bean public RequestFilter filter()&#123; return new RequestFilter() ; &#125;&#125; 这样重启之后就可以看到效果了: 不传 token 时： 传入 token 时： 可见一些鉴权操作是可以放到这里来进行统一处理的。 其余几个过滤器也是大同小异，可以根据实际场景来自定义。 Zuul 高可用Zuul 现在既然作为了对外的第一入口，那肯定不能是单节点，对于 Zuul 的高可用有以下两种方式实现。 Eureka 高可用第一种最容易想到和实现:我们可以部署多个 Zuul 节点，并且都注册于 Eureka ，如下图： 这样虽然简单易维护，但是有一个严重的缺点：那就是客户端也得注册到 Eureka 上才能对 Zuul 的调用做到负载，这显然是不现实的。 所以下面这种做法更为常见。 基于 Nginx 高可用在调用 Zuul 之前使用 Nginx 之类的负载均衡工具进行负载，这样 Zuul 既能注册到 Eureka ，客户端也能实现对 Zuul 的负载，如下图： 总结这样在原有的微服务架构的基础上加上网关之后另整个系统更加完善了，从网关的设计来看：大多数系统架构都有分层的概念，不能解决问题那就多分几层🤓。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【译】你可以用GitHub做的12件 Cool 事情]]></title>
    <url>%2F2017%2F11%2F05%2Ftranslation1-12%20cool%20things%20you%20can%20do%20with%20GitHub%2F</url>
    <content type="text"><![CDATA[原文链接1 在 GitHub.com 编辑代码我将从我认为大家都知道的一件事情开始(尽管我是直到一周前才知道)。 当你在 GitHub 查看文件时(任何文本文件，任何仓库中)，右上角会有一个小铅笔图标，点击它就可以编辑文件了。完成之后点击 Propose file change 按钮 GitHub 将会自动帮你 fork 该项目并且创建一个 pull request 。 很厉害吧！他自动帮你 fork 了该 repo。 不再需要 fork , pull ,本地编辑再 push 以及创建一个 PR 这样的流程了。 这非常适合修复编写代码中出现的拼写错误和修正一个不太理想的想法。 2 粘贴图片你不仅仅受限于输入文本和描述问题，你知道你可以直接从粘贴板中粘贴图片吗？当你粘贴时，你会看到图片已经被上传了(毫无疑问被上传到云端)之后会变成 Markdown 语法来显示图片。 3 格式化代码如果你想写一段代码，你可以三个反引号开始 —— 就像你在研究MarkDown时所学到的 —— 之后 GitHub 会试着猜测你写的语言。 但如果你写了一些类似于 Vue, Typescript, JSX 这样的语言，你可以明确指定得到正确的高亮。 注意第一行中的1```jsx 这意味着代码段将会呈现出: (这个扩展于 gists 。顺便说一句，如果你使用 .jsx 后缀，就会得到JSX的语法高亮) 这是一个所有受支持的语法列表。 4 在 PR 中用关键词关闭 Issues假设你创建了一个用于修复 Issues #234 的 PR ,你可以在你 PR 的描述中填写 fixes #234 (或是在你 PR 任意评论中填写都是可以的)。之后合并这个 PR 时将会自动关闭填写的 Issues。怎么样,很 cool 吧。 了解是更多相关的内容。 5 链接到评论你是否有过想要链接到特殊 comment 的想法但却无法实现？那是因为你不知道怎么做。朋友那都是过去式了，现在我就告诉你，点击用户名旁边的日期/时间即可链接到该 comment 。 6 链接到代码我知道你想链接到具体的代码行上。 尝试:查看文件时，点击代码旁边的行号。 看到了吧，浏览器的 URL 已经被更新为行号了。如果你按住 shift,同时点击其他行号，URL 再次被更新，并且你也高亮显示页面中的一段代码。 分享这个 URL ，访问时将会链接到该文件已经选中的那些代码段。 但等一下，那指向的是当前的分支，如果文件发生了改变呢？也许一个在当前状态连接到文件的永久连接正是你想要的。 我很懒，所以用一张截图展示以上的所有操作。 谈到网址。。。 7 像命令行一样使用 GitHub 链接使用 GitHub 自带的 UI 浏览也还不错，但有时直接在 URL 中输入是最快的方法。比如，我想跳转到我正在编辑的分支并和 master 进行对比，就可以在项目名称后面接上 /compare/branch-name 。 与选中分支的对比页将会显示出来: 以上就是和 master 分支的差异，如果想要合并分支的话，只需要输入 /compare/integration-branch...my-branch 即可。 你还可以利用快捷键达到同样的效果，使用 ctrl + L 或者 cmd + L 可以将光标移动到 URL 上(至少在 Chrome 中可以)。 加上浏览器的自动补全 —— 你就可以在两个分支之间轻松切换了。 8 在Issues创建列表你想在你的 issue 中看到复选框列表吗? 你想在查看 issue 列表是它们以好看的 2 of 5 进度条呈现吗？ 太好了！你可以用以下语法来创建一个交互性的复选框: 12345- [ ] Screen width (integer)- [x] Service worker support- [x] Fetch support- [ ] CSS flexbox support- [ ] Custom elements 是由一个空格、中横线、空格、左括号、空格(或者是 X )、右括号、空格以及一些文本组成。 你甚至可以真正的 选中/取消 这些复选框！基于某些原因，对于我来说你看起来像是技术魔力。是真的能够选中这些复选框！甚至它还更新了底层源码。 ps：以下包括第九点 基于GitHub的项目面板 由于用的不多就没有翻译。 10 GitHub wiki作为一个像维基百科那样的非结构化的页面集合， GitHub Wiki的供给(我把它称之为 Gwiki ) 是一个非常棒的功能。 对于结构化的页面来说 —— 例如你的文档：不能说这个页面是其他页面的子页面，或则是有 “下一节”，“上一节” 这样的便捷按钮。并且 Hansel 和 Gretel 也没有，因为结构化页面并没有 breadcrumbs 这样的设计。 我们继续，让 Gwiki 动起来，我从 NodeJS 的文档中复制了几页来作为 wiki 页面。然后创建了一个自定义侧边栏，帮助我更好地模拟一些实际的目录结构。尽管它不会突出显示你当前的页面位置，但侧边栏会一直存在。 这些链接需要你手动维护，但总的来说，我认为它可以做得很好。 如果需要的话可以看看。 虽然它与 GitBook ( Redux 文档所使用的)或者是定制网站相比仍有差距。但在你的 repo 中它有 80% 完全值得信赖的。 我的建议是: 如果你已经有多个 README.md 文件，并且想要一些关于用户指南或更详细的文档的不同的页面，那么你应该选择 Gwiki。 如果缺乏结构化/导航开始让你不爽的话，那就试试其他的吧。 11 GitHub Pages你可能已经知道使用 GitHub Pages 来托管一个静态网站。如果你不知道，现在就来学习，这一节是专门用于讨论使用 Jekyll 来构建一个站点的。 最简单的就是： GitHub Pages + Jekyll会通过一个漂亮的主题来渲染你的 README.md 文件。例如:通过 about-github 来查看的我的 README 页面。 如果我在 GitHub 中点击了 settings选项，切换到 Github Pages 设置，然后选择一个 Jekyll theme。。。 我就可以得到 Jekyll-themed 页面。 从这点上我可以主要依据易编辑的 Markdown 文件来构建一个完整的静态站点。本质上是把 GitHub 变成了 CMS。 虽然我没有实际使用过，但是 React Bootstrap 的网站都是使用它来构建的。所以它不会糟糕。 注意:它要求 Ruby 运行本地环境( Windows 自行安装， macOS 自带)。 12 把 GitHub 当做 CRM 使用假设你有一个存有一些文本内容的网站，你不想将文本内容存储于真正的 HTML 源码中。 相反的，你想要将这些文本块存储于非开发人员能轻松的进行编辑的地方。可能是一个版本控制系统，甚至是一个审核流程。 我的建议是:使用 GitHub 厂库中的 Markdown 文件来存储这些文本内容，然后使用前端组件来拉取这些文本块并展示在页面上。 我是搞 React 的，所以这有一个 解析 Markdown 的组件例子，给定一些 Markdown 文件路径，它将会自动拉取并作为 HTML 显示出来。 1234567891011121314151617181920212223242526class Markdown extends React.Component &#123; constructor(props) &#123; super(props); // replace with your URL, obviously this.baseUrl = &apos;https://raw.githubusercontent.com/davidgilbertson/about-github/master/text-snippets&apos;; this.state = &#123; markdown: &apos;&apos;, &#125;; &#125; componentDidMount() &#123; fetch(`$&#123;this.baseUrl&#125;/$&#123;this.props.url&#125;`) .then(response =&gt; response.text()) .then((markdown) =&gt; &#123; this.setState(&#123;markdown&#125;); &#125;); &#125; render() &#123; return ( &lt;div dangerouslySetInnerHTML=&#123;&#123;__html: marked(this.state.markdown)&#125;&#125; /&gt; ); &#125;&#125; 奖励环节 —— GitHub 工具我已经使用了 Octotree Chrome extension 有段时间了，现在我向大家推荐它！无论你是在查看哪个 repo 它都会在左侧给你一个树状面板。 通过这个视频我了解到了 octobox，它是用于管理你的 GitHub Issues 收件箱，看起来相当不错！以上就是我针对于octobox的全部想法。 其他就是这样了！我希望这里至少有三件事是你还不知道的。 最后: hava a nice day！]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十七) MQ应用]]></title>
    <url>%2F2017%2F10%2F20%2FSSM17%2F</url>
    <content type="text"><![CDATA[前言写这篇文章的起因是由于之前的一篇关于Kafka异常消费，当时为了解决问题不得不使用临时的方案。 总结起来归根结底还是对Kafka不熟悉导致的，加上平时工作的需要，之后就花些时间看了Kafka相关的资料。 何时使用MQ谈到Kafka就不得不提到MQ，是属于消息队列的一种。作为一种基础中间件在互联网项目中有着大量的使用。 一种技术的产生自然是为了解决某种需求，通常来说是以下场景： 需要跨进程通信：B系统需要A系统的输出作为输入参数。 当A系统的输出能力远远大于B系统的处理能力。 针对于第一种情况有两种方案: 使用RPC远程调用,A直接调用B。 使用MQ,A发布消息到MQ,B订阅该消息。 当我们的需求是:A调用B实时响应，并且实时关心响应结果则使用RPC，这种情况就得使用同步调用。 反之当我们并不关心调用之后的执行结果，并且有可能被调用方的执行非常耗时，这种情况就非常适合用MQ来达到异步调用目的。 比如常见的登录场景就只能用同步调用的方式，因为这个过程需要实时的响应结果，总不能在用户点了登录之后排除网络原因之外再额外的等几秒吧。 但类似于用户登录需要奖励积分的情况则使用MQ会更好，因为登录并不关系积分的情况，只需要发个消息到MQ,处理积分的服务订阅处理即可，这样还可以解决积分系统故障带来的雪崩效应。 MQ还有一个基础功能则是限流削峰，这对于大流量的场景如果将请求直接调用到B系统则非常有可能使B系统出现不可用的情况。这种场景就非常适合将请求放入MQ，不但可以利用MQ削峰还尽可能的保证系统的高可用。 Kafka简介本次重点讨论下Kafka。简单来说Kafka是一个支持水平扩展，高吞吐率的分布式消息系统。 Kafka的常用知识: Topic:生产者和消费者的交互都是围绕着一个Topic进行的，通常来说是由业务来进行区分，由生产消费者协商之后进行创建。 Partition(分区):是Topic下的组成，通常一个Topic下有一个或多个分区，消息生产之后会按照一定的算法负载到每个分区，所以分区也是Kafka性能的关键。当发现性能不高时便可考虑新增分区。 结构图如下: 创建TopicKafka的安装官网有非常详细的讲解。这里谈一下在日常开发中常见的一些操作，比如创建Topic： 1sh bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 3 --topic `test` 创建了三个分区的test主题。 使用 1sh bin/kafka-topics.sh --list --zookeeper localhost:2181 可以列出所有的Topic。 Kafka生产者使用kafka官方所提供的Java API来进行消息生产，实际使用中编码实现更为常用: 12345678910111213141516171819202122232425262728293031323334353637383940/** Kafka生产者 * @author crossoverJie */public class Producer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Producer.class); /** * 消费配置文件 */ private static String consumerProPath; public static void main(String[] args) throws IOException &#123; // set up the producer consumerProPath = System.getProperty("product_path"); KafkaProducer&lt;String, String&gt; producer = null; try &#123; FileInputStream inputStream = new FileInputStream(new File(consumerProPath)); Properties properties = new Properties(); properties.load(inputStream); producer = new KafkaProducer&lt;String, String&gt;(properties); &#125; catch (IOException e) &#123; LOGGER.error("load config error", e); &#125; try &#123; // send lots of messages for (int i=0 ;i&lt;100 ; i++)&#123; producer.send(new ProducerRecord&lt;String, String&gt;( "topic_optimization", i+"", i+"")); &#125; &#125; catch (Throwable throwable) &#123; System.out.printf("%s", throwable.getStackTrace()); &#125; finally &#123; producer.close(); &#125; &#125;&#125; 再配合以下启动参数即可发送消息:1-Dproduct_path=/xxx/producer.properties 以及生产者的配置文件:12345678910#集群地址，可以多个bootstrap.servers=10.19.13.51:9094acks=allretries=0batch.size=16384auto.commit.interval.ms=1000linger.ms=0key.serializer=org.apache.kafka.common.serialization.StringSerializervalue.serializer=org.apache.kafka.common.serialization.StringSerializerblock.on.buffer.full=true 具体的配置说明详见此处:https://kafka.apache.org/0100/documentation.html#theproducer 流程非常简单，其实就是一些API的调用。 消息发完之后可以通过以下命令查看队列内的情况:1sh kafka-consumer-groups.sh --bootstrap-server localhost:9094 --describe --group group1 其中的lag便是队列里的消息数量。 Kafka消费者有了生产者自然也少不了消费者，这里首先针对单线程消费: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/** * Function:kafka官方消费 * * @author crossoverJie * Date: 2017/10/19 01:11 * @since JDK 1.8 */public class KafkaOfficialConsumer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(KafkaOfficialConsumer.class); /** * 日志文件地址 */ private static String logPath; /** * 主题名称 */ private static String topic; /** * 消费配置文件 */ private static String consumerProPath ; /** * 初始化参数校验 * @return */ private static boolean initCheck() &#123; topic = System.getProperty("topic") ; logPath = System.getProperty("log_path") ; consumerProPath = System.getProperty("consumer_pro_path") ; if (StringUtil.isEmpty(topic) || logPath.isEmpty()) &#123; LOGGER.error("system property topic ,consumer_pro_path, log_path is required !"); return true; &#125; return false; &#125; /** * 初始化kafka配置 * @return */ private static KafkaConsumer&lt;String, String&gt; initKafkaConsumer() &#123; KafkaConsumer&lt;String, String&gt; consumer = null; try &#123; FileInputStream inputStream = new FileInputStream(new File(consumerProPath)) ; Properties properties = new Properties(); properties.load(inputStream); consumer = new KafkaConsumer&lt;String, String&gt;(properties); consumer.subscribe(Arrays.asList(topic)); &#125; catch (IOException e) &#123; LOGGER.error("加载consumer.props文件出错", e); &#125; return consumer; &#125; public static void main(String[] args) &#123; if (initCheck())&#123; return; &#125; int totalCount = 0 ; long totalMin = 0L ; int count = 0; KafkaConsumer&lt;String, String&gt; consumer = initKafkaConsumer(); long startTime = System.currentTimeMillis() ; //消费消息 while (true) &#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(200); if (records.count() &lt;= 0)&#123; continue ; &#125; LOGGER.debug("本次获取:"+records.count()); count += records.count() ; long endTime = System.currentTimeMillis() ; LOGGER.debug("count=" +count) ; if (count &gt;= 10000 )&#123; totalCount += count ; LOGGER.info("this consumer &#123;&#125; record，use &#123;&#125; milliseconds",count,endTime-startTime); totalMin += (endTime-startTime) ; startTime = System.currentTimeMillis() ; count = 0 ; &#125; LOGGER.debug("end totalCount=&#123;&#125;,min=&#123;&#125;",totalCount,totalMin); /*for (ConsumerRecord&lt;String, String&gt; record : records) &#123; record.value() ; JsonNode msg = null; try &#123; msg = mapper.readTree(record.value()); &#125; catch (IOException e) &#123; LOGGER.error("消费消息出错", e); &#125; LOGGER.info("kafka receive = "+msg.toString()); &#125;*/ &#125; &#125;&#125; 配合以下启动参数:1-Dlog_path=/log/consumer.log -Dtopic=test -Dconsumer_pro_path=consumer.properties 其中采用了轮询的方式获取消息，并且记录了消费过程中的数据。 消费者采用的配置:1234567891011121314151617bootstrap.servers=192.168.1.2:9094group.id=group1# 自动提交enable.auto.commit=truekey.deserializer=org.apache.kafka.common.serialization.StringDeserializervalue.deserializer=org.apache.kafka.common.serialization.StringDeserializer# fast session timeout makes it more fun to play with failoversession.timeout.ms=10000# These buffer sizes seem to be needed to avoid consumer switching to# a mode where it processes one bufferful every 5 seconds with multiple# timeouts along the way. No idea why this happens.fetch.min.bytes=50000receive.buffer.bytes=262144max.partition.fetch.bytes=2097152 为了简便我采用的是自动提交offset。 消息存放机制谈到offset就必须得谈谈Kafka的消息存放机制. Kafka的消息不会因为消费了就会立即删除，所有的消息都会持久化到日志文件，并配置有过期时间，到了时间会自动删除过期数据，并且不会管其中的数据是否被消费过。 由于这样的机制就必须的有一个标志来表明哪些数据已经被消费过了，offset(偏移量)就是这样的作用，它类似于指针指向某个数据，当消费之后offset就会线性的向前移动，这样一来的话消息是可以被任意消费的，只要我们修改offset的值即可。 消费过程中还有一个值得注意的是: 同一个consumer group(group.id相等)下只能有一个消费者可以消费，这个刚开始确实会让很多人踩坑。 多线程消费针对于单线程消费实现起来自然是比较简单，但是效率也是要大打折扣的。 为此我做了一个测试，使用之前的单线程消费120009条数据的结果如下: 总共花了12450毫秒。 那么换成多线程消费怎么实现呢？ 我们可以利用partition的分区特性来提高消费能力，单线程的时候等于是一个线程要把所有分区里的数据都消费一遍，如果换成多线程就可以让一个线程只消费一个分区,这样效率自然就提高了，所以线程数coreSize&lt;=partition。 首先来看下入口: 1234567891011121314151617public class ConsumerThreadMain &#123; private static String brokerList = &quot;localhost:9094&quot;; private static String groupId = &quot;group1&quot;; private static String topic = &quot;test&quot;; /** * 线程数量 */ private static int threadNum = 3; public static void main(String[] args) &#123; ConsumerGroup consumerGroup = new ConsumerGroup(threadNum, groupId, topic, brokerList); consumerGroup.execute(); &#125;&#125; 其中的ConsumerGroup类:12345678910111213141516171819202122232425262728293031323334353637383940public class ConsumerGroup &#123; private static Logger LOGGER = LoggerFactory.getLogger(ConsumerGroup.class); /** * 线程池 */ private ExecutorService threadPool; private List&lt;ConsumerCallable&gt; consumers ; public ConsumerGroup(int threadNum, String groupId, String topic, String brokerList) &#123; ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(&quot;consumer-pool-%d&quot;).build(); threadPool = new ThreadPoolExecutor(threadNum, threadNum, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); consumers = new ArrayList&lt;ConsumerCallable&gt;(threadNum); for (int i = 0; i &lt; threadNum; i++) &#123; ConsumerCallable consumerThread = new ConsumerCallable(brokerList, groupId, topic); consumers.add(consumerThread); &#125; &#125; /** * 执行任务 */ public void execute() &#123; long startTime = System.currentTimeMillis() ; for (ConsumerCallable runnable : consumers) &#123; Future&lt;ConsumerFuture&gt; future = threadPool.submit(runnable) ; &#125; if (threadPool.isShutdown())&#123; long endTime = System.currentTimeMillis() ; LOGGER.info(&quot;main thread use &#123;&#125; Millis&quot; ,endTime -startTime) ; &#125; threadPool.shutdown(); &#125;&#125; 最后真正的执行逻辑ConsumerCallable:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class ConsumerCallable implements Callable&lt;ConsumerFuture&gt; &#123; private static Logger LOGGER = LoggerFactory.getLogger(ConsumerCallable.class); private AtomicInteger totalCount = new AtomicInteger() ; private AtomicLong totalTime = new AtomicLong() ; private AtomicInteger count = new AtomicInteger() ; /** * 每个线程维护KafkaConsumer实例 */ private final KafkaConsumer&lt;String, String&gt; consumer; public ConsumerCallable(String brokerList, String groupId, String topic) &#123; Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, brokerList); props.put(&quot;group.id&quot;, groupId); //自动提交位移 props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); props.put(&quot;session.timeout.ms&quot;, &quot;30000&quot;); props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); this.consumer = new KafkaConsumer&lt;&gt;(props); consumer.subscribe(Arrays.asList(topic)); &#125; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ @Override public ConsumerFuture call() throws Exception &#123; boolean flag = true; int failPollTimes = 0 ; long startTime = System.currentTimeMillis() ; while (flag) &#123; // 使用200ms作为获取超时时间 ConsumerRecords&lt;String, String&gt; records = consumer.poll(200); if (records.count() &lt;= 0)&#123; failPollTimes ++ ; if (failPollTimes &gt;= 20)&#123; LOGGER.debug(&quot;达到&#123;&#125;次数，退出 &quot;,failPollTimes); flag = false ; &#125; continue ; &#125; //获取到之后则清零 failPollTimes = 0 ; LOGGER.debug(&quot;本次获取:&quot;+records.count()); count.addAndGet(records.count()) ; totalCount.addAndGet(count.get()) ; long endTime = System.currentTimeMillis() ; if (count.get() &gt;= 10000 )&#123; LOGGER.info(&quot;this consumer &#123;&#125; record，use &#123;&#125; milliseconds&quot;,count,endTime-startTime); totalTime.addAndGet(endTime-startTime) ; startTime = System.currentTimeMillis() ; count = new AtomicInteger(); &#125; LOGGER.debug(&quot;end totalCount=&#123;&#125;,min=&#123;&#125;&quot;,totalCount,totalTime); /*for (ConsumerRecord&lt;String, String&gt; record : records) &#123; // 简单地打印消息 LOGGER.debug(record.value() + &quot; consumed &quot; + record.partition() + &quot; message with offset: &quot; + record.offset()); &#125;*/ &#125; ConsumerFuture consumerFuture = new ConsumerFuture(totalCount.get(),totalTime.get()) ; return consumerFuture ; &#125;&#125; 理一下逻辑: 其实就是初始化出三个消费者实例，用于三个线程消费。其中加入了一些统计，最后也是消费120009条数据结果如下。 由于是并行运行，可见消费120009条数据可以提高2秒左右，当数据以更高的数量级提升后效果会更加明显。 但这也有一些弊端: 灵活度不高，当分区数量变更之后不能自适应调整。 消费逻辑和处理逻辑在同一个线程，如果处理逻辑较为复杂会影响效率，耦合也较高。当然这个处理逻辑可以再通过一个内部队列发出去由另外的程序来处理也是可以的。 总结Kafka的知识点还是较多，Kafka的使用也远不这些。之后会继续分享一些关于Kafka监控等相关内容。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(五)Hystrix-服务容错与保护]]></title>
    <url>%2F2017%2F09%2F20%2Fsbc5%2F</url>
    <content type="text"><![CDATA[前言看过 应用限流的朋友应该知道，限流的根本目的就是为了保障服务的高可用。 本次再借助SpringCloud中的集成的Hystrix组件来谈谈服务容错。 其实产生某项需求的原因都是为了解决某个需求。当我们将应用进行分布式模块部署之后,各个模块之间通过远程调用的方式进行交互(RPC)。拿我们平时最常见的下单买商品来说，点击下单按钮的一瞬间可能会向发送的请求包含： 请求订单系统创建订单。 请求库存系统扣除库存。 请求用户系统更新用户交易记录。 这其中的每一步都有可能因为网络、资源、服务器等原因造成延迟响应甚至是调用失败。当后面的请求源源不断的过来时延迟的资源也没有的到释放，这样的堆积很有可能把其中一个模块拖垮，其中的依赖关系又有可能把整个调用链中的应用Over最后导致整个系统不可能。这样就会产生一种现象:雪崩效应。 之前讲到的限流也能起到一定的保护作用，但还远远不够。我们需要从各个方面来保障服务的高可用。 比如： 超时重试。 断路器模式。 服务降级。等各个方面来保障。 使用HystrixSpringCloud中已经为我们集成了Netflix开源的Hystrix框架，使用该框架可以很好的帮我们做到服务容错。 Hystrix简介下面是一张官方的流程图: 简单介绍下: 在远程调用时，将请求封装到HystrixCommand进行同步或是异步调用，在调用过程中判断熔断器是否打开、线程池或是信号量是否饱和、执行过程中是否抛出异常，如果是的话就会进入回退逻辑。并且整个过程中都会收集运行状态来控制断路器的状态。 不但如此该框架还拥有自我恢复功能，当断路器打开后，每次请求都会进入回退逻辑。当我们的应用恢复正常后也不能再进入回退逻辑吧。 所以hystrix会在断路器打开后的一定时间将请求发送到服务提供者，如果正常响应就关闭断路器，反之则继续打开，这样就能很灵活的自我修复了。 Feign整合Hystrix在之前的章节中已经使用Feign来进行声明式调用了，并且在实际开发中也是如此，所以这次我们就直接用Feign来整合Hystrix。 使用了项目原有的sbc-user,sbc-order来进行演示，调用关系如下图: User应用通过Order提供出来的order-client依赖调用了Order中的创建订单服务。 其中主要修改的就是order-client，在之前的OrderServiceClient接口中增加了以下注解: 12345678910111213@RequestMapping(value="/orderService")@FeignClient(name="sbc-order", // fallbackFactory = OrderServiceFallbackFactory.class, // FIXME: 2017/9/4 如果配置了fallback 那么fallbackFactory将会无效 fallback = OrderServiceFallBack.class, configuration = OrderConfig.class)@RibbonClientpublic interface OrderServiceClient extends OrderService&#123; @ApiOperation("获取订单号") @RequestMapping(value = "/getOrderNo", method = RequestMethod.POST) BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) ;&#125; 由于Feign已经默认整合了Hystrix所以不需要再额外加入依赖。 服务降级对应的@FeignClient中的fallback属性则是服务容错中很关键的服务降级的具体实现，来看看OrderServiceFallBack类: 123456789101112public class OrderServiceFallBack implements OrderServiceClient &#123; @Override public BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) &#123; BaseResponse&lt;OrderNoResVO&gt; baseResponse = new BaseResponse&lt;&gt;() ; OrderNoResVO vo = new OrderNoResVO() ; vo.setOrderId(123456L); baseResponse.setDataBody(vo); baseResponse.setMessage(StatusEnum.FALLBACK.getMessage()); baseResponse.setCode(StatusEnum.FALLBACK.getCode()); return baseResponse; &#125;&#125; 该类实现了OrderServiceClient接口，可以很明显的看出其中的getOrderNo()方法就是服务降级时所触发的逻辑。 光有实现还不够，我们需要将改类加入到Spring中管理起来。这样上文中@FeignClient的configuration属性就起到作用了，来看看对应的OrderConfig的代码: 123456789101112@Configurationpublic class OrderConfig &#123; @Bean public OrderServiceFallBack fallBack()&#123; return new OrderServiceFallBack(); &#125; @Bean public OrderServiceFallbackFactory factory()&#123; return new OrderServiceFallbackFactory(); &#125;&#125; 其中new OrderServiceFallBack()并用了@Bean注解，等同于: 12&lt;bean id=&quot;orderServiceFallBack&quot; class=&quot;com.crossoverJie.order.feign.config.OrderServiceFallBack&quot;&gt;&lt;/bean&gt; 这样每当请求失败就会执行回退逻辑，如下图: 值得注意的是即便是执行了回退逻辑断路器也不一定打开了，我们可以通过应用的health端点来查看Hystrix的状态。 ps:想要查看该端点需要加入以下依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 就拿刚才的例子来说，先关闭Order应用，在Swagger访问下面这个接口，肯定是会进入回退逻辑: 12345678910@RestController@Api("用户服务API")@RequestMapping(value = "/userService")@Validatedpublic interface UserService &#123; @ApiOperation("hystrix容错调用") @RequestMapping(value = "/getUserByHystrix", method = RequestMethod.POST) BaseResponse&lt;OrderNoResVO&gt; getUserByHystrix(@RequestBody UserReqVO userReqVO) ;&#125; 查看health端点: 发现Hystrix的状态依然是UP状态，表明当前断路器并没有打开。 反复调用多次接口之后再次查看health端点: 发现这个时候断路器已经打开了。 这是因为断路器只有在达到了一定的失败阈值之后才会打开。 输出异常进入回退逻辑之后还不算完，大部分场景我们都需要记录为什么回退，也就是具体的异常。这些信息对我们后续的系统监控，应用调优也有很大帮助。 实现起来也很简单:上文中在@FeignClient注解中加入的fallbackFactory = OrderServiceFallbackFactory.class属性则是用于处理回退逻辑以及包含异常信息： 123456789101112131415161718192021222324252627282930/** * Function:查看fallback原因 * * @author crossoverJie * Date: 2017/9/4 00:45 * @since JDK 1.8 */public class OrderServiceFallbackFactory implements FallbackFactory&lt;OrderServiceClient&gt;&#123; private final static Logger LOGGER = LoggerFactory.getLogger(OrderServiceFallbackFactory.class); @Override public OrderServiceClient create(Throwable throwable) &#123; return new OrderServiceClient() &#123; @Override public BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) &#123; LOGGER.error("fallback:" + throwable); BaseResponse&lt;OrderNoResVO&gt; baseResponse = new BaseResponse&lt;&gt;() ; OrderNoResVO vo = new OrderNoResVO() ; vo.setOrderId(123456L); baseResponse.setDataBody(vo); baseResponse.setMessage(StatusEnum.FALLBACK.getMessage()); baseResponse.setCode(StatusEnum.FALLBACK.getCode()); return baseResponse; &#125; &#125;; &#125;&#125; 代码很简单，实现了FallbackFactory接口中的create()方法，该方法的入参就是异常信息，可以按照我们的需要自行处理，后面则是和之前一样的回退处理。 2017-09-21 13:22:30.307 ERROR 27838 --- [rix-sbc-order-1] c.c.o.f.f.OrderServiceFallbackFactory : fallback:java.lang.RuntimeException: com.netflix.client.ClientException: Load balancer does not have available server for client: sbc-order。 Note: fallbackFactory和fallback属性不可共用。 Hystrix监控Hystrix还自带了一套监控组件，只要依赖了spring-boot-starter-actuator即可通过/hystrix.stream端点来获得监控信息。 冰冷的数据肯定没有实时的图表来的直观，所以Hystrix也自带Dashboard。 Hystrix与Turbine聚合监控为此我们新建了一个应用sbc-hystrix-turbine来显示hystrix-dashboard。目录结构和普通的springboot应用没有差异，看看主类: 1234567891011//开启EnableTurbine@EnableTurbine@SpringBootApplication@EnableHystrixDashboardpublic class SbcHystrixTurbineApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SbcHystrixTurbineApplication.class, args); &#125;&#125; 其中使用@EnableHystrixDashboard开启Dashboard @EnableTurbine开启Turbine支持。 以上这些注解需要以下这些依赖:12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-turbine&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-netflix-turbine&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; 实际项目中，我们的应用都是多节点部署以达到高可用的目的，单个监控显然不现实，所以需要使用Turbine来进行聚合监控。 关键的application.properties配置文件: 123456789101112# 项目配置spring.application.name=sbc-hystrix-trubineserver.context-path=/server.port=8282# eureka地址eureka.client.serviceUrl.defaultZone=http://node1:8888/eureka/eureka.instance.prefer-ip-address=true# 需要加入的实例turbine.appConfig=sbc-user,sbc-orderturbine.cluster-name-expression=&quot;default&quot; 其中turbine.appConfig配置我们需要监控的应用，这样当多节点部署的时候就非常方便了(同一个应用的多个节点spring.application.name值是相同的)。 将该应用启动访问http://ip:port/hystrix.stream： 由于我们的turbine和Dashboard是一个应用所以输入http://localhost:8282/turbine.stream即可。 详细指标如官方描述: 通过该面板我们就可以及时的了解到应用当前的各个状态，如果再加上一些报警措施就能帮我们及时的响应生产问题。 总结服务容错的整个还是比较大的,博主也是摸着石头过河，关于本次的Hystrix只是一个入门版，后面会持续分析它的线程隔离、信号量隔离等原理。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十六) 曲线救国-Kafka消费异常]]></title>
    <url>%2F2017%2F09%2F05%2FSSM16%2F</url>
    <content type="text"><![CDATA[前言最近线上遇到一个问题:在消费kafka消息的时候如果长时间(大概半天到一天的时间)队列里没有消息就可能再也消费不了。针对这个问题我们反复调试多次。线下模拟，调整代码，但貌似还是没有找到原因。但是只要重启消费进程就又可以继续消费。 解决方案由于线上业务非常依赖kafka的消费，但一时半会也没有找到原因，所以最后只能想一个临时的替换方案： 基于重启就可以消费这个特点，我们在每次消费的时候都记下当前的时间点，当这个时间点在十分钟之内都没有更新我们就认为当前队列中没有消息了，就需要重启下消费进程。 既然是需要重启，由于目前还没有上分布式调度中心所以需要crontab来配合调度：每隔一分钟会调用一个shell脚本，该脚本会判断当前进程是否存在，如果存在则什么都不作，不存在则启动消费进程。 具体实现消费程序:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/** * kafka消费 * * @author crossoverJie * @date 2017年6月19日 下午3:15:16 */public class KafkaMsgConsumer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(KafkaMsgConsumer.class); private static final int CORE_POOL_SIZE = 4; private static final int MAXIMUM_POOL_SIZE = 4; private static final int BLOCKING_QUEUE_CAPACITY = 4000; private static final String KAFKA_CONFIG = "kafkaConfig"; private static final ExecutorService fixedThreadPool = new ThreadPoolExecutor(CORE_POOL_SIZE, MAXIMUM_POOL_SIZE, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(BLOCKING_QUEUE_CAPACITY)); //最后更新时间 private static AtomicLong LAST_MESSAGE_TIME = new AtomicLong(DateUtil.getLongTime()); private static MsgIterator iter = null; private static String topic;//主题名称 static &#123; Properties properties = new Properties(); String path = System.getProperty(KAFKA_CONFIG); checkArguments(!StringUtils.isBlank(path), "启动参数中没有配置kafka_easyframe_msg参数来指定kafka启动参数，请使用-DkafkaConfig=/path/fileName/easyframe-msg.properties"); try &#123; properties.load(new FileInputStream(new File(path))); &#125; catch (IOException e) &#123; LOGGER.error("IOException" ,e); &#125; EasyMsgConfig.setProperties(properties); &#125; private static void iteratorTopic() &#123; if (iter == null) &#123; iter = MsgUtil.consume(topic); &#125; long i = 0L; while (iter.hasNext()) &#123; i++; if (i % 10000 == 0) &#123; LOGGER.info("consume i:" + i); &#125; try &#123; String message = iter.next(); if (StringUtils.isEmpty(message)) &#123; continue; &#125; LAST_MESSAGE_TIME = new AtomicLong(DateUtil.getLongTime()); //处理消息 LOGGER.debug("msg = " + JSON.toJSONString(message)); &#125; catch (Exception e) &#123; LOGGER.error("KafkaMsgConsumer err:", e); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; LOGGER.error("Thread InterruptedException", e1); &#125; break; &#125; &#125; &#125; public static void main(String[] args) &#123; topic = System.getProperty("topic"); checkArguments(!StringUtils.isBlank(topic), "system property topic or log_path is must!"); while (true) &#123; try &#123; iteratorTopic(); &#125; catch (Exception e) &#123; MsgUtil.shutdownConsummer(); iter = null; LOGGER.error("KafkaMsgConsumer err:", e); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; LOGGER.error("Thread InterruptedException", e1); &#125; &#125; finally &#123; //此处关闭之后，由crontab每分钟检查一次，挂掉的话会重新拉起来 if (DateUtil.getLongTime() - LAST_MESSAGE_TIME.get() &gt; 10 * 60) &#123; //10分钟 fixedThreadPool.shutdown(); LOGGER.info("线程池是否关闭：" + fixedThreadPool.isShutdown()); try &#123; //当前线程阻塞10ms后，去检测线程池是否终止，终止则返回true while (!fixedThreadPool.awaitTermination(10, TimeUnit.MILLISECONDS)) &#123; LOGGER.info("检测线程池是否终止：" + fixedThreadPool.isTerminated()); &#125; &#125; catch (InterruptedException e) &#123; LOGGER.error("等待线程池关闭错误", e); &#125; LOGGER.info("线程池是否终止：" + fixedThreadPool.isTerminated()); LOGGER.info("in 10 min dont have data break"); break; &#125; &#125; &#125; LOGGER.info("app shutdown"); System.exit(0); &#125;&#125; 在线代码 需要配合以下这个shell脚本运行: 1234567891011121314151617181920#!/bin/sh#crontab# * * * * * sh /data/schedule/kafka/run-kafka-consumer.sh &gt;&gt;/data/schedule/kafka/run-sms-log.log# 如果进程存在就不启动a1=`ps -ef|grep &apos;KafkaMsgConsumer&apos;|grep -v grep|wc -l`if [ $a1 -gt 0 ];then echo &quot;======= `date +&apos;%Y-%m-%d %H:%M:%S&apos;` KafkaMsgConsumer is EXIT...======= &quot; exitfiLANG=&quot;zh_CN.UTF-8&quot;nohup /opt/java/jdk1.7.0_80/bin/java -d64 -Djava.security.egd=file:/dev/./urandom-Djava.ext.dirs=/opt/tomcat/webapps/ROOT/WEB-INF/lib-Dtopic=TOPIC_A-Dlogback.configurationFile=/data/schedule/kafka/logback.xml-DkafkaConfig=/opt/tomcat/iopconf/easyframe-msg.properties-classpath /opt/tomcat/webapps/ROOT/WEB-INF/classes com.crossoverJie.kafka.SMSMsgConsumer &gt;&gt; /data/schedule/kafka/smslog/kafka.log 2&gt;&amp;1 &amp;echo &quot;`date +&apos;%Y-%m-%d %H:%M:%S&apos;` KafkaMsgConsumer running....&quot; 在线代码 再配合crontab的调度:1* * * * * sh /data/schedule/kafka/run-kafka-consumer.sh &gt;&gt;/data/schedule/kafka/run-sms-log.log 即可。 总结虽说处理起来很简单，但依然是治标不治本，依赖的东西比较多(shell脚本，调度)。所以也问问各位有没有什么思路： 消费程序用的:https://github.com/linzhaoming/easyframe-msg 生产配置: 三台kafka、ZK组成的集群。 其中也有其他团队的消费程序在正常运行，应该和kafka的配置没有关系。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Kafka</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(四)应用限流]]></title>
    <url>%2F2017%2F08%2F11%2Fsbc4%2F</url>
    <content type="text"><![CDATA[前言 在一个高并发系统中对流量的把控是非常重要的，当巨大的流量直接请求到我们的服务器上没多久就可能造成接口不可用，不处理的话甚至会造成整个应用不可用。 比如最近就有个这样的需求，我作为客户端要向kafka生产数据，而kafka的消费者则再源源不断的消费数据，并将消费的数据全部请求到web服务器，虽说做了负载(有4台web服务器)但业务数据的量也是巨大的，每秒钟可能有上万条数据产生。如果生产者直接生产数据的话极有可能把web服务器拖垮。 对此就必须要做限流处理，每秒钟生产一定限额的数据到kafka，这样就能极大程度的保证web的正常运转。 其实不管处理何种场景，本质都是降低流量保证应用的高可用。 常见算法对于限流常见有两种算法: 漏桶算法 令牌桶算法 漏桶算法比较简单，就是将流量放入桶中，漏桶同时也按照一定的速率流出，如果流量过快的话就会溢出(漏桶并不会提高流出速率)。溢出的流量则直接丢弃。 如下图所示: 这种做法简单粗暴。 漏桶算法虽说简单，但却不能应对实际场景，比如突然暴增的流量。 这时就需要用到令牌桶算法: 令牌桶会以一个恒定的速率向固定容量大小桶中放入令牌，当有流量来时则取走一个或多个令牌。当桶中没有令牌则将当前请求丢弃或阻塞。 相比之下令牌桶可以应对一定的突发流量. RateLimiter实现对于令牌桶的代码实现，可以直接使用Guava包中的RateLimiter。 12345678910111213141516171819202122232425@Overridepublic BaseResponse&lt;UserResVO&gt; getUserByFeignBatch(@RequestBody UserReqVO userReqVO) &#123; //调用远程服务 OrderNoReqVO vo = new OrderNoReqVO() ; vo.setReqNo(userReqVO.getReqNo()); RateLimiter limiter = RateLimiter.create(2.0) ; //批量调用 for (int i = 0 ;i&lt; 10 ; i++)&#123; double acquire = limiter.acquire(); logger.debug("获取令牌成功!,消耗=" + acquire); BaseResponse&lt;OrderNoResVO&gt; orderNo = orderServiceClient.getOrderNo(vo); logger.debug("远程返回:"+JSON.toJSONString(orderNo)); &#125; UserRes userRes = new UserRes() ; userRes.setUserId(123); userRes.setUserName("张三"); userRes.setReqNo(userReqVO.getReqNo()); userRes.setCode(StatusEnum.SUCCESS.getCode()); userRes.setMessage("成功"); return userRes ;&#125; 详见此。 调用结果如下: 代码可以看出以每秒向桶中放入两个令牌，请求一次消耗一个令牌。所以每秒钟只能发送两个请求。按照图中的时间来看也确实如此(返回值是获取此令牌所消耗的时间，差不多也是每500ms一个)。 使用RateLimiter有几个值得注意的地方: 允许先消费，后付款，意思就是它可以来一个请求的时候一次性取走几个或者是剩下所有的令牌甚至多取，但是后面的请求就得为上一次请求买单，它需要等待桶中的令牌补齐之后才能继续获取令牌。 总结针对于单个应用的限流 RateLimiter 够用了，如果是分布式环境可以借助 Redis 来完成。 最近也怼了一个，可以参考。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
        <tag>RateLimiter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(三)自定义Starter-SpringBoot重构去重插件]]></title>
    <url>%2F2017%2F08%2F01%2Fsbc3%2F</url>
    <content type="text"><![CDATA[前言之前看过SSM(十四) 基于annotation的http防重插件的朋友应该记得我后文说过之后要用SpringBoot来进行重构。 这次采用自定义的starter的方式来进行重构。 关于starter(起步依赖)其实在第一次使用SpringBoot的时候就已经用到了，比如其中的: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 我们只需要引入这一个依赖SpringBoot就会把相关的依赖都加入进来，自己也不需要再去担心各个版本之间的兼容问题(具体使用哪个版本由使用的spring-boot-starter-parent版本决定)，这些SpringBoot都已经帮我们做好了。 Spring自动化配置先加入需要的一些依赖: 123456789101112131415161718192021222324252627282930&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--aop相关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--redis相关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--配置相关--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;!--通用依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;sbc-common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 创建了CheckReqConf配置类用于在应用启动的时候自动配置。当然前提还得在resources目录下创建META-INF/spring.factories配置文件用于指向当前类，才能在应用启动时进行自动配置。 spring.factories: 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\com.crossoverJie.request.check.conf.CheckReqConf 使用条件化配置试着考虑下如下情况: 因为该插件是使用redis来存储请求信息的，外部就依赖了redis。如果使用了该插件的应用没有配置或者忘了配置redis的一些相关连接，那么在应用使用过程中肯定会出现写入redis异常。 如果异常没有控制好的话还有可能影响项目的正常运行。 那么怎么解决这个情况呢，可以使用Spring4.0新增的条件化配置来解决。 解决思路是:可以简单的通过判断应用中是否配置有spring.redis.hostredis连接，如果没有我们的这个配置就会被忽略掉。 实现代码: 1234567891011import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Conditional;import org.springframework.context.annotation.Configuration;@Configuration@ComponentScan("com.crossoverJie.request.check.interceptor,com.crossoverJie.request.check.properties")//是否有redis配置的校验，如果没有配置则不会加载改配置，也就是当前插件并不会生效@Conditional(CheckReqCondition.class)public class CheckReqConf &#123;&#125; 具体校验的代码CheckReqCondition: 12345678910111213141516171819public class CheckReqCondition implements Condition &#123; private static Logger logger = LoggerFactory.getLogger(CheckReqCondition.class); @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata annotatedTypeMetadata) &#123; //如果没有加入redis配置的就返回false String property = context.getEnvironment().getProperty("spring.redis.host"); if (StringUtils.isEmpty(property))&#123; logger.warn("Need to configure redis!"); return false ; &#125;else &#123; return true; &#125; &#125;&#125; 只需要实现org.springframework.context.annotation.Condition并重写matches()方法,即可实现个人逻辑。 可以在使用了该依赖的配置文件中配置或者是不配置spring.redis.host这个配置,来看我们的切面类(ReqNoDrcAspect)中53行的日志是否有打印来判断是否生效。 这样只有在存在该key的情况下才会应用这个配置。 当然最好的做法是直接尝试读、写redis,看是否连接畅通来进行判断。 AOP切面最核心的其实就是这个切面类，里边主要逻辑和之前是一模一样的就不在多说,只是这里应用到了自定义配置。 切面类ReqNoDrcAspect: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//切面注解@Aspect//扫描@Component//开启cglib代理@EnableAspectJAutoProxy(proxyTargetClass = true)public class ReqNoDrcAspect &#123; private static Logger logger = LoggerFactory.getLogger(ReqNoDrcAspect.class); @Autowired private CheckReqProperties properties ; private String prefixReq ; private long day ; @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; @PostConstruct public void init() throws Exception &#123; prefixReq = properties.getRedisKey() == null ? "reqNo" : properties.getRedisKey() ; day = properties.getRedisTimeout() == null ? 1L : properties.getRedisTimeout() ; logger.info("sbc-request-check init......"); logger.info(String.format("redis prefix is [%s],timeout is [%s]", prefixReq, day)); &#125; /** * 切面该注解 */ @Pointcut("@annotation(com.crossoverJie.request.check.anotation.CheckReqNo)") public void checkRepeat()&#123; &#125; @Before("checkRepeat()") public void before(JoinPoint joinPoint) throws Exception &#123; BaseRequest request = getBaseRequest(joinPoint); if(request != null)&#123; final String reqNo = request.getReqNo(); if(StringUtil.isEmpty(reqNo))&#123; throw new SBCException(StatusEnum.REPEAT_REQUEST); &#125;else&#123; try &#123; String tempReqNo = redisTemplate.opsForValue().get(prefixReq +reqNo); logger.debug("tempReqNo=" + tempReqNo); if((StringUtil.isEmpty(tempReqNo)))&#123; redisTemplate.opsForValue().set(prefixReq + reqNo, reqNo, day, TimeUnit.DAYS); &#125;else&#123; throw new SBCException("请求号重复,"+ prefixReq +"=" + reqNo); &#125; &#125; catch (RedisConnectionFailureException e)&#123; logger.error("redis操作异常",e); throw new SBCException("need redisService") ; &#125; &#125; &#125; &#125; public static BaseRequest getBaseRequest(JoinPoint joinPoint) throws Exception &#123; BaseRequest returnRequest = null; Object[] arguments = joinPoint.getArgs(); if(arguments != null &amp;&amp; arguments.length &gt; 0)&#123; returnRequest = (BaseRequest) arguments[0]; &#125; return returnRequest; &#125;&#125; 这里我们的写入rediskey的前缀和过期时间改为从CheckReqProperties类中读取: 12345678910111213141516171819202122232425262728293031@Component//定义配置前缀@ConfigurationProperties(prefix = "sbc.request.check")public class CheckReqProperties &#123; private String redisKey ;//写入redis中的前缀 private Long redisTimeout ;//redis的过期时间 默认是天 public String getRedisKey() &#123; return redisKey; &#125; public void setRedisKey(String redisKey) &#123; this.redisKey = redisKey; &#125; public Long getRedisTimeout() &#123; return redisTimeout; &#125; public void setRedisTimeout(Long redisTimeout) &#123; this.redisTimeout = redisTimeout; &#125; @Override public String toString() &#123; return "CheckReqProperties&#123;" + "redisKey='" + redisKey + '\'' + ", redisTimeout=" + redisTimeout + '&#125;'; &#125;&#125; 这样如果是需要很多配置的情况下就可以将内容封装到该对象中，方便维护和读取。 使用的时候只需要在自己应用的application.properties中加入 123# 去重配置sbc.request.check.redis-key = reqsbc.request.check.redis-timeout= 2 应用插件使用方法也和之前差不多(在sbc-order应用)： 加入依赖： 123456&lt;!--防重插件--&gt;&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie.request.check&lt;/groupId&gt; &lt;artifactId&gt;request-check&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 在接口上加上注解: 12345678910111213141516171819202122@RestController@Api(value = "orderApi", description = "订单API", tags = &#123;"订单服务"&#125;)public class OrderController implements OrderService&#123; private final static Logger logger = LoggerFactory.getLogger(OrderController.class); @Override @CheckReqNo public BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) &#123; BaseResponse&lt;OrderNoResVO&gt; res = new BaseResponse(); res.setReqNo(orderNoReq.getReqNo()); if (null == orderNoReq.getAppId())&#123; throw new SBCException(StatusEnum.FAIL); &#125; OrderNoResVO orderNoRes = new OrderNoResVO() ; orderNoRes.setOrderId(DateUtil.getLongTime()); res.setCode(StatusEnum.SUCCESS.getCode()); res.setMessage(StatusEnum.SUCCESS.getMessage()); res.setDataBody(orderNoRes); return res ; &#125;&#125; 使用效果如下: 总结注意一点是spring.factories的路径不要搞错了,之前就是因为路径写错了，导致自动配置没有加载，AOP也就没有生效，排查了好久。。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>重构</tag>
        <tag>AOP</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(二)高可用Eureka+声明式服务调用]]></title>
    <url>%2F2017%2F07%2F19%2Fsbc2%2F</url>
    <content type="text"><![CDATA[前言 上一篇简单入门了SpringBoot+SpringCloud 构建微服务。但只能算是一个demo级别的应用。这次会按照实际生产要求来搭建这套服务。 Swagger应用上次提到我们调用自己的http接口的时候采用的是PostMan来模拟请求，这个在平时调试时自然没有什么问题，但当我们需要和前端联调开发的时候效率就比较低了。 通常来说现在前后端分离的项目一般都是后端接口先行。 后端大大们先把接口定义好(入参和出参),前端大大们来确定是否满足要求，可以了之后后端才开始着手写实现，这样整体效率要高上许多。 但也会带来一个问题:在接口定义阶段频繁变更接口定义而没有一个文档或类似的东西来记录，那么双方的沟通加上前端的调试都是比较困难的。 基于这个需求网上有各种解决方案，比如阿里的rap就是一个不错的例子。 但是springCould为我们在提供了一种在开发springCloud项目下更方便的工具swagger。 实际效果如下: 配置swagger以sbc-order为例我将项目分为了三个模块: 123456789├── order // Order服务实现 │ ├── src/main├── order-api // 对内API│ ├── src/main├── order-client // 对外的clientAPI│ ├── src/main├── .gitignore ├── LICENSE ├── README.md 因为实现都写在order模块中，所以只需要在该模块中配置即可。 首先需要加入依赖，由于我在order模块中依赖了: 12345&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;order-api&lt;/artifactId&gt; &lt;version&gt;$&#123;target.version&#125;&lt;/version&gt;&lt;/dependency&gt; order-api又依赖了： 12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; 接着需要配置一个SwaggerConfig 12345678910111213141516171819202122232425262728@Configuration@EnableSwagger2/** 是否打开swagger **/@ConditionalOnExpression(&quot;&apos;$&#123;swagger.enable&#125;&apos; == &apos;true&apos;&quot;)public class SwaggerConfig &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(&quot;com.crossoverJie.sbcorder.controller&quot;)) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(&quot;sbc order api&quot;) .description(&quot;sbc order api&quot;) .termsOfServiceUrl(&quot;http://crossoverJie.top&quot;) .contact(&quot;crossoverJie&quot;) .version(&quot;1.0.0&quot;) .build(); &#125; &#125; 其实就是配置swagger的一些基本信息。之后启动项目，在地址栏输入http://ip:port/swagger-ui.html#/即可进入。可以看到如上图所示的接口列表,点击如下图所示的参数例子即可进行接口调用。 自定义开关Swagger swagger的便利能给我们带来很多好处，但稍有不慎也可能出现问题。 比如如果在生产环境还能通过IP访问swagger的话那后果可是不堪设想的。所以我们需要灵活控制swagger的开关。 这点可以利用spring的条件化配置(条件化配置可以配置存在于应用中,一旦满足一些特定的条件时就取消这些配置)来实现这一功能: 1@ConditionalOnExpression("'$&#123;swagger.enable&#125;' == 'true'") 该注解的意思是给定的SpEL表达式计算结果为true时才会创建swagger的bean。 swagger.enable这个配置则是配置在application.properties中: 12# 是否打开swaggerswagger.enable = true 这样当我们在生产环境时只需要将该配置改为false即可。 ps:更多spring条件化配置: 123456789101112@ConditionalOnBean //配置了某个特定Bean@ConditionalOnMissingBean //没有配置特定的Bean@ConditionalOnClass //Classpath里有指定的类@ConditionalOnMissingClass //Classpath里缺少指定的类@ConditionalOnExpression //给定的Spring Expression Language(SpEL)表达式计算结果为true@ConditionalOnJava //Java的版本匹配特定值或者一个范围值@ConditionalOnJndi //参数中给定的JNDI位置必须存在一个，如果没有给参数，则要有JNDI InitialContext@ConditionalOnProperty //指定的配置属性要有一个明确的值@ConditionalOnResource //Classpath里有指定的资源@ConditionalOnWebApplication //这是一个Web应用程序@ConditionalOnNotWebApplication //这不是一个Web应用程序(参考SpringBoot实战) 高可用Eureka在上一篇中是用Eureka来做了服务注册中心，所有的生产者都往它注册服务，消费者又通过它来获取服务。 但是之前讲到的都是单节点，这在生产环境风险巨大，我们必须做到注册中心的高可用，搭建Eureka集群。 这里简单起见就搭建两个Eureka,思路则是这两个Eureka都把自己当成应用向对方注册，这样就可以构成一个高可用的服务注册中心。 在实际生产环节中会是每个注册中心一台服务器，为了演示起见，我就在本地启动两个注册中心，但是端口不一样。 首先需要在本地配置一个host: 1127.0.0.1 node1 node2 这样不论是访问node1还是node2都可以在本机调用的到(当然不配置host也可以，只是需要通过IP来访问，这样看起来不是那么明显)。 并给sbc-service新增了两个配置文件: application-node1.properties: 12345678910spring.application.name=sbc-serviceserver.port=8888eureka.instance.hostname=node1## 不向注册中心注册自己#eureka.client.register-with-eureka=false### 不需要检索服务#eureka.client.fetch-registry=falseeureka.client.serviceUrl.defaultZone=http://node2:9999/eureka/ application-node2.properties: 12345678910spring.application.name=sbc-serviceserver.port=9999eureka.instance.hostname=node2## 不向注册中心注册自己#eureka.client.register-with-eureka=false### 不需要检索服务#eureka.client.fetch-registry=falseeureka.client.serviceUrl.defaultZone=http://node1:8888/eureka/ 其中最重要的就是: 12eureka.client.serviceUrl.defaultZone=http://node2:9999/eureka/eureka.client.serviceUrl.defaultZone=http://node1:8888/eureka/ 两个应用互相注册。 启动的时候我们按照:java -jar sbc-service-1.0.0-SNAPSHOT.jar --spring.profiles.active=node1启动，就会按照传入的node1或者是node2去读取application-node1.properties,application-node2.properties这两个配置文件(配置文件必须按照application-{name}.properties的方式命名)。 分别启动两个注册中心可以看到以下: 可以看到两个注册中心以及互相注册了。在服务注册的时候只需要将两个地址都加上即可:eureka.client.serviceUrl.defaultZone=http://node1:8888/eureka/,http://node2:9999/eureka/ 在服务调用的时候可以尝试关闭其中一个，正常情况下依然是可以调用到服务的。 Feign声明式调用接下来谈谈服务调用，上次提到可以用ribbon来进行服务调用，但是明显很不方便，不如像之前rpc调用那样简单直接。 为此这次使用Feign来进行声明式调用，就像调用一个普通方法那样简单。 order-client片头说到我将应用分成了三个模块order、order-api、order-client，其中的client模块就是关键。 来看看其中的内容,只有一个接口: 12345678910@RequestMapping(value="/orderService")@FeignClient(name="sbc-order")@RibbonClientpublic interface OrderServiceClient extends OrderService&#123; @ApiOperation("获取订单号") @RequestMapping(value = "/getOrderNo", method = RequestMethod.POST) BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) ;&#125; @FeignClient这个注解要注意下，其中的name的是自己应用的应用名称，在application.properties中的spring.application.name配置。 其中继承了一个OrderService在order-api模块中，来看看order-api中的内容。 order-api其中也只有一个接口: 12345678910@RestController@Api("订单服务API")@RequestMapping(value = "/orderService")@Validatedpublic interface OrderService &#123; @ApiOperation("获取订单号") @RequestMapping(value = "/getOrderNo", method = RequestMethod.POST) BaseResponse&lt;OrderNoResVO&gt; getOrderNo(@RequestBody OrderNoReqVO orderNoReq) ;&#125; 这个接口有两个目的。 给真正的controller来进行实现。 给client接口进行继承。 类关系如下: 注解这些都没什么好说的，一看就懂。 orderorder则是具体接口实现的模块，就和平时写controller一样。来看看如何使用client进行声明式调用: 这次看看sbc-user这个项目，在里边调用了sbc-order的服务。其中的user模块依赖了order-client: 1234&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;order-client&lt;/artifactId&gt;&lt;/dependency&gt; 具体调用: 12345678910111213141516171819202122@Autowiredprivate OrderServiceClient orderServiceClient ;@Overridepublic BaseResponse&lt;UserResVO&gt; getUserByFeign(@RequestBody UserReqVO userReq) &#123; //调用远程服务 OrderNoReqVO vo = new OrderNoReqVO() ; vo.setReqNo(userReq.getReqNo()); BaseResponse&lt;OrderNoResVO&gt; orderNo = orderServiceClient.getOrderNo(vo); logger.info("远程返回:"+JSON.toJSONString(orderNo)); UserRes userRes = new UserRes() ; userRes.setUserId(123); userRes.setUserName("张三"); userRes.setReqNo(userReq.getReqNo()); userRes.setCode(StatusEnum.SUCCESS.getCode()); userRes.setMessage("成功"); return userRes ;&#125; 可以看到只需要将order-client包中的Order服务注入进来即可。 在sbc-client的swagger中进行调用: 由于我并没传appId所以order服务返回的错误。 总结 当一个应用需要对外暴露接口时着需要按照以上方式提供一个client包更消费者使用。 其实应用本身也是需要做高可用的，和Eureka高可用一样，再不同的服务器上再启一个或多个服务并注册到Eureka集群中即可。 后续还会继续谈到zuul网关，容错，断路器等内容，欢迎拍砖讨论。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
        <tag>swagger</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十五) 乐观锁与悲观锁的实际应用]]></title>
    <url>%2F2017%2F07%2F09%2FSSM15%2F</url>
    <content type="text"><![CDATA[前言随着互联网的兴起，现在三高(高可用、高性能、高并发)项目是越来越流行。 本次来谈谈高并发。首先假设一个业务场景：数据库中有一条数据，需要获取到当前的值，在当前值的基础上+10，然后再更新回去。如果此时有两个线程同时并发处理，第一个线程拿到数据是10，+10=20更新回去。第二个线程原本是要在第一个线程的基础上再+20=40,结果由于并发访问取到更新前的数据为10，+20=30。 这就是典型的存在中间状态，导致数据不正确。来看以下的例子： 并发所带来的问题和上文提到的类似，这里有一张price表，表结构如下： 1234567CREATE TABLE `price` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `total` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;总值&apos;, `front` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费前&apos;, `end` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费后&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1268 DEFAULT CHARSET=utf8 我这里写了一个单测：就一个主线程，循环100次，每次把front的值减去10，再写入一次流水记录，正常情况是写入的每条记录都会每次减去10。 12345678910111213141516171819/** * 单线程消费 */@Testpublic void singleCounsumerTest1()&#123; for (int i=0 ;i&lt;100 ;i++)&#123; Price price = priceMapper.selectByPrimaryKey(1); int ron = 10 ; price.setFront(price.getFront().subtract(new BigDecimal(ron))); price.setEnd(price.getEnd().add(new BigDecimal(ron))); price.setTotal(price.getFront().add(price.getEnd())); priceMapper.updateByPrimaryKey(price) ; price.setId(null); priceMapper.insertSelective(price) ; &#125;&#125; 执行结果如下： 可以看到确实是每次都递减10。 但是如果是多线程的情况下会是如何呢： 我这里新建了一个PriceController 1234567891011121314151617181920212223242526272829303132333435363738394041424344 /** * 线程池 无锁 * @param redisContentReq * @return */@RequestMapping(value = "/threadPrice",method = RequestMethod.POST)@ResponseBodypublic BaseResponse&lt;NULLBody&gt; threadPrice(@RequestBody RedisContentReq redisContentReq)&#123; BaseResponse&lt;NULLBody&gt; response = new BaseResponse&lt;NULLBody&gt;() ; try &#123; for (int i=0 ;i&lt;10 ;i++)&#123; Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123; Price price = priceMapper.selectByPrimaryKey(1); int ron = 10 ; price.setFront(price.getFront().subtract(new BigDecimal(ron))); price.setEnd(price.getEnd().add(new BigDecimal(ron))); priceMapper.updateByPrimaryKey(price) ; price.setId(null); priceMapper.insertSelective(price) ; &#125; &#125;); config.submit(t); &#125; response.setReqNo(redisContentReq.getReqNo()); response.setCode(StatusEnum.SUCCESS.getCode()); response.setMessage(StatusEnum.SUCCESS.getMessage()); &#125;catch (Exception e)&#123; logger.error("system error",e); response.setReqNo(response.getReqNo()); response.setCode(StatusEnum.FAIL.getCode()); response.setMessage(StatusEnum.FAIL.getMessage()); &#125; return response ;&#125; 其中为了节省资源使用了一个线程池: 1234567891011121314151617@Componentpublic class ThreadPoolConfig &#123; private static final int MAX_SIZE = 10 ; private static final int CORE_SIZE = 5; private static final int SECOND = 1000; private ThreadPoolExecutor executor ; public ThreadPoolConfig()&#123; executor = new ThreadPoolExecutor(CORE_SIZE,MAX_SIZE,SECOND, TimeUnit.MICROSECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()) ; &#125; public void submit(Thread thread)&#123; executor.submit(thread) ; &#125;&#125; 关于线程池的使用今后会仔细探讨。这里就简单理解为有10个线程并发去处理上面单线程的逻辑，来看看结果怎么样： 会看到明显的数据错误，导致错误的原因自然就是有线程读取到了中间状态进行了错误的更新。 进而有了以下两种解决方案：悲观锁和乐观锁。 悲观锁简单理解下悲观锁：当一个事务锁定了一些数据之后，只有当当前锁提交了事务，释放了锁，其他事务才能获得锁并执行操作。 使用方式如下：首先要关闭MySQL的自动提交：set autocommit = 0; 123456bigen --开启事务select id, total, front, end from price where id=1 for update insert into price values(?,?,?,?,?)commit --提交事务 这里使用select for update的方式利用数据库开启了悲观锁，锁定了id=1的这条数据(注意:这里除非是使用了索引会启用行级锁，不然是会使用表锁，将整张表都锁住。)。之后使用commit提交事务并释放锁，这样下一个线程过来拿到的就是正确的数据。 悲观锁一般是用于并发不是很高，并且不允许脏读等情况。但是对数据库资源消耗较大。 乐观锁那么有没有性能好，支持的并发也更多的方式呢？ 那就是乐观锁。 乐观锁是首先假设数据冲突很少，只有在数据提交修改的时候才进行校验，如果冲突了则不会进行更新。 通常的实现方式增加一个version字段，为每一条数据加上版本。每次更新的时候version+1，并且更新时候带上版本号。实现方式如下： 新建了一张price_version表： 12345678CREATE TABLE `price_version` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `total` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;总值&apos;, `front` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费前&apos;, `end` decimal(12,2) DEFAULT &apos;0.00&apos; COMMENT &apos;消费后&apos;, `version` int(11) DEFAULT &apos;0&apos; COMMENT &apos;并发版本控制&apos;, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1268 DEFAULT CHARSET=utf8 更新数据的SQL： 1234567&lt;update id="updateByVersion" parameterType="com.crossoverJie.pojo.PriceVersion"&gt; UPDATE price_version SET front = #&#123;front,jdbcType=DECIMAL&#125;, version= version + 1 WHERE id = #&#123;id,jdbcType=INTEGER&#125; AND version = #&#123;version,jdbcType=INTEGER&#125; &lt;/update&gt; 调用方式： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 线程池，乐观锁 * @param redisContentReq * @return */@RequestMapping(value = "/threadPriceVersion",method = RequestMethod.POST)@ResponseBodypublic BaseResponse&lt;NULLBody&gt; threadPriceVersion(@RequestBody RedisContentReq redisContentReq)&#123; BaseResponse&lt;NULLBody&gt; response = new BaseResponse&lt;NULLBody&gt;() ; try &#123; for (int i=0 ;i&lt;3 ;i++)&#123; Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123; PriceVersion priceVersion = priceVersionMapper.selectByPrimaryKey(1); int ron = new Random().nextInt(20); logger.info("本次消费="+ron); priceVersion.setFront(new BigDecimal(ron)); int count = priceVersionMapper.updateByVersion(priceVersion); if (count == 0)&#123; logger.error("更新失败"); &#125;else &#123; logger.info("更新成功"); &#125; &#125; &#125;); config.submit(t); &#125; response.setReqNo(redisContentReq.getReqNo()); response.setCode(StatusEnum.SUCCESS.getCode()); response.setMessage(StatusEnum.SUCCESS.getMessage()); &#125;catch (Exception e)&#123; logger.error("system error",e); response.setReqNo(response.getReqNo()); response.setCode(StatusEnum.FAIL.getCode()); response.setMessage(StatusEnum.FAIL.getMessage()); &#125; return response ;&#125; 处理逻辑：开了三个线程生成了20以内的随机数更新到front字段。 当调用该接口时日志如下： 可以看到线程1、4、5分别生成了15，2，11三个随机数。最后线程4、5都更新失败了，只有线程1更新成功了。 查看数据库： 发现也确实是更新的15。 乐观锁在实际应用相对较多，它可以提供更好的并发访问，并且数据库开销较少，但是有可能存在脏读的情况。 总结以上两种各有优劣，大家可以根据具体的业务场景来判断具体使用哪种方式来保证数据的一致性。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>lock</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sbc(一)SpringBoot+SpringCloud初探]]></title>
    <url>%2F2017%2F06%2F15%2Fsbc1%2F</url>
    <content type="text"><![CDATA[前言 有看过我之前的SSM系列的朋友应该有一点印象是非常深刻的。 那就是需要配置的配置文件非常多，什么Spring、mybatis、redis、mq之类的配置文件非常多，并且还存在各种版本，甚至有些版本还互不兼容。其中有很多可能就是刚开始整合的时候需要配置，之后压根就不会再动了。 鉴于此，Spring又推出了又一神器SpringBoot. 它可以让我们更加快速的开发Spring应用，甚至做到了开箱即用。由于在实际开发中我们使用SpringBoot+SpringCloud进行了一段时间的持续交付，并在生产环境得到了验证，其中也有不少踩坑的地方，借此机会和大家分享交流一下。 本篇我们首先会用利用SpringBoot构建出一个简单的REST API.接着会创建另一个SpringBoot项目，基于SpringCloud部署，并在两个应用之间进行调用。 使用SpringBoot构建REST API我们可以使用Spring官方提供的初始化工具帮我们生成一个基础项目：http://start.spring.io/,如下图所示： 填入相应信息即可。由于只是要实现REST API所以这里只需要引用web依赖即可。 将生成好的项目导入IDE(我使用的是idea)中,目录结构如下; 其中的SbcUserApplication是整个应用的入口。 resource/application.properties这里是存放整个应用的配置文件。 其中的static和templates是存放静态资源以及前端模板的地方，由于我们采用了前后端分离，所以这些目录基本上用不上了。 通过运行SbcUserApplication类的main方法可以启动SpringBoot项目。 接着在PostMan中进行调用，看到以下结果表明启动成功了： 这样一看是不是要比之前用Spring+SpringMVC来整合要方便快捷很多。 创建另一个SpringBoot项目当我们的项目采用微服务构建之后自然就会被拆分成N多个独立的应用。比如上文中的sbc-user用于用户管理。这里再创建一个sbc-order用户生成订单。 为了方便之后的代码复用，我将common包中的一些枚举值、工具类单独提到sbc-common应用中了，这样有其他应用要使用这些基础类直接引入这个依赖即可。 12345&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;sbc-common&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 创建步骤和上文差不多，这里就不再赘述了。其中有一个order/getOrderNo的服务，调用结果如下： 之后会利用SpringCloud来将两个服务关联起来，并可以互相调用。 使用SpringCloud进行分布式调用搭建eureka注册中心既然是要搭建微服务那自然少不了注册中心了，之前讲的dubbo采用的是zookeeper作为注册中心，SpringCloud则采用的是Netflix Eureka来做服务的注册与发现。 新建一个项目sbc-service,目录结构如下： 核心的pom.xml 123456789101112131415161718192021222324&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Brixton.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 非常easy，只需要引入eureka的依赖即可。然后在入口类加入一个注解@EnableEurekaServer，即可将该项目作为服务注册中心： 12345678910111213141516171819package com.crossoverJie.service;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@EnableEurekaServer@SpringBootApplicationpublic class EurekaApplication &#123; private final static Logger logger = LoggerFactory.getLogger(EurekaApplication.class); public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class, args); logger.info("SpringBoot Start Success"); &#125;&#125; 接着修改配置文件application.properties: 123456789server.port=8888# 不向注册中心注册自己eureka.client.register-with-eureka=false# 不需要检索服务eureka.client.fetch-registry=falseeureka.client.serviceUrl.defaultZone=http://localhost:$&#123;server.port&#125;/eureka/ 配置一下端口以及注册中心的地址即可。然后按照正常启动springBoot项目一样启动即可。 在地址栏输入http://localhost:8888看到一下界面： 当然现在在注册中心还看不到任何一个应用，下面需要将上文的sbc-user,sbc-order注册进来。 向注册中心注册服务提供者只需要在application.properties配置文件中加上注册中心的配置： 1eureka.client.serviceUrl.defaultZone=http://localhost:8888/eureka/ 并在sbc-order的主类中加入@EnableDiscoveryClient注解即可完成注册服务。 启动注册中心以及应用，在注册中心看到一下界面则成功注册: 消费注册中心的服务服务是注册上去了，自然是需要消费了，这里就简单模拟了在调用http://localhost:8080/user/getUser这个接口的时候getUser接口会去调用order的getOrder服务。 这里会用到另一个依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 他可以帮我们做到客户端负载，具体使用如下： 加入ribbon依赖。 在主类中开启@LoadBalanced客户端负载。 创建restTemplate类的实例 12345@Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; 使用restTemplate调用远程服务: 123456789101112131415161718192021222324@Autowired private RestTemplate restTemplate; @RequestMapping(value = "/getUser",method = RequestMethod.POST) public UserRes getUser(@RequestBody UserReq userReq)&#123; OrderNoReq req = new OrderNoReq() ; req.setReqNo("1213"); //调用远程服务 ResponseEntity&lt;Object&gt; res = restTemplate.postForEntity("http://sbc-order/order/getOrderNo", req, Object.class); logger.info("res="+JSON.toJSONString(res)); logger.debug("入参="+ JSON.toJSONString(userReq)); UserRes userRes = new UserRes() ; userRes.setUserId(123); userRes.setUserName("张三"); userRes.setReqNo(userReq.getReqNo()); userRes.setCode(StatusEnum.SUCCESS.getCode()); userRes.setMessage("成功"); return userRes ; &#125; 由于我的远程接口是post,所以使用了postForEntity()方法，如果是get就换成getForEntity()即可。 注意这里是使用应用名sbc-order(配置于sbc-order的application.properties中)来进行调用的，并不是一个IP地址。 启动注册中心、两个应用。用PostMan调用getUser接口时控制台打印: 12017-06-27 00:18:04.534 INFO 63252 --- [nio-8080-exec-3] c.c.sbcuser.controller.UserController : res=&#123;&quot;body&quot;:&#123;&quot;code&quot;:&quot;4000&quot;,&quot;message&quot;:&quot;appID不能为空&quot;,&quot;reqNo&quot;:&quot;1213&quot;&#125;,&quot;headers&quot;:&#123;&quot;X-Application-Context&quot;:[&quot;sbc-order:8181&quot;],&quot;Content-Type&quot;:[&quot;application/xml;charset=UTF-8&quot;],&quot;Transfer-Encoding&quot;:[&quot;chunked&quot;],&quot;Date&quot;:[&quot;Mon, 26 Jun 2017 16:18:04 GMT&quot;]&#125;,&quot;statusCode&quot;:&quot;OK&quot;,&quot;statusCodeValue&quot;:200&#125; 由于并没有传递appId所以order服务返回了一个错误，也正说明是远程调用到了该服务。 总结 ps:这里只是简单使用了ribbon来进行服务调用，但在实际的开发中还是比较少的使用这种方式来调用远程服务，而是使用Feign进行声明式调用，可以简化客户端代码，具体使用方式请持续关注。 本次算是springBoot+springCloud的入门，还有很多东西没有讲到，之后我将会根据实际使用的一些经验继续分享SpringCloud这个新兴框架。 项目：https://github.com/crossoverJie/springboot-cloud 博客：http://crossoverjie.top。]]></content>
      <categories>
        <category>sbc</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十四) 基于annotation的http防重插件]]></title>
    <url>%2F2017%2F05%2F24%2FSSM14%2F</url>
    <content type="text"><![CDATA[前言针对于我们现在常用的RESTful API通常我们需要对请求进行唯一标识，也就是每次都要带上一个请求号,如reqNO。 对于入库这种操作数据库的请求我们一般要保证他的唯一性，一个请求号通常只能用一次，所以需要我们对这种请求加上校验机制。 该需求的实现思路是通过自定义annotation，只给需要进行校验的接口加上注解。然后通过切面使用了注解的接口将每次请求号存进Redis，每次都进行判断是否存在这个请求号即可。 来看下加上本次插件的实际效果： 自定义注解首先我们要自定义一个注解： 1234567@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface CheckReqNo &#123; String desc() default "";&#125; (ps:这里并不过多的讲解注解相关的知识)。 首先使用@interface来声明一个注解。接着利用Java为我们提供的三个元注解来定义CheckReqNo注解。 其中@Target表明这个注解被用于什么地方，使用ElementType.METHOD表明被应用到方法上，还有一些其他值可以查看java.lang.annotation.ElementType这个枚举类型。 @Retention注解表明我们的注解在什么范围内有效，这里配置的RetentionPolicy.RUNTIME表明在运行时可以通过反射来获取。 @Documented看字面意思应该也能猜到是用于生成JavaDoc文档的。 其中定义了一个desc()的方法其实并没有用到，但如果需要在使用注解的时候需要自定义一些filed(域)的需求可以按照这样的方式写到这里，通过反射都可以获取到具体的值。如：@CheckReqNo(desc = &quot;abc&quot;)就可以获取到&quot;abc&quot;的值。 切面注解按照之前的想法是在对所有使用了该注解的方法进行切面：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Aspect@Componentpublic class ReqNoDrcAspect &#123; private static Logger logger = LoggerFactory.getLogger(ReqNoDrcAspect.class); @Value("$&#123;redis.prefixReq:reqNo&#125;") private String prefixReq ; @Value("$&#123;redis.day:1&#125;") private long day ; @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; @PostConstruct public void init() throws Exception &#123; logger.info("SSM-REQUEST-CHECK init......"); &#125; @Pointcut("@annotation(com.crossoverJie.request.anotation.CheckReqNo)") public void checkRepeat()&#123; &#125; @Before("checkRepeat()") public void before(JoinPoint joinPoint) throws Exception &#123; BaseRequest request; request = getBaseRequest(joinPoint); if(request != null)&#123; final String reqNo = request.getReqNo(); if(StringUtil.isEmpty(reqNo))&#123; throw new RuntimeException("reqNo不能为空"); &#125;else&#123; try &#123; String tempReqNo = redisTemplate.opsForValue().get(prefixReq +reqNo); logger.debug("tempReqNo="+tempReqNo); if((StringUtil.isEmpty(tempReqNo)))&#123; redisTemplate.opsForValue().set(prefixReq + reqNo, reqNo, day, TimeUnit.DAYS); &#125;else&#123; throw new RuntimeException("请求号重复,reqNo="+reqNo); &#125; &#125; catch (RedisConnectionFailureException e)&#123; logger.error("redis操作异常",e); throw new RuntimeException("need redisService") ; &#125; &#125; &#125; &#125; public static BaseRequest getBaseRequest(JoinPoint joinPoint) throws Exception &#123; BaseRequest returnRequest = null; Object[] arguments = joinPoint.getArgs(); if(arguments != null &amp;&amp; arguments.length &gt; 0)&#123; returnRequest = (BaseRequest) arguments[0]; &#125; return returnRequest; &#125;&#125; 使用@Aspect来定义了一个切面。其中prefixReq,day域可以自定义缓存请求号时的key前缀以及缓存的时间。 最关键的一点是用@Pointcut(&quot;@annotation(com.crossoverJie.request.anotation.CheckReqNo)&quot;)定义了一个切入点，这样所有使用@CheckReqNo的注解都会被拦截。 接下来的逻辑就比较简单了，在每次请求之前进行拦截。 先去Redis中查看这个请求号(ps:反射获取)是否存在，如果不存在则通过并将本次的请求号缓存起来。如果存在则抛出异常。 使用注解可以在jdbc.properties配置文件中自定义前缀和缓存时间 1234#redis前缀redis.prefixReq=reqNo#redis缓存时间 默认单位为天redis.day=1 不定义也可以，会使用默认值。 由于该注解是需要加到controller层,因此我们得使用CGLIB代理。这里有一个坑，需要将开启CGLIB的配置配置到我们web.xml中的 1234567891011&lt;!-- Spring MVC servlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;/servlet&gt; 这里所定义的spring-mvc.xml文件中，不然springMVC所在的子容器是无法被父容器所加载的。 使用实例： 1234567891011121314151617181920212223@CheckReqNo@RequestMapping(value = "/createRedisContent",method = RequestMethod.POST)@ResponseBodypublic BaseResponse&lt;NULLBody&gt; createRedisContent(@RequestBody RedisContentReq redisContentReq)&#123; BaseResponse&lt;NULLBody&gt; response = new BaseResponse&lt;NULLBody&gt;() ; Rediscontent rediscontent = new Rediscontent() ; try &#123; CommonUtil.setLogValueModelToModel(redisContentReq,rediscontent); rediscontentMapper.insertSelective(rediscontent) ; response.setReqNo(redisContentReq.getReqNo()); response.setCode(StatusEnum.SUCCESS.getCode()); response.setMessage(StatusEnum.SUCCESS.getMessage()); &#125;catch (Exception e)&#123; logger.error("system error",e); response.setReqNo(response.getReqNo()); response.setCode(StatusEnum.FAIL.getCode()); response.setMessage(StatusEnum.FAIL.getMessage()); &#125; return response ;&#125; 统一异常controller1234567891011121314151617181920212223242526272829/** * * ClassName: ErrorController &lt;br/&gt; * Function: 错误异常统一处理. &lt;br/&gt; * @author crossoverJie * @version * @since JDK 1.7 */@ControllerAdvicepublic class ErrorController &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @ExceptionHandler(Exception.class) @ResponseStatus(HttpStatus.OK) @ResponseBody public Object processUnauthenticatedException(NativeWebRequest request, Exception e) &#123; logger.error("请求出现异常:", e); BaseResponse&lt;NULLBody&gt; response = new BaseResponse&lt;NULLBody&gt;(); response.setCode(StatusEnum.FAIL.getCode()); if (e instanceof RuntimeException)&#123; response.setMessage(e.getMessage()); &#125; else &#123; response.setMessage(StatusEnum.FAIL.getMessage()); &#125; return response ; &#125;&#125; 这样当controller层出现异常之后都会进入这里进行统一的返回。 总结至此整个插件的流程已经全部OK，从中可以看出Spring AOP在实际开发中的各种好处。之前的几篇文章也有应用到： 在JavaWeb应用中使用Redis 动态切换数据源 不知不觉这个小白入门的SSM系列已经更新了14篇了，在GitHub也有了500多颗星了，期间也和不少朋友有过交流、探讨，感谢大家的支持。 接下来可能不太会更新这个系列了，由于博主现在所在的项目组采用的是目前比较流行的SpringBoot+SpringCloud和Docker的方式来进行架构的，所以之后的重心肯定会移到这方面，用过SpringBoot之后相信大家肯定也回不去了。 所以之后我会继续更新SpringBoot+SpringCloud相关的文章，欢迎持续关注，持续拍砖(ps:这个插件也会用springBoot重写一遍) 插件地址：https://github.com/crossoverJie/SSM-REQUEST-CHECK.git 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
        <tag>annotation</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十三) 将dubbo暴露出HTTP服务]]></title>
    <url>%2F2017%2F05%2F07%2FSSM13%2F</url>
    <content type="text"><![CDATA[前言通常来说一个dubbo服务都是对内给内部调用的，但也有可能一个服务就是需要提供给外部使用，并且还不能有使用语言的局限性。 比较标准的做法是对外的服务我们统一提供一个openAPI，这样的调用方需要按照标准提供相应的appID以及密钥来进行验签才能使用。这样固然是比较规范和安全，但复杂度也不亚于开发一个单独的系统了。 这里所讲到的没有那么复杂，就只是把一个不需要各种权限检验的dubbo服务对外提供为HTTP服务。 调用示例: 准备工作以下是本文所涉及到的一些知识点： Spring相关知识。 Java反射相关知识。 SpringMVC相关知识。 其实思路很简单，就是利用SpringMVC提供一个HTTP接口。在该接口中通过入参进行反射找到具体的dubbo服务实现进行调用。 HttpProviderConf配置类首先需要定义一个HttpProviderConf类用于保存声明需要对外提供服务的包名，毕竟我们反射时需要用到一个类的全限定名： 12345678public class HttpProviderConf &#123; /** * 提供http访问的包 */ private List&lt;String&gt; usePackage ; //省略getter setter方法&#125; 就只有一个usePackage成员变量，用于存放需要包名。至于用List的原因是允许有多个。 请求响应入参、出参HttpRequest入参123456public class HttpRequest &#123; private String param ;//入参 private String service ;//请求service private String method ;//请求方法 //省略getter setter方法&#125; 其中param是用于存放真正调用dubbo服务时的入参，传入json在调用的时候解析成具体的参数对象。 service存放dubbo服务声明的interface API的包名。 method则是真正调用的方法名称。 HttpResponse 响应1234567891011public class HttpResponse implements Serializable&#123; private static final long serialVersionUID = -552828440320737814L; private boolean success;//成功标志 private String code;//信息码 private String description;//描述 //省略getter setter方法&#125; 这里只是封装了常用的HTTP服务的响应数据。 暴露服务controller最重要的则是controller里的实现代码了。 先贴代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155@Controller@RequestMapping("/dubboAPI")public class DubboController implements ApplicationContextAware&#123; private final static Logger logger = LoggerFactory.getLogger(DubboController.class); @Autowired private HttpProviderConf httpProviderConf; //缓存作用的map private final Map&lt;String, Class&lt;?&gt;&gt; cacheMap = new HashMap&lt;String, Class&lt;?&gt;&gt;(); protected ApplicationContext applicationContext; @ResponseBody @RequestMapping(value = "/&#123;service&#125;/&#123;method&#125;",method = RequestMethod.POST) public String api(HttpRequest httpRequest, HttpServletRequest request, @PathVariable String service, @PathVariable String method) &#123; logger.debug("ip:&#123;&#125;-httpRequest:&#123;&#125;",getIP(request), JSON.toJSONString(httpRequest)); String invoke = invoke(httpRequest, service, method); logger.debug("callback :"+invoke) ; return invoke ; &#125; private String invoke(HttpRequest httpRequest,String service,String method)&#123; httpRequest.setService(service); httpRequest.setMethod(method); HttpResponse response = new HttpResponse() ; logger.debug("input param:"+JSON.toJSONString(httpRequest)); if (!CollectionUtils.isEmpty(httpProviderConf.getUsePackage()))&#123; boolean isPac = false ; for (String pac : httpProviderConf.getUsePackage()) &#123; if (service.startsWith(pac))&#123; isPac = true ; break ; &#125; &#125; if (!isPac)&#123; //调用的是未经配置的包 logger.error("service is not correct,service="+service); response.setCode("2"); response.setSuccess(false); response.setDescription("service is not correct,service="+service); &#125; &#125; try &#123; Class&lt;?&gt; serviceCla = cacheMap.get(service); if (serviceCla == null)&#123; serviceCla = Class.forName(service) ; logger.debug("serviceCla:"+JSON.toJSONString(serviceCla)); //设置缓存 cacheMap.put(service,serviceCla) ; &#125; Method[] methods = serviceCla.getMethods(); Method targetMethod = null ; for (Method m : methods) &#123; if (m.getName().equals(method))&#123; targetMethod = m ; break ; &#125; &#125; if (method == null)&#123; logger.error("method is not correct,method="+method); response.setCode("2"); response.setSuccess(false); response.setDescription("method is not correct,method="+method); &#125; Object bean = this.applicationContext.getBean(serviceCla); Object result = null ; Class&lt;?&gt;[] parameterTypes = targetMethod.getParameterTypes(); if (parameterTypes.length == 0)&#123; //没有参数 result = targetMethod.invoke(bean); &#125;else if (parameterTypes.length == 1)&#123; Object json = JSON.parseObject(httpRequest.getParam(), parameterTypes[0]); result = targetMethod.invoke(bean,json) ; &#125;else &#123; logger.error("Can only have one parameter"); response.setSuccess(false); response.setCode("2"); response.setDescription("Can only have one parameter"); &#125; return JSON.toJSONString(result) ; &#125;catch (ClassNotFoundException e)&#123; logger.error("class not found",e); response.setSuccess(false); response.setCode("2"); response.setDescription("class not found"); &#125; catch (InvocationTargetException e) &#123; logger.error("InvocationTargetException",e); response.setSuccess(false); response.setCode("2"); response.setDescription("InvocationTargetException"); &#125; catch (IllegalAccessException e) &#123; logger.error("IllegalAccessException",e); response.setSuccess(false); response.setCode("2"); response.setDescription("IllegalAccessException"); &#125; return JSON.toJSONString(response) ; &#125; /** * 获取IP * @param request * @return */ private String getIP(HttpServletRequest request) &#123; if (request == null) return null; String s = request.getHeader("X-Forwarded-For"); if (s == null || s.length() == 0 || "unknown".equalsIgnoreCase(s)) &#123; s = request.getHeader("Proxy-Client-IP"); &#125; if (s == null || s.length() == 0 || "unknown".equalsIgnoreCase(s)) &#123; s = request.getHeader("WL-Proxy-Client-IP"); &#125; if (s == null || s.length() == 0 || "unknown".equalsIgnoreCase(s)) &#123; s = request.getHeader("HTTP_CLIENT_IP"); &#125; if (s == null || s.length() == 0 || "unknown".equalsIgnoreCase(s)) &#123; s = request.getHeader("HTTP_X_FORWARDED_FOR"); &#125; if (s == null || s.length() == 0 || "unknown".equalsIgnoreCase(s)) &#123; s = request.getRemoteAddr(); &#125; if ("127.0.0.1".equals(s) || "0:0:0:0:0:0:0:1".equals(s)) try &#123; s = InetAddress.getLocalHost().getHostAddress(); &#125; catch (UnknownHostException unknownhostexception) &#123; return ""; &#125; return s; &#125; public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; 先一步一步的看： 首先是定义了一个DubboController,并使用了SpringMVC的注解对外暴露HTTP服务。 实现了org.springframework.context.ApplicationContextAware类，实现了setApplicationContext()方法用于初始化Spring上下文对象，在之后可以获取到容器里的相应对象。 核心的invoke()方法。 调用时：http://127.0.0.1:8080/SSM-SERVICE/dubboAPI/com.crossoverJie.api.UserInfoApi/getUserInfo。 具体如上文的调用实例。先将com.crossoverJie.api.UserInfoApi、getUserInfo赋值到httpRequest入参中。 判断传入的包是否是对外提供的。如下配置：1234567891011&lt;!--dubbo服务暴露为http服务--&gt;&lt;bean class="com.crossoverJie.dubbo.http.conf.HttpProviderConf"&gt; &lt;property name="usePackage"&gt; &lt;list&gt; &lt;!--需要暴露服务的接口包名，可多个--&gt; &lt;value&gt;com.crossoverJie.api&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!--扫描暴露包--&gt;&lt;context:component-scan base-package="com.crossoverJie.dubbo.http"/&gt; 其中的com.crossoverJie.api就是自己需要暴露的包名，可以多个。 接着在缓存map中取出反射获取到的接口类类型，如果获取不到则通过反射获取，并将值设置到缓存map中，这样不用每次都反射获取，可以节省系统开销(反射很耗系统资源)。 接着也是判断该接口中是否有传入的getUserInfo方法。 取出该方法的参数列表，如果没有参数则直接调用。 如果有参数，判断个数。这里最多只运行一个参数。也就是说在真正的dubbo调用的时候只能传递一个BO类型，具体的参数列表可以写到BO中。因为如果有多个在进行json解析的时候是无法赋值到两个参数对象中去的。 之后进行调用，将调用返回的数据进行返回即可。 总结通常来说这样提供的HTTP接口再实际中用的不多，但是很方便调试。 比如写了一个dubbo的查询接口，在测试环境或者是预发布环境中就可以直接通过HTTP请求的方式进行简单的测试，或者就是查询数据。比在Java中写单测来测试或查询快的很多。 安装1git clone https://github.com/crossoverJie/SSM-DUBBO-HTTP.git 1cd SSM-DUBBO-HTTP 1mvn clean 1mvn install 使用12345&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM-HTTP-PROVIDER&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; spring配置1234567891011&lt;!--dubbo服务暴露为http服务--&gt;&lt;bean class="com.crossoverJie.dubbo.http.conf.HttpProviderConf"&gt; &lt;property name="usePackage"&gt; &lt;list&gt; &lt;!--需要暴露服务的接口包名，可多个--&gt; &lt;value&gt;com.crossoverJie.api&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!--扫描暴露包--&gt;&lt;context:component-scan base-package="com.crossoverJie.dubbo.http"/&gt; 插件地址：https://github.com/crossoverJie/SSM-DUBBO-HTTP 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>dubbo</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科普-为自己的博客免费加上小绿锁]]></title>
    <url>%2F2017%2F05%2F07%2Fhttps%2F</url>
    <content type="text"><![CDATA[在如今的HTTPS大当其道的情况下自己的博客要是还没有用上。作为互联网的螺丝钉(码农)岂不是很没面子。 使用CLOUDFLARE这里使用CLOUDFLARE来提供HTTPS服务。 在其官网进行注册，按照提示添加好自己的域名即可。 之后需要在自己域名的提供商处修改DNS服务器，我是在万网购买的修改后如下图：其中的DNS服务器地址由CLOUDFLARE是提供的。修改完成之后通常需要等待一段时间才能生效。 接着在CLOUDFLARE配置DNS解析：点击CLOUDFLARE顶部的DNS进行如我上图中的配置，和之前的配置没有什么区别。 等待一段时间之后发现使用HTTP,HTTPS都能访问，但是最好还是能在访问HTTP的时候能强制跳转到HTTPS. 在CLOUDFLARE菜单栏点击page-rules之后新建一个page rule：这样整个网站的请求都会强制到请求到HTTPS. 主题配置由于我才用的是Hexo中的Next主题，其中配置了CNZZ站长统计。其中配置的CNZZ统计JS是才用的HTTP。导致在首页的时候chrome一直提示感叹号。修改站点themes/next/layout/_scripts/third-party/analytics目录下的cnzz-analytics.swig文件1234567&#123;% if theme.cnzz_siteid %&#125; &lt;div style=&quot;display: none;&quot;&gt; &lt;script src=&quot;https://s6.cnzz.com/stat.php?id=&#123;&#123; theme.cnzz_siteid &#125;&#125;&amp;web_id=&#123;&#123; theme.cnzz_siteid &#125;&#125;&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; &lt;/div&gt;&#123;% endif %&#125; 之后再进行构建的时候就会使用HTTPS. 值得注意一点的是之后文章中所使用的图片都要用HTTPS的地址了，不然chrome会提示感叹号。 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>科普</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十二) dubbo日志插件]]></title>
    <url>%2F2017%2F04%2F25%2FSSM12%2F</url>
    <content type="text"><![CDATA[前言在之前dubbo分布式框架中讲到了如何利用dubbo来搭建一个微服务项目。其中还有一些值得优化提高开发效率的地方，比如日志： 当我们一个项目拆分为N多个微服务之后，当其中一个调用另一个服务出现了问题，首先第一步自然是查看日志。 出现问题的有很多情况，如提供方自身代码的问题，调用方的姿势不对等。 自身的问题这个管不了，但是我们可以对每一个入参、返回都加上日志，这样首先就可以判断调用方是否姿势不对了。 为了规范日志已经后续的可扩展，我们可以单独提供一个插件给每个项目使用即可。 效果如下： 123456789101112132017-04-25 15:15:38,968 DEBUG [com.alibaba.dubbo.remoting.transport.DecodeHandler] - [DUBBO] Decode decodeable message com.alibaba.dubbo.rpc.protocol.dubbo.DecodeableRpcInvocation, dubbo version: 2.5.3, current host: 127.0.0.12017-04-25 15:15:39,484 DEBUG [com.crossoverJie.dubbo.filter.DubboTraceFilter] - dubbo请求数据:&#123;&quot;args&quot;:[1],&quot;interfaceName&quot;:&quot;com.crossoverJie.api.UserInfoApi&quot;,&quot;methodName&quot;:&quot;getUserInfo&quot;&#125;2017-04-25 15:15:39,484 INFO [com.crossoverJie.api.impl.UserInfoApiImpl] - 用户查询Id=12017-04-25 15:15:39,505 DEBUG [org.mybatis.spring.SqlSessionUtils] - Creating a new SqlSession2017-04-25 15:15:39,525 DEBUG [org.mybatis.spring.SqlSessionUtils] - SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@6f56b29] was not registered for synchronization because synchronization is not active2017-04-25 15:15:39,549 DEBUG [org.mybatis.spring.transaction.SpringManagedTransaction] - JDBC Connection [com.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@778b3121] will not be managed by Spring2017-04-25 15:15:39,555 DEBUG [com.crossoverJie.api.dubbo.dao.T_userDao.selectByPrimaryKey] - ==&gt; Preparing: select id, username, password,roleId from t_user where id = ? 2017-04-25 15:15:39,591 DEBUG [com.crossoverJie.api.dubbo.dao.T_userDao.selectByPrimaryKey] - ==&gt; Parameters: 1(Integer)2017-04-25 15:15:39,616 DEBUG [com.crossoverJie.api.dubbo.dao.T_userDao.selectByPrimaryKey] - &lt;== Total: 12017-04-25 15:15:39,616 DEBUG [com.alibaba.druid.pool.PreparedStatementPool] - &#123;conn-10003, pstmt-20000&#125; enter cache2017-04-25 15:15:39,617 DEBUG [org.mybatis.spring.SqlSessionUtils] - Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@6f56b29]2017-04-25 15:15:45,473 INFO [com.crossoverJie.dubbo.filter.DubboTraceFilter] - dubbo执行成功2017-04-25 15:15:45,476 DEBUG [com.crossoverJie.dubbo.filter.DubboTraceFilter] - dubbo返回数据&#123;&quot;args&quot;:[&#123;&quot;id&quot;:1,&quot;password&quot;:&quot;123456&quot;,&quot;roleId&quot;:1,&quot;userName&quot;:&quot;crossoverJie&quot;&#125;],&quot;interfaceName&quot;:&quot;com.crossoverJie.api.UserInfoApi&quot;,&quot;methodName&quot;:&quot;getUserInfo&quot;&#125; dubbo filter拓展参考官方文档，我们可以通过1234567891011## 定义实体首先定义一个实体类用于保存调用过程中的一些数据：```javapublic class FilterDesc &#123; private String interfaceName ;//接口名 private String methodName ;//方法名 private Object[] args ;//参数 //省略getter setter&#125; DubboTraceFilter具体拦截逻辑1234567891011121314151617181920212223242526272829303132333435363738@Activate(group = Constants.PROVIDER, order = -999)public class DubboTraceFilter implements Filter&#123; private static final Logger logger = LoggerFactory.getLogger(DubboTraceFilter.class); public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException &#123; try &#123; FilterDesc filterReq = new FilterDesc() ; filterReq.setInterfaceName(invocation.getInvoker().getInterface().getName()); filterReq.setMethodName(invocation.getMethodName()) ; filterReq.setArgs(invocation.getArguments()); logger.debug("dubbo请求数据:"+JSON.toJSONString(filterReq)); Result result = invoker.invoke(invocation); if (result.hasException() &amp;&amp; invoker.getInterface() != GenericService.class)&#123; logger.error("dubbo执行异常",result.getException()); &#125;else &#123; logger.info("dubbo执行成功"); FilterDesc filterRsp = new FilterDesc() ; filterRsp.setMethodName(invocation.getMethodName()); filterRsp.setInterfaceName(invocation.getInvoker().getInterface().getName()); filterRsp.setArgs(new Object[]&#123;result.getValue()&#125;); logger.debug("dubbo返回数据"+JSON.toJSONString(filterRsp)); &#125; return result ; &#125;catch (RuntimeException e)&#123; logger.error("dubbo未知异常" + RpcContext.getContext().getRemoteHost() + ". service: " + invoker.getInterface().getName() + ", method: " + invocation.getMethodName() + ", exception: " + e.getClass().getName() + ": " + e.getMessage(), e); throw e ; &#125; &#125;&#125; 逻辑非常简单，只是对调用过程、异常、成功之后打印相应的日志而已。 但是有个地方要注意一下：需要在resource目录下加上META-INF.dubbo/com.alibaba.dubbo.rpc.Filter文件。1dubboTraceFilter=com.crossoverJie.dubbo.filter.DubboTraceFilter 目录结构如下：12345678910src |-main |-java |-com |-xxx |-XxxFilter.java (实现Filter接口) |-resources |-META-INF |-dubbo |-com.alibaba.dubbo.rpc.Filter (纯文本文件，内容为：xxx=com.xxx.XxxFilter) 总结该项目已经托管到GitHub：https://github.com/crossoverJie/SSM-DUBBO-FILTER 使用方法安装1cd /SSM-DUBBO-FILTER 1mvn clean 1mvn install 使用在服务提供的项目中加上依赖，这样每次调用都会打上日志。12345&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM-TRACE-FILTER&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 在拦截器中最好不要加上一些耗时任务，需要考虑到性能问题。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十一) 基于dubbo的分布式架构]]></title>
    <url>%2F2017%2F04%2F07%2FSSM11%2F</url>
    <content type="text"><![CDATA[前言现在越来越多的互联网公司还是将自己公司的项目进行服务化，这确实是今后项目开发的一个趋势，就这个点再凭借之前的SSM项目来让第一次接触的同学能快速上手。 浅谈分布式架构分布式架构单看这个名字给人的感觉就是高逼格，但其实从历史的角度来分析一下就比较明了了。 我们拿一个电商系统来说： 单系统对于一个刚起步的创业公司项目肯定是追求越快完成功能越好，并且用户量也不大。 这时候所有的业务逻辑都是在一个项目中就可以满足。 垂直拆分-多应用当业务量和用户量发展到一定地步的时候，这时一般会将应用同时部署到几台服务器上，在用户访问的时候使用Nginx进行反向代理和简单的负载均衡。 SOA服务化当整个系统以及发展的足够大的时候，比如一个电商系统中存在有： 用户系统 订单系统 支付系统 物流系统 等系统。如果每次修改了其中一个系统就要重新发布上线的话那么耦合就太严重了。 所以需要将整个项目拆分成若干个独立的应用，可以进行独立的开发上线实现快速迭代。 如上图所示每个应用之间相互独立,每个应用可以消费其他应用暴露出来的服务，同时也对外提供服务。 从架构的层面简单的理解了，接下来看看如何编码实现。 基于dubbo的实现dubbo应该算是国内使用最多的分布式服务框架，基于此来实现对新入门的同学应该很有帮助。 其中有涉及到安装dubbo服务的注册中心zookeeper等相关知识点可以自行查看官方文档，这里就不单独讲了。 对外提供服务首先第一步需要在SSM-API模块中定义一个接口，这里就搞了一个用户查询的接口12345678910111213141516/** * Function:用户API * @author chenjiec * Date: 2017/4/4 下午9:46 * @since JDK 1.7 */public interface UserInfoApi &#123; /** * 获取用户信息 * @param userId * @return * @throws Exception */ public UserInfoRsp getUserInfo(int userId) throws Exception;&#125; 接着在SSM-SERVICE模块中进行实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import com.alibaba.dubbo.config.annotation.Service;/** * Function: * @author chenjiec * Date: 2017/4/4 下午9:51 * @since JDK 1.7 */@Servicepublic class UserInfoApiImpl implements UserInfoApi &#123; private static Logger logger = LoggerFactory.getLogger(UserInfoApiImpl.class); @Autowired private T_userService t_userService ; /** * 获取用户信息 * * @param userId * @return * @throws Exception */ @Override public UserInfoRsp getUserInfo(int userId) throws Exception &#123; logger.info("用户查询Id="+userId); //返回对象 UserInfoRsp userInfoRsp = new UserInfoRsp() ; T_user t_user = t_userService.selectByPrimaryKey(userId) ; //构建 buildUserInfoRsp(userInfoRsp,t_user) ; return userInfoRsp; &#125; /** * 构建返回 * @param userInfoRsp * @param t_user */ private void buildUserInfoRsp(UserInfoRsp userInfoRsp, T_user t_user) &#123; if (t_user == null)&#123; t_user = new T_user() ; &#125; CommonUtil.setLogValueModelToModel(t_user,userInfoRsp); &#125;&#125; 这些都是通用的代码，但值得注意的一点是这里使用的dubbo框架所提供的@service注解。作用是声明需要暴露的服务接口。 再之后就是几个dubbo相关的配置文件了。 spring-dubbo-config.xml12345678910111213&lt;dubbo:application name="ssm-service" owner="crossoverJie" organization="ssm-crossoverJie" logger="slf4j"/&gt;&lt;dubbo:registry id="dubbo-registry" address="zookeeper://192.168.0.188:2181" file="/tmp/dubbo.cachr" /&gt;&lt;dubbo:monitor protocol="registry" /&gt;&lt;dubbo:protocol name="dubbo" port="20880" /&gt;&lt;dubbo:provider timeout="15000" retries="0" delay="-1" /&gt;&lt;dubbo:consumer check="false" timeout="15000" /&gt; 其实就是配置我们服务注册的zk地址，以及服务名称、超时时间等配置。 spring-dubbo-provider.xml1&lt;dubbo:annotation package="com.crossoverJie.api.impl" /&gt; 这个配置扫描注解包的位置，一般配置到接口实现包即可。 spring-dubbo-consumer.xml这个是消费者配置项，表明我们需要依赖的其他应用。这里我们在SSM-BOOT项目中进行配置：12&lt;dubbo:reference id="userInfoApi" interface="com.crossoverJie.api.UserInfoApi" /&gt; 直接就是配置的刚才我们提供的那个用户查询的接口，这样当我们自己的内部项目需要使用到这个服务只需要依赖SSM-BOOT即可，不需要单独的再去配置consumer。这个我有在上一篇SSM(十) 项目重构-互联网项目的Maven结构中也有提到。 安装管理控制台还有一个需要做的就是安装管理控制台，这里可以看到我们有多少服务、调用情况是怎么样等作用。 这里我们可以将dubbo的官方源码下载下来，对其中的dubbo-admin模块进行打包，将生成的WAR包放到Tomcat中运行起来即可。 但是需要注意一点的是：需要将其中的dubbo.properties的zk地址修改为自己的即可。123dubbo.registry.address=zookeeper://127.0.0.1:2181dubbo.admin.root.password=rootdubbo.admin.guest.password=guest 到时候登陆的话使用root，密码也是root。使用guest，密码也是guest。 登陆界面如下图： 其中我们可以看到有两个服务以及注册上去了，但是没有消费者。 消费服务为了能够更直观的体验到消费服务，我新建了一个项目：https://github.com/crossoverJie/SSM-CONSUMER。 其中在SSM-CONSUMER-API中我也定义了一个接口：12345678910111213141516/** * Function:薪资API * @author chenjiec * Date: 2017/4/4 下午9:46 * @since JDK 1.7 */public interface SalaryInfoApi &#123; /** * 获取薪资 * @param userId * @return * @throws Exception */ public SalaryInfoRsp getSalaryInfo(int userId) throws Exception;&#125; 因为作为消费者的同时我们也对外提供了一个获取薪资的一个服务。 在SSM-CONSUMER-SERVICE模块中进行了实现：12345678910111213141516171819202122232425262728293031323334353637/** * Function: * @author chenjiec * Date: 2017/4/4 下午9:51 * @since JDK 1.7 */@Servicepublic class SalaryInfoApiImpl implements SalaryInfoApi &#123; private static Logger logger = LoggerFactory.getLogger(SalaryInfoApiImpl.class); @Autowired UserInfoApi userInfoApi ; /** * 获取用户信息 * * @param userId * @return * @throws Exception */ @Override public SalaryInfoRsp getSalaryInfo(int userId) throws Exception &#123; logger.info("薪资查询Id="+userId); //返回对象 SalaryInfoRsp salaryInfoRsp = new SalaryInfoRsp() ; //调用远程服务 UserInfoRsp userInfo = userInfoApi.getUserInfo(userId); salaryInfoRsp.setUsername(userInfo.getUserName()); return salaryInfoRsp; &#125;&#125; 其中就可以直接使用userInfoApi调用之前的个人信息服务。 再调用之前需要注意的有点是，我们只需要依赖SSM-BOOT这个模块即可进行调用，因为SSM-BOOT模块已经为我们配置了消费者之类的操作了：1234&lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM-BOOT&lt;/artifactId&gt;&lt;/dependency&gt; 还有一点是在配置SSM-BOOT中的spring-dubbo-cosumer.xml配置文件的时候，路径要和我们初始化spring配置文件时的路径一致：12345&lt;!-- Spring和mybatis的配置文件 --&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:spring/*.xml&lt;/param-value&gt;&lt;/context-param&gt; 接下来跑个单测试一下能否调通：123456789101112131415161718192021/** * Function: * * @author chenjiec * Date: 2017/4/5 下午10:41 * @since JDK 1.7 */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123; "classpath*:/spring/*.xml" &#125;)public class SalaryInfoApiImplTest &#123; @Autowired private SalaryInfoApi salaryInfoApi ; @Test public void getSalaryInfo() throws Exception &#123; SalaryInfoRsp salaryInfo = salaryInfoApi.getSalaryInfo(1); System.out.println(JSON.toJSONString(salaryInfo)); &#125;&#125; 消费者 提供者可以看到确实是调用成功了的。 接下来将消费者项目也同时启动在来观察管理控制台有什么不一样：会看到多了一个消费者所提供的服务com.crossoverjie.consumer.api.SalaryInfoApi,同时com.crossoverJie.api.UserInfoApi服务已经正常，说明已经有消费者了。 点进去便可查看具体的消费者。 总结这样一个基于dubbo的分布式服务已经讲的差不多了，在实际的开发中我们便会开发一个大系统中的某一个子应用，这样就算一个子应用出问题了也不会影响到整个大的项目。 再提一点：在实际的生产环境一般同一个服务我们都会有一个master,slave的主从服务，这样在上线的过程中不至于整个应用出现无法使用的尴尬情况。 谈到了SOA的好处，那么自然也有相对于传统模式的不方便之处： 拆分一个大的项目为成百上千的子应用就不可能手动上线了，即需要自动化的部署上线，如Jenkins。 还有一个需要做到的就是监控，需要一个单独的监控平台来帮我们实时查看各个服务的运行情况以便于及时定位和解决问题。 日志查看分析，拆分之后不可能再去每台服务器上查看日志，需要一个单独的日志查看分析工具如elk。 以上就是我理解的，如有差错欢迎指正。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(十) 项目重构-互联网项目的Maven结构]]></title>
    <url>%2F2017%2F03%2F04%2FSSM10%2F</url>
    <content type="text"><![CDATA[前言很久没有更新博客了，之前定下周更逐渐成了月更。怎么感觉像我追过的一部动漫。这个博文其实很早就想写了。之前所有的代码都是在一个模块里面进行开发，这和maven的理念是完全不相符的，最近硬是抽了一个时间来对项目的结构进行了一次重构。 先来看看这次重构之后的目录结构 为什么需要分模块 至于为什么要分模块呢？ 我们设想一个这样的场景：在现在的互联网开发中，会把一个很大的系统拆分成各个子系统用于降低他们之间的耦合度。 在一个子项目中通常都会为API、WEB、Service等模块。而且当项目够大时，这些通常都不是一个人能完成的工作，需要一个团队来各司其职。 想象一下：当之前所有的项目都在一个模块的时候，A改动了API，需要Deploy代码。而B也改动了service的代码，但并没有完全做完。所以A在提交build的时候就会报错 而且在整个项目足够大的时候，这个build的时间也是很影响效率的。 但让我将各个模块之间分开之后效果就不一样了。我修改了API我就只需要管我的就行，不需要整个项目进行build。 而且当有其他项目需要依赖我这个API的时候也只需要依赖API即可，不用整个项目都依赖过去。 各个模块的作用来看下这次我所分的模块。 ROOT这是整个项目的根节点。先看一下其中的pom.xml： 123456789101112131415161718192021222324252627282930&lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;modules&gt; &lt;module&gt;SSM-API&lt;/module&gt; &lt;module&gt;SSM-BOOT&lt;/module&gt; &lt;module&gt;SSM-SERVICE&lt;/module&gt; &lt;module&gt;SSM-WEB&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;spring.version&gt;4.1.4.RELEASE&lt;/spring.version&gt; &lt;jackson.version&gt;2.5.0&lt;/jackson.version&gt; &lt;lucene.version&gt;6.0.1&lt;/lucene.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM-API&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 我截取了其中比较重点的配置。 由于这是父节点，所以我的packag类型使用的是pom。其中分别有着四个子模块。 其中重点看下&lt;dependencyManagement&gt;这个标签。如果使用的是IDEA这个开发工具的话是可以看到如下图： 标红的有一个向下的箭头，点一下就可以进入子模块中相同的依赖。这样子模块就不需要配置具体的版本了，统一由父模块来进行维护，对之后的版本升级也带来了好处。 SSM-API接下来看下API这个模块： 通常这个模块都是用于定义外部接口的，以及改接口所依赖的一些DTO类。一般这个模块都是拿来给其他项目进行依赖，并和本项目进行数据交互的。 SSM-BOOTBOOT这个模块比较特殊。可以看到这里没有任何代码，只有一个rpc的配置文件。通常这个模块是用于给我们内部项目进行依赖的，并不像上面的API模块一样给其他部门或者是项目进行依赖的。 因为在我们的RPC调用的时候，用dubbo来举例，是需要配置所依赖的consumer。 但如果是我们自己内部调用的话我们就可以把需要调用自己的dubbo服务提供者配置在这里，这样的话我们自己调用就只需要依赖这个BOOT就可以进行调用了。 哦对了，BOOT同时还会依赖API，这样才实现了只依赖BOOT就可以调用自己内部的dubbo服务了。如下所示：12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM-API&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; SSM-SERVICESERVICE模块就比较好理解了。是处理具体业务逻辑的地方，也是对之前的API的实现。 通常这也是一个web模块，所以我的pom类型是WAR。 SSM-WEB其实WEB模块和SERVICE模块有点重合了。通常来说这个模块一般在一个对外提供http访问接口的项目中。 这里只是为了展示项目结构，所以也写在了这里。 他的作用和service差不多，都是WAR的类型。 总结这次没有实现什么特别的功能，只是对一些还没有接触过这种项目结构开发的童鞋能起到一些引导作用。 具体源码还请关注我的github。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Maven</tag>
        <tag>重构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(九) 反射的实际应用 - 构建日志对象]]></title>
    <url>%2F2017%2F01%2F19%2FSSM9%2F</url>
    <content type="text"><![CDATA[前言相信做Java的童鞋或多或少都听过反射，这也应该是Java从入门到进阶的必经之路。 但是在我们的实际开发中直接使用它们的几率貌似还是比较少的，（除了造轮子或者是Spring Mybatis这些框架外）。 所以这里介绍一个在实际开发中还是小有用处的反射实例。 传统日志有关反射的一些基本知识就不说了，可以自行Google，也可以看下反射入门。 日志相信大家都不陌生，在实际开发中一些比较敏感的数据表我们需要对它的每一次操作都记录下来。 先来看看传统的写法：1234567891011121314@Testpublic void insertSelective() throws Exception &#123; Content content = new Content() ; content.setContent("asdsf"); content.setCreatedate("2016-12-09"); contentService.insertSelective(content) ; ContentLog log = new ContentLog(); log.setContentid(content.getContentid()); log.setContent("asdsf"); log.setCreatedate("2016-12-09"); contentLogService.insertSelective(log);&#125; 非常简单，就是在保存完数据表之后再把相同的数据保存到日志表中。但是这样有以下几个问题： 如果数据表的字段较多的话，比如几百个。那么日志表的setter()方法就得写几百次，还得是都写对的情况下。 如果哪天数据表的字段发生了增加，那么每个写日志的地方都得增加该字段，提高了维护的成本。 针对以上的情况就得需要反射这个主角来解决了。 利用反射构建日志我们先来先来看下使用反射之后对代码所带来的改变：12345678910111213@Testpublic void insertSelective2() throws Exception &#123; Content content = new Content(); content.setContent("你好"); content.setContentname("1"); content.setCreatedate("2016-09-23"); contentService.insertSelective(content); ContentLog log = new ContentLog(); CommonUtil.setLogValueModelToModel(content, log); contentLogService.insertSelective(log);&#125; 同样的保存日志，不管多少字段，只需要三行代码即可解决。而且就算之后字段发生改变写日志这段代码仍然不需要改动。 其实这里最主要的一个方法就是CommonUtil.setLogValueModelToModel(content, log); 来看下是如何实现的;12345678910111213141516171819202122232425262728293031323334353637/** * 生成日志实体工具 * * @param objectFrom * @param objectTo */ public static void setLogValueModelToModel(Object objectFrom, Object objectTo) &#123; Class&lt;? extends Object&gt; clazzFrom = objectFrom.getClass(); Class&lt;? extends Object&gt; clazzTo = objectTo.getClass(); for (Method toSetMethod : clazzTo.getMethods()) &#123; String mName = toSetMethod.getName(); if (mName.startsWith("set")) &#123; //字段名 String field = mName.substring(3); //获取from 值 Object value; try &#123; if ("LogId".equals(field)) &#123; continue; &#125; Method fromGetMethod = clazzFrom.getMethod("get" + field); value = fromGetMethod.invoke(objectFrom); //设置值 toSetMethod.invoke(objectTo, value); &#125; catch (NoSuchMethodException e) &#123; throw new RuntimeException(e); &#125; catch (InvocationTargetException e) &#123; throw new RuntimeException(e); &#125; catch (IllegalAccessException e) &#123; throw new RuntimeException(e); &#125; &#125; &#125; &#125; 再使用之前我们首先需要构建好主的数据表，然后new一个日志表的对象。 在setLogValueModelToModel()方法中： 分别获得数据表和日志表对象的类类型。 获取到日志对象的所有方法集合。 遍历该集合，并拿到该方法的名称。 只取其中set开头的方法，也就是set方法。因为我们需要在循环中为日志对象的每一个字段赋值。 之后截取方法名称获得具体的字段名称。 用之前截取的字段名称，通过getMethod()方法返回数据表中的该字段的getter方法。 相当于执行了String content = content.getContent(); 执行该方法获得该字段具体的值。 利用当前循环的setter方法为日志对象的每一个字段赋值。 相当于执行了log.setContent(&quot;asdsf&quot;); 其中字段名称为LogId时跳出了当前循环，因为LogId是日志表的主键，是不需要赋值的。 当循环结束时，日志对象也就构建完成了。之后只需要保存到数据库中即可。 总结反射其实是非常耗资源的，再使用过程中还是要慎用。其中对method、field、constructor等对象做缓存也是很有必要的。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reflect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(八)动态切换数据源]]></title>
    <url>%2F2017%2F01%2F05%2FSSM8%2F</url>
    <content type="text"><![CDATA[前言 在现在开发的过程中应该大多数朋友都有遇到过切换数据源的需求。比如现在常用的数据库读写分离，或者就是有两个数据库的情况，这些都需要用到切换数据源。 手动切换数据源使用Spring的AbstractRoutingDataSource类来进行拓展多数据源。 该类就相当于一个dataSource的路由，用于根据key值来进行切换对应的dataSource。 下面简单来看下AbstractRoutingDataSource类的几段关键源码：123456789101112131415161718192021222324252627282930313233343536373839@Overridepublic Connection getConnection() throws SQLException &#123; return determineTargetDataSource().getConnection();&#125;@Overridepublic Connection getConnection(String username, String password) throws SQLException &#123; return determineTargetDataSource().getConnection(username, password);&#125;/** * Retrieve the current target DataSource. Determines the * &#123;@link #determineCurrentLookupKey() current lookup key&#125;, performs * a lookup in the &#123;@link #setTargetDataSources targetDataSources&#125; map, * falls back to the specified * &#123;@link #setDefaultTargetDataSource default target DataSource&#125; if necessary. * @see #determineCurrentLookupKey() */protected DataSource determineTargetDataSource() &#123; Assert.notNull(this.resolvedDataSources, "DataSource router not initialized"); Object lookupKey = determineCurrentLookupKey(); DataSource dataSource = this.resolvedDataSources.get(lookupKey); if (dataSource == null &amp;&amp; (this.lenientFallback || lookupKey == null)) &#123; dataSource = this.resolvedDefaultDataSource; &#125; if (dataSource == null) &#123; throw new IllegalStateException("Cannot determine target DataSource for lookup key [" + lookupKey + "]"); &#125; return dataSource;&#125;/** * Determine the current lookup key. This will typically be * implemented to check a thread-bound transaction context. * &lt;p&gt;Allows for arbitrary keys. The returned key needs * to match the stored lookup key type, as resolved by the * &#123;@link #resolveSpecifiedLookupKey&#125; method. */protected abstract Object determineCurrentLookupKey(); 可以看到其中获取链接的方法getConnection()调用的determineTargetDataSource则是关键方法。该方法用于返回我们使用的数据源。 其中呢又是determineCurrentLookupKey()方法来返回当前数据源的key值。之后通过该key值在resolvedDataSources这个map中找到对应的value(该value就是数据源)。 resolvedDataSources这个map则是在：123456789101112131415@Overridepublic void afterPropertiesSet() &#123; if (this.targetDataSources == null) &#123; throw new IllegalArgumentException("Property 'targetDataSources' is required"); &#125; this.resolvedDataSources = new HashMap&lt;Object, DataSource&gt;(this.targetDataSources.size()); for (Map.Entry&lt;Object, Object&gt; entry : this.targetDataSources.entrySet()) &#123; Object lookupKey = resolveSpecifiedLookupKey(entry.getKey()); DataSource dataSource = resolveSpecifiedDataSource(entry.getValue()); this.resolvedDataSources.put(lookupKey, dataSource); &#125; if (this.defaultTargetDataSource != null) &#123; this.resolvedDefaultDataSource = resolveSpecifiedDataSource(this.defaultTargetDataSource); &#125;&#125; 这个方法通过targetDataSources这个map来进行赋值的。targetDataSources则是我们在配置文件中进行赋值的，下面会讲到。 再来看看determineCurrentLookupKey()方法，从protected来修饰就可以看出是需要我们来进行重写的。 DynamicDataSource 和 DataSourceHolder于是我新增了DynamicDataSource类，代码如下：1234567891011121314151617package com.crossoverJie.util;import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;/** * Function: * * @author chenjiec * Date: 2017/1/2 上午12:22 * @since JDK 1.7 */public class DynamicDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; return DataSourceHolder.getDataSources(); &#125;&#125; 代码很简单，继承了AbstractRoutingDataSource类并重写了其中的determineCurrentLookupKey()方法。 这里直接用DataSourceHolder返回了一个数据源。 DataSourceHolder代码如下：1234567891011121314151617181920package com.crossoverJie.util;/** * Function:动态数据源 * * @author chenjiec * Date: 2017/1/2 上午12:19 * @since JDK 1.7 */public class DataSourceHolder &#123; private static final ThreadLocal&lt;String&gt; dataSources = new ThreadLocal&lt;String&gt;(); public static void setDataSources(String dataSource) &#123; dataSources.set(dataSource); &#125; public static String getDataSources() &#123; return dataSources.get(); &#125;&#125; 这里我使用了ThreadLocal来保存了数据源，关于ThreadLocal的知识点可以查看以下这篇文章：解密ThreadLocal 之后在Spring的配置文件中配置我们的数据源，就是上文讲到的为targetDataSources赋值：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;bean id="ssm1DataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 指定连接数据库的驱动 --&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClass&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.user&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="3" /&gt; &lt;property name="minIdle" value="3" /&gt; &lt;property name="maxActive" value="20" /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="60000" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="300000" /&gt; &lt;property name="validationQuery" value="SELECT 'x'" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="testOnBorrow" value="false" /&gt; &lt;property name="testOnReturn" value="false" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="true" /&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20" /&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name="filters" value="stat" /&gt; &lt;/bean&gt; &lt;bean id="ssm2DataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 指定连接数据库的驱动 --&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClass&#125;"/&gt; &lt;property name="url" value="$&#123;jdbc.url2&#125;"/&gt; &lt;property name="username" value="$&#123;jdbc.user2&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password2&#125;"/&gt; &lt;property name="initialSize" value="3"/&gt; &lt;property name="minIdle" value="3"/&gt; &lt;property name="maxActive" value="20"/&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="60000"/&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000"/&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="300000"/&gt; &lt;property name="validationQuery" value="SELECT 'x'"/&gt; &lt;property name="testWhileIdle" value="true"/&gt; &lt;property name="testOnBorrow" value="false"/&gt; &lt;property name="testOnReturn" value="false"/&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="true"/&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20"/&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name="filters" value="stat"/&gt; &lt;/bean&gt; &lt;bean id="dataSource" class="com.crossoverJie.util.DynamicDataSource"&gt; &lt;property name="targetDataSources"&gt; &lt;map key-type="java.lang.String"&gt; &lt;entry key="ssm1DataSource" value-ref="ssm1DataSource"/&gt; &lt;entry key="ssm2DataSource" value-ref="ssm2DataSource"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;!--默认数据源--&gt; &lt;property name="defaultTargetDataSource" ref="ssm1DataSource"/&gt; &lt;/bean&gt; 这里分别配置了两个数据源：ssm1DataSource和ssm2DataSource。之后再通过Spring的依赖注入方式将两个数据源设置进targetDataSources。 接下来的用法相比大家也应该猜到了。 就是在每次调用数据库之前我们都要先通过DataSourceHolder来设置当前的数据源。看下demo：123456@Testpublic void selectByPrimaryKey() throws Exception &#123; DataSourceHolder.setDataSources(Constants.DATASOURCE_TWO); Datasource datasource = dataSourceService.selectByPrimaryKey(7); System.out.println(JSON.toJSONString(datasource));&#125; 详见我的单测。 使用起来也是非常简单。但是不知道大家注意到没有，这样的做法槽点很多： 每次使用需要手动切换，总有一些人会忘记写(比如我)。 如果是后期需求变了，查询其他的表了还得一个个改回来。 那有没有什么方法可以自动的帮我们切换呢？ 肯定是有的，大家应该也想得到。就是利用Spring的AOP了。 自动切换数据源首先要定义好我们的切面类DataSourceExchange:1234567891011121314151617181920212223242526272829303132333435363738394041package com.crossoverJie.util;import org.aspectj.lang.JoinPoint;/** * Function:拦截器方法 * * @author chenjiec * Date: 2017/1/3 上午12:34 * @since JDK 1.7 */public class DataSourceExchange &#123; /** * * @param point */ public void before(JoinPoint point) &#123; //获取目标对象的类类型 Class&lt;?&gt; aClass = point.getTarget().getClass(); //获取包名用于区分不同数据源 String whichDataSource = aClass.getName().substring(25, aClass.getName().lastIndexOf(".")); if ("ssmone".equals(whichDataSource)) &#123; DataSourceHolder.setDataSources(Constants.DATASOURCE_ONE); &#125; else &#123; DataSourceHolder.setDataSources(Constants.DATASOURCE_TWO); &#125; &#125; /** * 执行后将数据源置为空 */ public void after() &#123; DataSourceHolder.setDataSources(null); &#125;&#125; 逻辑也比较简单，就是在执行数据库操作之前做一个切面。 通过JoinPoint对象获取目标对象。 在目标对象中获取包名来区分不同的数据源。 根据不同数据源来进行赋值。 执行完毕之后将数据源清空。 关于一些JoinPoint的API：1234567891011121314package org.aspectj.lang;import org.aspectj.lang.reflect.SourceLocation;public interface JoinPoint &#123; String toString(); //连接点所在位置的相关信息 String toShortString(); //连接点所在位置的简短相关信息 String toLongString(); //连接点所在位置的全部相关信息 Object getThis(); //返回AOP代理对象 Object getTarget(); //返回目标对象 Object[] getArgs(); //返回被通知方法参数列表 Signature getSignature(); //返回当前连接点签名 SourceLocation getSourceLocation();//返回连接点方法所在类文件中的位置 String getKind(); //连接点类型 StaticPart getStaticPart(); //返回连接点静态部分&#125; 为了通过包名来区分不同数据源，我将目录结构稍微调整了下： 将两个不同的数据源的实现类放到不同的包中，这样今后如果还需要新增其他数据源也可以灵活的切换。 看下Spring的配置：123456789101112131415161718192021&lt;bean id="dataSourceExchange" class="com.crossoverJie.util.DataSourceExchange"/&gt;&lt;!--配置切面拦截方法 --&gt;&lt;aop:config proxy-target-class="false"&gt; &lt;!--将com.crossoverJie.service包下的所有select开头的方法加入拦截 去掉select则加入所有方法 --&gt; &lt;aop:pointcut id="controllerMethodPointcut" expression=" execution(* com.crossoverJie.service.*.select*(..))"/&gt; &lt;aop:pointcut id="selectMethodPointcut" expression=" execution(* com.crossoverJie.dao..*Mapper.select*(..))"/&gt; &lt;aop:advisor advice-ref="methodCacheInterceptor" pointcut-ref="controllerMethodPointcut"/&gt; &lt;!--所有数据库操作的方法加入切面--&gt; &lt;aop:aspect ref="dataSourceExchange"&gt; &lt;aop:pointcut id="dataSourcePointcut" expression="execution(* com.crossoverJie.service.*.*(..))"/&gt; &lt;aop:before pointcut-ref="dataSourcePointcut" method="before"/&gt; &lt;aop:after pointcut-ref="dataSourcePointcut" method="after"/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 这是在我们上一篇整合redis缓存的基础上进行修改的。这样缓存和多数据源都满足了。 实际使用：12345@Testpublic void selectByPrimaryKey() throws Exception &#123; Rediscontent rediscontent = rediscontentService.selectByPrimaryKey(30); System.out.println(JSON.toJSONString(rediscontent));&#125; 这样看起来就和使用一个数据源这样简单，再也不用关心切换的问题了。 总结不过按照这样的写法是无法做到在一个事务里控制两个数据源的。这个我还在学习中，有相关经验的大牛不妨指点一下。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GoodBye 2016,Welcome 2017 | 码农砌墙记]]></title>
    <url>%2F2016%2F12%2F31%2Fannual-summary%2FGoodBye%202016%2CWelcome%202017%20%7C%20%E7%A0%81%E5%86%9C%E7%A0%8C%E5%A2%99%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[前言 早在这个月初的时候我就很想写一篇年终总结了，因为这一年相对于去年确实是经历的太多了。结果一直等到31号，在家里和媳妇吃完晚饭就马上打开电脑开码。 五月二十三-第一次跳槽 根据整年的时间线开始第一件大事自然就是换公司了。 先来点前景提要:我是14年11月份参加工作的。当时其实还没有毕业就在一家给大型企业做定制软件开发的公司实习。刚开始工作的时候什么事情都觉得非常新奇，一个在学校学的东西能运用到实际开发中并能给用户带来便利让我觉得做码农真是一件非常正确的选择啊(ps当时真是太年轻)。 后来真是造化弄人，当时负责我参与的这个项目的负责人跳槽了，我自然就成了整个公司最熟悉此项目的人了。现在不得不佩服公司老板真是心大啊，居然让一个实习生来负责这个项目。就这样我成了整个项目的负责人，从之后的开发到测试到上线到后面的维护几乎都是我一个人在负责。来一张当时上线的截图： 由于这次项目的顺利验收，公司也对我越来越信任。之后也就理所当然的又负责了几个项目。 虽然离开了但真的非常感谢公司当时对一个什么都不懂的新人给予信任。 之后随着技术的提升我接触了github、v站这样的技术论坛，逐渐的发现天外有天，我这点雕虫小技真的完全不算什么，真正机遇与挑战并存的地方是互联网。 但是此时我已经在这家公司做了一年多了，突然离开这个舒适圈来到一个陌生的环境是需要很大勇气的，或者说需要一个刺激点。 正好@嘟爷成了这个导火索。那个时候我正在搭我的个人博客正好看到了他的文章，觉得写得非常好。而且正好他也正准备转向互联网，于是我给他写了一封很长的邮件说了我心中的一些疑惑与顾虑让他给点建议。 在他的建议之下我才开始投递简历准备换一家互联网公司，感谢嘟爷给了我一个这么正确的建议。 之后我顺利的进入了一个创业公司，开始了狭义的互联网开发道路，为什么是狭义请接着往后看。 搭建个人博客 搭建博客这事也是必须的拿出来说一说的。 上面说到我看了嘟爷的博客才开始搭建自己的博客，到现在为止由于我的拖延症(加上是真的懒)一共写了20篇。不能说写的有多好，但确实是我在工作和学习中的一些总结。 让我意外的是我博客的访问量，下图是我cnzz的统计截图： 六月二十一-开源项目关于开源项目，之前我在github上面看很多优秀的开源项目，也很佩服那些作者，于是就想着自己能不能也搞一个，但是一来就造个轮子对我来说确实有点不现实。 于是我换了一个思路，由于现在我勉强也不算是新入门的菜鸟了，但我是从菜鸟过来的，深知刚开始的时候找资料的痛苦。不是资料太老就是没有体系，讲一点是一点的那种。 于是就有了现在这个项目:会不定期更新一些在实际开发中使用的技巧(ps:目前不是很忙基本上一周一更)。 没有复杂的业务流程，更不是XXXX系统，只有一些技术的分享。 从六月二十一号到现在还是有100多颗星了： 九月二十三-第二次跳槽看到这里是不是觉得我有病啊，怎么又是跳槽。。。 其实我也不想，我在上面说到开始了我的狭义互联网开发，为什么是狭义呢？ 因为做了一段时间才发现这个项目除了是部署在云服务器上和有一个微信端之外和我之前所做的项目貌似没有本质上的区别，还是一个管理系统。 这里我不评价公司的业务，但是公司的技术总监在修改问题的时候是直接在云服务器上登陆数据库删除数据，会不会觉得很奇葩。最奇葩的是删除的时候忘了写where条件导致把整张表的数据都删了，这个时候如果是你你会不会怀疑那啥。。 除此之外技术总监本人还是挺好的，不过我更觉得他适合做销售总监。 加上后来公司的业务没有发展起来，所做的系统又老是出问题(联想上文)，加上还在流传我们技术部要裁人。那我还不如自己走(现在V站逛多了突然觉得好亏)。 于是我开始了我的第二次跳槽，前后时间才间隔4个月，不得不感慨命运弄人啊。 之后我来到现在这家员工5000余人的真正的互联网公司，开始了真正意义的互联网开发。这里必须得感谢我的面试官也是我现在这个项目的leader，给了我这个互联网菜鸟机会。 不过命运总是如此的相识，明年也就是下周他就换部门了，意味着现在这个项目我又成负责人了。希望一切顺利吧。 技术相关前面说到我是九月份的时候才进入这家正真意义的互联网公司的，所以体术提升最明显也是在这段时间。 这段时间所学的起码是我在前面两家公司一年都学不到的，这里我大致列了一下： 熟悉了一个互联网产品的生命周期(关于开发、测试、预发布、灰度以及上线) 熟悉了一些关于并发、主从、缓存、调度、容器这些主流的技术。 最重要的一点，学会了不加班不舒服斯基。 身体相关不知是错觉还是什么，感觉今年看到IT行业猝死或者是出事的新闻越来越多，加上我这个今年才22岁的青年有时候也会腰疼脖子酸，导致我对于身体也是越来越担忧。 其实我从初中的时候就开始打篮球，在工作之前也是对篮球完全是痴迷的状态，每天不打球就浑身难受。刚工作的那段时间还能坚持每周末去打球，但是今年能做到一个月打一次都非常难得了。。 再此，我立个flag，明天下午出去打球，明年坚持至少每两周打一次球。 2017小目标到这里也基本上总结的差不多了，还有半个小时就是17年了。 还是定一个17年的小目标吧： 博客坚持写，至少保持两周一更。 开源项目坚持维护，争取造一个轮子出来。 坚持锻炼，我还得养家糊口。 最后希望家人朋友都平平安安。]]></content>
      <categories>
        <category>annual-summary</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SSM(七)在JavaWeb应用中使用Redis]]></title>
    <url>%2F2016%2F12%2F18%2FSSM7%2F</url>
    <content type="text"><![CDATA[前言由于最近换(mang)了(de)家(yi)公(bi)司接触了新的东西所以很久没有更新了。这次谈谈Redis，关于Redis应该很多朋友就算没有用过也听过，算是这几年最流行的NoSql之一了。Redis的应用场景非常多这里就不一一列举了，这次就以一个最简单的也最常用的 缓存数据 来举例。先来看一张效果图： 作用就是在每次查询接口的时候首先判断Redis中是否有缓存，有的话就读取，没有就查询数据库并保存到Redis中，下次再查询的话就会直接从缓存中读取了。Redis中的结果： 之后查询redis发现确实是存进来了。 Redis安装与使用首先第一步自然是安装Redis。我是在我VPS上进行安装的，操作系统是CentOS6.5。 下载Redishttps://redis.io/download，我机器上安装的是3.2.5 将下载下来的’reidis-3.2.5-tar.gz’上传到usr/local这个目录进行解压。 进入该目录。 编译安装 12makemake install 修改redis.conf配置文件。 这里我只是简单的加上密码而已。12vi redis.confrequirepass 你的密码 启动Redis 启动时候要选择我们之前修改的配置文件才能使配置文件生效。1234进入src目录cd /usr/local/redis-3.2.5/src启动服务./redis-server ../redis.conf 登陆redis1./redis-cli -a 你的密码 Spring整合Redis这里我就直接开始用Spring整合毕竟在实际使用中都是和Spring一起使用的。 修改Spring配置文件加入以下内容：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;!-- jedis 配置 --&gt; &lt;bean id="poolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxIdle" value="$&#123;redis.maxIdle&#125;"/&gt; &lt;property name="maxWaitMillis" value="$&#123;redis.maxWait&#125;"/&gt; &lt;property name="testOnBorrow" value="$&#123;redis.testOnBorrow&#125;"/&gt; &lt;/bean&gt; &lt;!-- redis服务器中心 --&gt; &lt;bean id="connectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory"&gt; &lt;property name="poolConfig" ref="poolConfig"/&gt; &lt;property name="port" value="$&#123;redis.port&#125;"/&gt; &lt;property name="hostName" value="$&#123;redis.host&#125;"/&gt; &lt;property name="password" value="$&#123;redis.password&#125;"/&gt; &lt;property name="timeout" value="$&#123;redis.timeout&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate"&gt; &lt;property name="connectionFactory" ref="connectionFactory"/&gt; &lt;property name="keySerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer"/&gt; &lt;/property&gt; &lt;property name="valueSerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.JdkSerializationRedisSerializer"/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- cache配置 --&gt; &lt;bean id="methodCacheInterceptor" class="com.crossoverJie.intercept.MethodCacheInterceptor"&gt; &lt;property name="redisUtil" ref="redisUtil"/&gt; &lt;/bean&gt; &lt;bean id="redisUtil" class="com.crossoverJie.util.RedisUtil"&gt; &lt;property name="redisTemplate" ref="redisTemplate"/&gt; &lt;/bean&gt; &lt;!--配置切面拦截方法 --&gt; &lt;aop:config proxy-target-class="true"&gt; &lt;!--将com.crossoverJie.service包下的所有select开头的方法加入拦截 去掉select则加入所有方法w --&gt; &lt;aop:pointcut id="controllerMethodPointcut" expression=" execution(* com.crossoverJie.service.*.select*(..))"/&gt; &lt;aop:pointcut id="selectMethodPointcut" expression=" execution(* com.crossoverJie.dao..*Mapper.select*(..))"/&gt; &lt;aop:advisor advice-ref="methodCacheInterceptor" pointcut-ref="controllerMethodPointcut"/&gt; &lt;/aop:config&gt;``` 更多的配置可以直接在源码里面查看：[https://github.com/crossoverJie/SSM/blob/master/src/main/resources/spring-mybatis.xml](https://github.com/crossoverJie/SSM/blob/master/src/main/resources/spring-mybatis.xml)。以上都写有注释，也都是一些简单的配置相信都能看懂。下面我会着重说下如何配置缓存的。# Spring切面使用缓存Spring的`AOP`真是是一个好东西，还不太清楚是什么的同学建议先自行`Google`下吧。在不使用切面的时候如果我们想给某个方法加入缓存的话肯定是在方法返回之前就要加入相应的逻辑判断，只有一个或几个倒还好，如果有几十上百个的话那GG了，而且维护起来也特别麻烦。&gt; 好在Spring的AOP可以帮我们解决这个问题。&gt; 这次就在我们需要加入缓存方法的切面加入这个逻辑，并且只需要一个配置即可搞定，就是上文中所提到的配置文件，如下：```xml &lt;!--配置切面拦截方法 --&gt; &lt;aop:config proxy-target-class="true"&gt; &lt;!--将com.crossoverJie.service包下的所有select开头的方法加入拦截 去掉select则加入所有方法w --&gt; &lt;aop:pointcut id="controllerMethodPointcut" expression=" execution(* com.crossoverJie.service.*.select*(..))"/&gt; &lt;aop:pointcut id="selectMethodPointcut" expression=" execution(* com.crossoverJie.dao..*Mapper.select*(..))"/&gt; &lt;aop:advisor advice-ref="methodCacheInterceptor" pointcut-ref="controllerMethodPointcut"/&gt; &lt;/aop:config&gt; 这里我们使用表达式execution(* com.crossoverJie.service.*.select*(..))来拦截service中所有以select开头的方法。这样只要我们要将加入的缓存的方法以select命名开头的话每次进入方法之前都会进入我们自定义的MethodCacheInterceptor拦截器。这里贴一下MethodCacheInterceptor中处理逻辑的核心方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; Object value = null; String targetName = invocation.getThis().getClass().getName(); String methodName = invocation.getMethod().getName(); // 不需要缓存的内容 //if (!isAddCache(StringUtil.subStrForLastDot(targetName), methodName)) &#123; if (!isAddCache(targetName, methodName)) &#123; // 执行方法返回结果 return invocation.proceed(); &#125; Object[] arguments = invocation.getArguments(); String key = getCacheKey(targetName, methodName, arguments); logger.debug("redisKey: " + key); try &#123; // 判断是否有缓存 if (redisUtil.exists(key)) &#123; return redisUtil.get(key); &#125; // 写入缓存 value = invocation.proceed(); if (value != null) &#123; final String tkey = key; final Object tvalue = value; new Thread(new Runnable() &#123; @Override public void run() &#123; if (tkey.startsWith("com.service.impl.xxxRecordManager")) &#123; redisUtil.set(tkey, tvalue, xxxRecordManagerTime); &#125; else if (tkey.startsWith("com.service.impl.xxxSetRecordManager")) &#123; redisUtil.set(tkey, tvalue, xxxSetRecordManagerTime); &#125; else &#123; redisUtil.set(tkey, tvalue, defaultCacheExpireTime); &#125; &#125; &#125;).start(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); if (value == null) &#123; return invocation.proceed(); &#125; &#125; return value; &#125; 先是查看了当前方法是否在我们自定义的方法中，如果不是的话就直接返回，不进入拦截器。 之后利用反射获取的类名、方法名、参数生成redis的key。 用key在redis中查询是否已经有缓存。 有缓存就直接返回缓存内容，不再继续查询数据库。 如果没有缓存就查询数据库并将返回信息加入到redis中。 使用PageHelper这次为了分页方便使用了比较流行的PageHelper来帮我们更简单的进行分页。首先是新增一个mybatis的配置文件mybatis-config：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;setting name="multipleResultSetsEnabled" value="true"/&gt; &lt;setting name="useColumnLabel" value="true"/&gt; &lt;setting name="useGeneratedKeys" value="false"/&gt; &lt;setting name="autoMappingBehavior" value="PARTIAL"/&gt; &lt;setting name="defaultExecutorType" value="SIMPLE"/&gt; &lt;setting name="defaultStatementTimeout" value="25"/&gt; &lt;setting name="safeRowBoundsEnabled" value="false"/&gt; &lt;setting name="mapUnderscoreToCamelCase" value="false"/&gt; &lt;setting name="localCacheScope" value="SESSION"/&gt; &lt;setting name="jdbcTypeForNull" value="OTHER"/&gt; &lt;setting name="lazyLoadTriggerMethods" value="equals,clone,hashCode,toString"/&gt; &lt;/settings&gt; &lt;plugins&gt; &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt; &lt;plugin interceptor="com.github.pagehelper.PageHelper"&gt; &lt;property name="dialect" value="mysql"/&gt; &lt;!-- 该参数默认为false --&gt; &lt;!-- 设置为true时，会将RowBounds第一个参数offset当成pageNum页码使用 --&gt; &lt;!-- 和startPage中的pageNum效果一样 --&gt; &lt;property name="offsetAsPageNum" value="true"/&gt; &lt;!-- 该参数默认为false --&gt; &lt;!-- 设置为true时，使用RowBounds分页会进行count查询 --&gt; &lt;property name="rowBoundsWithCount" value="true"/&gt; &lt;!-- 设置为true时，如果pageSize=0或者RowBounds.limit = 0就会查询出全部的结果 --&gt; &lt;!-- （相当于没有执行分页查询，但是返回结果仍然是Page类型） &lt;property name="pageSizeZero" value="true"/&gt; --&gt; &lt;!-- 3.3.0版本可用 - 分页参数合理化，默认false禁用 --&gt; &lt;!-- 启用合理化时，如果pageNum&lt;1会查询第一页，如果pageNum&gt;pages会查询最后一页 --&gt; &lt;!-- 禁用合理化时，如果pageNum&lt;1或pageNum&gt;pages会返回空数据 --&gt; &lt;property name="reasonable" value="true"/&gt; &lt;!-- 3.5.0版本可用 - 为了支持startPage(Object params)方法 --&gt; &lt;!-- 增加了一个`params`参数来配置参数映射，用于从Map或ServletRequest中取值 --&gt; &lt;!-- 可以配置pageNum,pageSize,count,pageSizeZero,reasonable,不配置映射的用默认值 --&gt; &lt;!-- 不理解该含义的前提下，不要随便复制该配置 --&gt; &lt;property name="params" value="pageNum=start;pageSize=limit;"/&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; 接着在mybatis的配置文件中引入次配置文件：1234567&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name="mapperLocations" value="classpath:mapping/*.xml"&gt;&lt;/property&gt; &lt;!--加入PageHelper--&gt; &lt;property name="configLocation" value="classpath:mybatis-config.xml"/&gt;&lt;/bean&gt; 接着在service方法中：1234567891011@Overridepublic PageEntity&lt;Rediscontent&gt; selectByPage(Integer pageNum, Integer pageSize) &#123; PageHelper.startPage(pageNum, pageSize); //因为是demo，所以这里默认没有查询条件。 List&lt;Rediscontent&gt; rediscontents = rediscontentMapper.selectByExample(new RediscontentExample()); PageEntity&lt;Rediscontent&gt; rediscontentPageEntity = new PageEntity&lt;Rediscontent&gt;(); rediscontentPageEntity.setList(rediscontents); int size = rediscontentMapper.selectByExample(new RediscontentExample()).size(); rediscontentPageEntity.setCount(size); return rediscontentPageEntity;&#125; 只需要使用PageHelper.startPage(pageNum, pageSize);方法就可以帮我们简单的分页了。这里我自定义了一个分页工具类PageEntity来更方便的帮我们在之后生成JSON数据。123456789101112131415161718192021222324252627282930package com.crossoverJie.util;import java.io.Serializable;import java.util.List;/** * 分页实体 * * @param &lt;T&gt; */public class PageEntity&lt;T&gt; implements Serializable &#123; private List&lt;T&gt; list;// 分页后的数据 private Integer count; public Integer getCount() &#123; return count; &#125; public void setCount(Integer count) &#123; this.count = count; &#125; public List&lt;T&gt; getList() &#123; return list; &#125; public void setList(List&lt;T&gt; list) &#123; this.list = list; &#125;&#125; 更多PageHelper的使用请查看一下链接：https://github.com/pagehelper/Mybatis-PageHelper 前端联调接下来看下控制层RedisController:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.crossoverJie.controller;import com.crossoverJie.pojo.Rediscontent;import com.crossoverJie.service.RediscontentService;import com.crossoverJie.util.CommonUtil;import com.crossoverJie.util.PageEntity;import com.github.pagehelper.PageHelper;import net.sf.json.JSONArray;import net.sf.json.JSONObject;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import javax.servlet.http.HttpServletResponse;@Controller@RequestMapping("/redis")public class RedisController &#123; private static Logger logger = LoggerFactory.getLogger(RedisController.class); @Autowired private RediscontentService rediscontentService; @RequestMapping("/redis_list") public void club_list(HttpServletResponse response, @RequestParam(value = "page", defaultValue = "0") int page, @RequestParam(value = "pageSize", defaultValue = "0") int pageSize) &#123; JSONObject jsonObject = new JSONObject(); JSONObject jo = new JSONObject(); try &#123; JSONArray ja = new JSONArray(); PageHelper.startPage(1, 10); PageEntity&lt;Rediscontent&gt; rediscontentPageEntity = rediscontentService.selectByPage(page, pageSize); for (Rediscontent rediscontent : rediscontentPageEntity.getList()) &#123; JSONObject jo1 = new JSONObject(); jo1.put("rediscontent", rediscontent); ja.add(jo1); &#125; jo.put("redisContents", ja); jo.put("count", rediscontentPageEntity.getCount()); jsonObject = CommonUtil.parseJson("1", "成功", jo); &#125; catch (Exception e) &#123; jsonObject = CommonUtil.parseJson("2", "操作异常", ""); logger.error(e.getMessage(), e); &#125; //构建返回 CommonUtil.responseBuildJson(response, jsonObject); &#125;&#125; 这里就不做过多解释了，就是从redis或者是service中查询出数据并返回。 前端的显示界面在https://github.com/crossoverJie/SSM/blob/master/src/main/webapp/redis/showRedis.jsp中(并不是前端，将就看)。其中核心的redis_list.js的代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485var page = 1, rows = 10;$(document).ready(function () &#123; initJqPaginator(); //加载 load_redis_list(); $(".query_but").click(function () &#123;//查询按钮 page = 1; load_redis_list(); &#125;);&#125;);//初始化分页function initJqPaginator() &#123; $.jqPaginator('#pagination', &#123; totalPages: 100, visiblePages: 10, currentPage: 1, first: '&lt;li class="prev"&gt;&lt;a href="javascript:;"&gt;首页&lt;/a&gt;&lt;/li&gt;', last: '&lt;li class="prev"&gt;&lt;a href="javascript:;"&gt;末页&lt;/a&gt;&lt;/li&gt;', prev: '&lt;li class="prev"&gt;&lt;a href="javascript:;"&gt;上一页&lt;/a&gt;&lt;/li&gt;', next: '&lt;li class="next"&gt;&lt;a href="javascript:;"&gt;下一页&lt;/a&gt;&lt;/li&gt;', page: '&lt;li class="page"&gt;&lt;a href="javascript:;"&gt;&#123;&#123;page&#125;&#125;&lt;/a&gt;&lt;/li&gt;', onPageChange: function (num, type) &#123; page = num; if (type == "change") &#123; load_redis_list(); &#125; &#125; &#125;);&#125;//列表function create_club_list(redisContens) &#123; var phone = 0; var html = '&lt;div class="product_box"&gt;' + '&lt;div class="br"&gt;' + '&lt;div class="product_link"&gt;' + '&lt;div class="product_phc"&gt;' + '&lt;img class="phc" src="" &gt;' + '&lt;/div&gt;' + '&lt;span class="product_name"&gt;' + redisContens.id + '&lt;/span&gt;&lt;/div&gt;' + '&lt;div class="product_link toto"&gt;' + redisContens.content + '&lt;/div&gt;' + '&lt;div class="product_link toto"&gt;' + '&lt;span&gt;' + "" + '&lt;/span&gt;' + '&lt;/div&gt;' + '&lt;div class="product_link toto"&gt;' + '&lt;span&gt;' + phone + '&lt;/span&gt;&lt;/div&gt;' + '&lt;div class="product_link toto"&gt;' + '&lt;span&gt;' + 0 + '&lt;/span&gt;&lt;/div&gt;' + '&lt;div class="product_link toto product_operation"&gt;' + '&lt;span onclick="edit_club(' + 0 + ')"&gt;编辑&lt;/span&gt;' + '&lt;span onclick="edit_del(' + 0 + ')"&gt;删除&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;' + '&lt;/div&gt;'; return html;&#125;//加载列表function load_redis_list() &#123; var name = $("#name").val(); $.ajax(&#123; type: 'POST', url: getPath() + '/redis/redis_list', async: false, data: &#123;name: name, page: page, pageSize: rows&#125;, datatype: 'json', success: function (data) &#123; if (data.result == 1) &#123; $(".product_length_number").html(data.data.count); var html = ""; var count = data.data.count; for (var i = 0; i &lt; data.data.redisContents.length; i++) &#123; var redisContent = data.data.redisContents[i]; html += create_club_list(redisContent.rediscontent); &#125; $(".product_content").html(html); //这里是分页的插件 $('#pagination').jqPaginator('option', &#123; totalPages: (Math.ceil(count / rows) &lt; 1 ? 1 : Math.ceil(count / rows)), currentPage: page &#125;); &#125; else &#123; alert(data.msg); &#125; &#125; &#125;); $(".product_box:even").css("background", "#e6e6e6");//隔行变色&#125; 其实就是一个简单的请求接口，并根据返回数据动态生成Dom而已。 总结以上就是一个简单的redis的应用。redis的应用场景还非常的多，比如现在我所在做的一个项目就有用来处理短信验证码的业务场景，之后有时间可以写一个demo。 项目地址：https://github.com/crossoverJie/SSM.gitGitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(六)跨域传输]]></title>
    <url>%2F2016%2F10%2F18%2FSSM6%2F</url>
    <content type="text"><![CDATA[前言不知大家在平时的开发过程中有没有遇到过跨域访问资源的问题，我不巧在上周就碰到一个这样的问题，幸运的是在公司前端同学的帮忙下解决了该问题。 什么是跨域问题？ 只要协议、域名、端口有任何一个不同，都被当作是不同的域 只要是在不同域中是无法进行通信的。 基于以上的的出发点，我们又有跨域共享资源的需求(譬如现在流行的前后端分离之后分别部署的情况)，本文所采用的解决办法是JSONP，说到JSONP就会首先想到JSON。虽然只有一字之差但意义却完全不一样，首先科普一下JSON。 JSON 其实现在JSON已经是相当流行了，只要涉及到前后端的数据交互大都都是采用的JSON(不管是web还是android和IOS)，所以我这里就举一个例子，就算是没有用过的同学也能很快明白其中的意思。 PostMan首先给大家安利一款后端开发的利器PostMan,可以用于模拟几乎所有的HTTP请求，在开发阶段调试后端接口非常有用。这是一个Chrome插件，可以直接在google商店搜索直接下载(当然前提你懂得)。之后界面就如下： 界面非常简洁，有点开发经验的童鞋应该都会使用，不太会用的直接google下就可以了比较简单。接着我们就可以利用PostMan来发起一次请求获取JSON了。这里以我SSM项目为例,也正好有暴露一个JSON的接口。地址如下:http://www.crossoverjie.top/SSM/content_load。直接在POSTMAN中的地址栏输入该地址，采用GET的方式请求，之后所返回的就是JSON格式的字符串。由于Javascript原生的就支持JSON，所以解析起来非常方便。 JSONP好了，终于可以谈谈JSONP了。之前说道JSONP是用来解决跨域问题的，那么他是如何解决的呢。经过我们开发界的前辈们发现，HTML中拥有SRC属性的标签都不受跨域的影响，比如：&lt;script&gt;、&lt;img&gt;、&lt;iframe&gt;标签。由于JS原生支持JSON的解析，于是我们采用&lt;script&gt;的方式来处理跨域解析，代码如下一看就明白。web端:1234567891011121314151617181920212223242526272829303132&lt;html lang="zh"&gt;&lt;head&gt; &lt;script type="text/javascript"&gt; $(document).ready(function()&#123; $.ajax(&#123; type: "get", async: false, url: "http://www.crossoverjie.top/SSM/jsonpInfo?callback=getUser&amp;userId=3", dataType: "jsonp", jsonp: "callback",//一般默认为:callback jsonpCallback:"getUser",//自定义的jsonp回调函数名称，默认为jQuery自动生成的随机函数名，也可以写"?"，jQuery会自动为你处理数据 success: function(json)&#123; /** * 获得服务器返回的信息。 * 可以做具体的业务处理。 */ alert('用户信息：ID： ' + json.userId + ' ，姓名： ' + json.username + '。'); &#125;, error: function()&#123; alert('fail'); &#125; &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body oncontextmenu="return false"&gt;&lt;/body&gt;&lt;/html&gt; 其中我们采用了JQuery给我封装好的函数，这样就可以自动帮我们解析了。首先我们来看下代码中的http://www.crossoverjie.top/SSM/jsonpInfo?callback=getUser&amp;userId=3这个地址返回的是什么内容，还是放到POSTMAN中执行如下：。可以看到我们所传递的callback参数带着查询的数据又原封不动的返回给我们了，这样的话即使我们不使用JQuery给我封装好的函数，我们自定义一个和callback名称一样的函数一样是可以解析其中的数据的，只是Jquery帮我们做了而已。 前端没问题了，那么后端又是如何实现的呢？也很简单，如下：1234567@RequestMapping(value = "/jsonpInfo",method = &#123; RequestMethod.GET &#125;)@ResponseBodypublic Object jsonpInfo(String callback,Integer userId) throws IOException &#123; User user = userService.getUserById(userId); JSONPObject jsonpObject = new JSONPObject(callback,user) ; return jsonpObject ;&#125; 后端采用了jackson中的JSONPObject这个类的一个构造方法，只需要将callback字段和需要转成JSON字符串的对象放进去即可。需要主要的是需要使用@ResponseBody注解才能成功返回。 总结其实网上还有其他的方法来处理跨域问题，不过我觉得这样的方式最为简单。同样JSONP也是有缺点的，比如：只支持GET方式的HTTP请求。以上代码依然在博主的SSM项目中，如有需要可以直接FORK。 项目地址：https://github.com/crossoverJie/SSM.git 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JSONP</tag>
        <tag>JSON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux（二）服务器运行环境配置]]></title>
    <url>%2F2016%2F09%2F20%2FLinux-normal2%2F</url>
    <content type="text"><![CDATA[前言Linux相信对大多数程序员来说都不陌生，毕竟在服务器端依然还是霸主地位而且丝毫没有退居二线的意思，以至于现在几乎每一个软件开发的相关人员都得或多或少的知道一些Linux的相关内容，本文将介绍如何在刚拿到一台云服务器(采用centos)来进行运行环境的搭建，包括JDK、Mysql、Tomcat以及nginx。相信对于小白来说很有必要的，也是我个人的一个记录。 该服务器的用途是用于部署JavaEE项目。部署之后的效果图如下: JDK安装由于我们之后需要部署的是JavaEE项目，所以首先第一步就是安装JDK了。 卸载自带的openJDK现在的服务器拿来之后一般都是默认给我们安装一个openJDK，首先我们需要卸载掉。 使用rpm -qa | grep java命令查看系统中是否存在有Java。 使用rpm -e --nodeps 相关应用名称来进行卸载。(相关应用名称就是上一个命令中显示出来的名称复制到这里卸载即可)。 下载并安装JDK 之后是下载ORACLE所提供的JDK，传送门根据自己系统的情况下载对应版本即可。笔者使用的是jdk-8u101-linux-x64.rpm版本。 然后使用FTP工具上传到/usr/java目录下即可，没有java目录新建一个即可。 然后使用rpm -ivh jdk-8u101-linux-x64.rpm命令进行解压安装。 profile文件配置安装完成之后使用vi /etc/profile命令编辑profile文件(注意该文件路径是指根目录下的etc文件夹不要找错了)。在该文件中加入以下内容：123export JAVA_HOME=/usr/java/jdk-8u101-linux-x64export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/bin 保存之后运行source /etc/profile使配置生效。 验证是否安装成功之后我们使用在windows平台也有的命令java -version，如果输出如图：表示安装成功。 MySQL安装卸载自带的Mysql首先第一步还是要卸载掉自带的mysql。rpm -e --nodeps mysql命令和之前一样只是把应用名称换成mysql了而已。 使用yum来安装mysql之后我们采用yum来安装mysql。这样的方式最简单便捷。yum install -y mysql-server mysql mysql-deve执行该命令直到出现Complete!提示之后表示安装成功。rpm -qi mysql-server之后使用该命令可以查看我们安装的mysql信息。 mysql相关配置使用service mysqld start来启动mysql服务(第一次会输出很多信息)，之后就不会了。然后我们可以使用chkconfig mysqld on命令将mysql设置为开机启动。输入chkconfig --list | grep mysql命令显示如下图：表示设置成功。使用mysqladmin -u root password &#39;root&#39;为root账户设置密码。 设置远程使用1234grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;123456&apos; with grant option;# root是用户名，%代表任意主机，&apos;123456&apos;指定的登录密码（这个和本地的root密码可以设置不同的，互不影响）flush privileges; # 重载系统权限exit; 验证使用使用mysql -u root -proot来登录mysql。如果出现以下界面表示设置成功。 Tomcat安装Tomcat也是我们运行JavaEE项目必备的一个中间件。 第一步需要下载linux的Tomcat，传送门。根据自己系统版本进行下载即可。之后将apache-tomcat-8.5.5.tar.gz上传到/usr/local目录中。 解压该压缩包tar -zxv -f apache-tomcat-8.5.5.tar.gz,再使用mv apache-tomcat-8.5.5 tomcat将解压的Tomcat移动到外层的Tomcat目录中。 进入/usr/local/tomcat/apache-tomcat-8.5.5/bin目录使用./startup.bat命令启动tomcat。 因为tomcat使用的默认端口是8080，linux防火墙默认是不能访问的，需要手动将其打开。使用vi + /etc/sysconfig/iptables编辑iptables(注意etc目录是根目录下的)，加入以下代码:12-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 8080 -j ACCEPT-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT 这里我们开放了8080和80端口，之后安装nginx就不用在开放了。 ps:这里用到了简单的vim命令。按i进入插入模式，输入上面两段代码。之后按esc退出插入模式。再按:wq保存关闭即可。之后使用service iptables restart命令重启防火墙即可。在浏览器输入服务器的ip+8080如果出现Tomcat的欢迎页即表明Tomcat安装成功。 nginx安装最后是安装nginx，这里我们还是使用最简单的yum的方式来进行安装。 首先使用以下几个命令安装必备的几个库： 123yum -y install pcre*yum -y install openssl*yum -y install gcc 之后安装nginx。 1234567cd /usr/local/wget http://nginx.org/download/nginx-1.4.2.tar.gztar -zxvf nginx-1.4.2.tar.gzcd nginx-1.4.2 ./configure --prefix=/usr/local/nginx --with-http_stub_status_modulemakemake install 之后就可以使用/usr/local/nginx/sbin/nginx命令来启动nginx了。输入服务器的IP地址，如果出现nginx的欢迎界面表示安装成功了。 nginx配置这里我就简单贴以下我的配置，主要就是配置一个upstream,之后在server中引用配置的那个upstream即可。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream crossover_main &#123; server 127.0.0.1:8080; &#125; server &#123; listen 80; server_name www.crossoverjie.top; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://crossover_main/examples/; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-For $remote_addr; index index.jsp; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443; # server_name localhost; # ssl on; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_timeout 5m; # ssl_protocols SSLv2 SSLv3 TLSv1; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; 之后我们在地址栏输入服务器的IP地址(如果有域名解析了服务器的IP可以直接输入域名)就会进入我们在upstream中配置的地址加上在server中的地址。根据我这里的配置最后解析地址就是http://127.0.0.1:8080/examples应该是很好理解的。最终的结果是我在片头放的那张截图一样。 总结这是一个简单的基于centOS的运行环境配置，对于小白练手应该是够了，有不清楚和错误的地方欢迎指出反正我也不会回复。 个人博客地址：http://crossoverjie.top。 GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>Linux笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>centos</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(五)基于webSocket的聊天室]]></title>
    <url>%2F2016%2F09%2F04%2FSSM5%2F</url>
    <content type="text"><![CDATA[前言不知大家在平时的需求中有没有遇到需要实时处理信息的情况，如站内信，订阅，聊天之类的。在这之前我们通常想到的方法一般都是采用轮训的方式每隔一定的时间向服务器发送请求从而获得最新的数据，但这样会浪费掉很多的资源并且也不是实时的，于是随着HTML5的推出带来了websocket可以根本的解决以上问题实现真正的实时传输。 websocket是什么？至于websocket是什么、有什么用这样的问题一Google一大把，这里我就简要的说些websocket再本次实例中的作用吧。由于在本次实例中需要实现的是一个聊天室，一个实时的聊天室。如下图： 采用websocket之后可以让前端和和后端像C/S模式一样实时通信，不再需要每次单独发送请求。由于是基于H5的所以对于老的浏览器如IE7、IE8之类的就没办法了，不过H5是大势所趋这点不用担心。 后端既然推出了websocket，作为现在主流的Java肯定也有相应的支持，所以在JavaEE7之后也对websocket做出了规范，所以本次的代码理论上是要运行在Java1.7+和Tomcat7.0+之上的。看过我前面几篇文章的朋友应该都知道本次实例也是运行在之前的SSM之上的，所以这里就不再赘述了。首先第一步需要加入websocket的依赖：123456789101112&lt;!-- https://mvnrepository.com/artifact/javax.websocket/javax.websocket-api --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.websocket&lt;/groupId&gt; &lt;artifactId&gt;javax.websocket-api&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-websocket&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt; 以上就是使用websocket所需要用到的包。spring-websocket这个主要是在之后需要在websocket的后端注入service所需要的。之后再看一下后端的核心代码MyWebSocket.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package com.crossoverJie.controller;/** * Created by Administrator on 2016/8/7. */import com.crossoverJie.pojo.Content;import com.crossoverJie.service.ContentService;import org.apache.camel.BeanInject;import org.apache.camel.EndpointInject;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import org.springframework.stereotype.Controller;import org.springframework.web.context.support.SpringBeanAutowiringSupport;import org.springframework.web.socket.server.standard.SpringConfigurator;import java.io.IOException;import java.text.SimpleDateFormat;import java.util.Date;import java.util.concurrent.CopyOnWriteArraySet;import javax.annotation.PostConstruct;import javax.websocket.OnClose;import javax.websocket.OnError;import javax.websocket.OnMessage;import javax.websocket.OnOpen;import javax.websocket.Session;import javax.websocket.server.ServerEndpoint;//该注解用来指定一个URI，客户端可以通过这个URI来连接到WebSocket。/** 类似Servlet的注解mapping。无需在web.xml中配置。 * configurator = SpringConfigurator.class是为了使该类可以通过Spring注入。 */@ServerEndpoint(value = "/websocket",configurator = SpringConfigurator.class)public class MyWebSocket &#123; //静态变量，用来记录当前在线连接数。应该把它设计成线程安全的。 private static int onlineCount = 0; public MyWebSocket() &#123; &#125; @Autowired private ContentService contentService ; //concurrent包的线程安全Set，用来存放每个客户端对应的MyWebSocket对象。 // 若要实现服务端与单一客户端通信的话，可以使用Map来存放，其中Key可以为用户标识 private static CopyOnWriteArraySet&lt;MyWebSocket&gt; webSocketSet = new CopyOnWriteArraySet&lt;MyWebSocket&gt;(); //与客户端的连接会话，需要通过它来给客户端发送数据 private Session session; /** * 连接建立成功调用的方法 * @param session 可选的参数。session为与某个客户端的连接会话，需要通过它来给客户端发送数据 */ @OnOpen public void onOpen(Session session)&#123; this.session = session; webSocketSet.add(this); //加入set中 addOnlineCount(); //在线数加1 System.out.println("有新连接加入！当前在线人数为" + getOnlineCount()); &#125; /** * 连接关闭调用的方法 */ @OnClose public void onClose()&#123; webSocketSet.remove(this); //从set中删除 subOnlineCount(); //在线数减1 System.out.println("有一连接关闭！当前在线人数为" + getOnlineCount()); &#125; /** * 收到客户端消息后调用的方法 * @param message 客户端发送过来的消息 * @param session 可选的参数 */ @OnMessage public void onMessage(String message, Session session) &#123; System.out.println("来自客户端的消息:" + message); //群发消息 for(MyWebSocket item: webSocketSet)&#123; try &#123; item.sendMessage(message); &#125; catch (IOException e) &#123; e.printStackTrace(); continue; &#125; &#125; &#125; /** * 发生错误时调用 * @param session * @param error */ @OnError public void onError(Session session, Throwable error)&#123; System.out.println("发生错误"); error.printStackTrace(); &#125; /** * 这个方法与上面几个方法不一样。没有用注解，是根据自己需要添加的方法。 * @param message * @throws IOException */ public void sendMessage(String message) throws IOException&#123; //保存数据到数据库 Content content = new Content() ; content.setContent(message); SimpleDateFormat sm = new SimpleDateFormat("yyyy-MM-dd HH:mm:dd") ; content.setCreateDate(sm.format(new Date())); contentService.insertSelective(content) ; this.session.getBasicRemote().sendText(message); //this.session.getAsyncRemote().sendText(message); &#125; public static synchronized int getOnlineCount() &#123; return onlineCount; &#125; public static synchronized void addOnlineCount() &#123; MyWebSocket.onlineCount++; &#125; public static synchronized void subOnlineCount() &#123; MyWebSocket.onlineCount--; &#125;&#125; 这就是整个websocket的后端代码。看起来也比较简单主要就是使用那几个注解。每当有一个客户端连入、关闭、发送消息都会调用各自注解的方法。这里我讲一下sendMessage()这个方法。 websocket绕坑在sendMessage()方法中我只想实现一个简单的功能，就是将每次的聊天记录都存到数据库中。看似一个简单的功能硬是花了我半天的时间。我先是按照以前的惯性思维只需要在这个类中注入service即可。但是无论怎么弄每次都注入不进来都是null。最后没办法只有google了，最后终于在神级社区StackOverFlow中找到了答案，就是前边所说的需要添加的第二个 maven依赖，然后加入@ServerEndpoint(value = &quot;/websocket&quot;,configurator = SpringConfigurator.class)这个注解即可利用Spring注入了。接着就可以做消息的保存了。 前端前端我采用了Bootstrap做的，不太清楚Bootstrap的童鞋建议先看下官方文档也比较简单。还是先贴一下代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146&lt;%@ page language="java" import="java.util.*" pageEncoding="UTF-8" %&gt;&lt;% String path = request.getContextPath(); String basePath = request.getScheme() + "://" + request.getServerName() + ":" + request.getServerPort() + path + "/";%&gt;&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;base href="&lt;%=basePath%&gt;"&gt; &lt;!-- Bootstrap --&gt; &lt;link rel="stylesheet" href="http://cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"&gt; &lt;!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries --&gt; &lt;!-- WARNING: Respond.js doesn't work if you view the page via file:// --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src="//cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/respond.js/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;script type="text/javascript" charset="utf-8" src="&lt;%=path%&gt;/ueditor/ueditor.config.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" charset="utf-8" src="&lt;%=path%&gt;/ueditor/ueditor.all.min.js"&gt; &lt;/script&gt; &lt;!--建议手动加在语言，避免在ie下有时因为加载语言失败导致编辑器加载失败--&gt; &lt;!--这里加载的语言文件会覆盖你在配置项目里添加的语言类型，比如你在配置项目里配置的是英文，这里加载的中文，那最后就是中文--&gt; &lt;script type="text/javascript" charset="utf-8" src="&lt;%=path%&gt;/ueditor/lang/zh-cn/zh-cn.js"&gt;&lt;/script&gt; &lt;title&gt;聊天室&lt;/title&gt;&lt;/head&gt;&lt;body data="/ssm"&gt;&lt;input id="text" type="text"/&gt;&lt;button onclick="send()"&gt;发送&lt;/button&gt;&lt;button onclick="closeWebSocket()"&gt;关闭连接&lt;/button&gt;&lt;div id="message"&gt;&lt;/div&gt;&lt;div class="container-fluid"&gt; &lt;div class="row"&gt; &lt;div class="col-md-12"&gt; &lt;div class="panel panel-primary"&gt; &lt;div class="panel-heading"&gt;聊天室&lt;/div&gt; &lt;div id="msg" class="panel-body"&gt; &lt;/div&gt; &lt;div class="panel-footer"&gt; 在线人数&lt;span id="onlineCount"&gt;1&lt;/span&gt;人 &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="container-fluid"&gt; &lt;div class="row"&gt; &lt;div class="col-md-12"&gt; &lt;script id="editor" type="text/plain" style="width:1024px;height:200px;"&gt;&lt;/script&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="container-fluid"&gt; &lt;div class="row"&gt; &lt;div class="col-md-12"&gt; &lt;p class="text-right"&gt; &lt;button onclick="sendMsg();" class="btn btn-success"&gt;发送&lt;/button&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;script type="text/javascript"&gt; var ue = UE.getEditor('editor'); var websocket = null; //判断当前浏览器是否支持WebSocket if ('WebSocket' in window) &#123; websocket = new WebSocket("ws://192.168.0.102:8080/ssm/websocket"); &#125; else &#123; alert("对不起！你的浏览器不支持webSocket") &#125; //连接发生错误的回调方法 websocket.onerror = function () &#123; setMessageInnerHTML("error"); &#125;; //连接成功建立的回调方法 websocket.onopen = function (event) &#123; setMessageInnerHTML("加入连接"); &#125;; //接收到消息的回调方法 websocket.onmessage = function (event) &#123; setMessageInnerHTML(event.data); &#125;; //连接关闭的回调方法 websocket.onclose = function () &#123; setMessageInnerHTML("断开连接"); &#125;; //监听窗口关闭事件，当窗口关闭时，主动去关闭websocket连接， // 防止连接还没断开就关闭窗口，server端会抛异常。 window.onbeforeunload = function () &#123; var is = confirm("确定关闭窗口？"); if (is)&#123; websocket.close(); &#125; &#125;; //将消息显示在网页上 function setMessageInnerHTML(innerHTML) &#123; $("#msg").append(innerHTML+"&lt;br/&gt;") &#125;; //关闭连接 function closeWebSocket() &#123; websocket.close(); &#125; //发送消息 function send() &#123; var message = $("#text").val() ; websocket.send(message); $("#text").val("") ; &#125; function sendMsg()&#123; var msg = ue.getContent(); websocket.send(msg); ue.setContent(''); &#125;&lt;/script&gt;&lt;!-- jQuery (necessary for Bootstrap's JavaScript plugins) --&gt;&lt;script src="http://cdn.bootcss.com/jquery/1.11.3/jquery.min.js"&gt;&lt;/script&gt;&lt;!-- Include all compiled plugins (below), or include individual files as needed --&gt;&lt;script src="http://cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="&lt;%=path%&gt;/js/Globals.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="&lt;%=path%&gt;/js/websocket.js"&gt;&lt;/script&gt;&lt;/html&gt; 其实其中重要的就是那几个JS方法，都写有注释。需要注意的是这里1234567//判断当前浏览器是否支持WebSocketif ('WebSocket' in window) &#123; websocket = new WebSocket("ws://192.168.0.102:8080/ssm/websocket");&#125;else &#123; alert("对不起！你的浏览器不支持webSocket")&#125; 当项目跑起来之后需要将这里的地址改为你项目的地址即可。哦对了，我在这里采用了百度的一个Ueditor的富文本编辑器(虽然百度搜索我现在很少用了，但是这个编辑器确实还不错)，这个编辑器也比较简单只需要个性化的配置一下个人的需求即可。 Ueditor相关配置直接使用我项目运行的童鞋就不需要重新下载了，我将资源放在了webapp目录下的ueditor文件夹下面的。值得注意的是我们首先需要将jsp--&gt;lib下的jar包加入到项目中。加好之后会出现一个想下的箭头表示已经引入成功。，之后修改该目录下的config.json文件，主要修改以下内容即可：123456"imageAllowFiles": [".png", ".jpg", ".jpeg", ".gif", ".bmp"], /* 上传图片格式显示 */"imageCompressEnable": true, /* 是否压缩图片,默认是true */"imageCompressBorder": 1600, /* 图片压缩最长边限制 */"imageInsertAlign": "none", /* 插入的图片浮动方式 */"imageUrlPrefix": "http://192.168.0.102:8080/ssm", /* 图片访问路径前缀 */"imagePathFormat": "/ueditor/jsp/upload/image/&#123;yyyy&#125;&#123;mm&#125;&#123;dd&#125;/&#123;time&#125;&#123;rand:6&#125;", 这里主要是要修改imageUrlPrefix为你自己的项目地址就可以了。ueditor一个我认为很不错的就是他支持图片、多图、截图上传，而且都不需要手动编写后端接口，所有上传的文件、图片都会保存到项目发布出去的jsp--&gt;upload文件夹下一看就明白了。更多关于ueditor的配置可以查看官网。 其中值得注意一点的是，由于项目采用了Spring MVC并拦截了所有的请求，导致静态资源不能访问，如果是需要用到上传txt文件之类的需求可以参照web.xml中修改，如下:1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;*.txt&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 这样就可以访问txt文件了，如果还需要上传PPT之类的就以此类推。 总结这样一个简单的基于websocket的聊天室就算完成了，感兴趣的朋友可以将项目部署到外网服务器上这样好基友之间就可以愉快的聊(zhuang)天(bi)了。当然这只是一个简单的项目，感兴趣的朋友再这基础之上加入实时在线人数，用户名和IP之类的。 项目地址：https://github.com/crossoverJie/SSM.git个人博客地址：http://crossoverjie.top。GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>websocket</tag>
        <tag>HTML5</tag>
        <tag>ueditor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(四)WebService入门详解]]></title>
    <url>%2F2016%2F08%2F02%2FSSM4%2F</url>
    <content type="text"><![CDATA[前言webservice这个不知道大家首次接触的时候是怎么理解的，反正我记得我当时第一次接触这个东西的时候以为又是一个XX框架，觉得还挺高大上。然而这一切在之后我使用过后才发现这些全都是YY。那么webservice到底是什么呢，根据我自己的理解：简单来说就像是一个公开的接口，其他系统不管你是用什么语言来编写的都可以调用这个接口，并可以返回相应的数据给你。就像是现在很多的天气应用，他们肯定不会自己去搞一个气象局之类的部门去监测天气，大多都是直接调用一个天气接口，然后返回天气数据，相关应用就可以将这些信息展示给用户了。通常来说发布这类接口的应用都是用一两种语言来编写即可，但是调用这个接口应用可能会是各种语言来编写的，为了满足这样的需求webservice出现了。 简单来说webservice就是为了满足以上需求而定义出来的规范。 Spring整合CXF在Java中实现webservice有多种方法，java本身在jdk1.7之后也对webservice有了默认的实现，但是在我们实际开发中一般还是会使用框架来，比如这里所提到的CXF就有着广泛的应用。废话我就不多说了，直接讲Spring整合CXF，毕竟现在的JavaEE开发是离不开Spring了。该项目还是基于之前的SSM进行开发的。 加入maven依赖第一步肯定是要加入maven依赖：12345678910111213141516171819&lt;!--cxf--&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.cxf/cxf-rt-frontend-jaxws --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-rt-frontend-jaxws&lt;/artifactId&gt; &lt;version&gt;3.1.6&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.cxf/cxf-core --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-core&lt;/artifactId&gt; &lt;version&gt;3.1.6&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.cxf/cxf-rt-transports-http --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-rt-transports-http&lt;/artifactId&gt; &lt;version&gt;3.1.6&lt;/version&gt;&lt;/dependency&gt; web.xml配置接着我们需要配置一个CXF的servlet： 123456789&lt;!--定义一个cxf的servlet--&gt;&lt;servlet&gt; &lt;servlet-name&gt;CXFServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.cxf.transport.servlet.CXFServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;CXFServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/webservice/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 之后只要我们访问webservice/*这个地址就会进入CXF的servlet中。 整合Spring配置接下来是最重要的一部，用Spring整合CXF：在这之前我有新建一个CXF的包，如下图： 这里有两个主要类 HelloWorld接口。 实现HelloWorld接口的HelloWorldImpl类。代码如下：HelloWorld.java12345678package com.crossoverJie.cxf;import javax.jws.WebService;@WebServicepublic interface HelloWorld &#123; public String say(String str);&#125; 其中就只定义了一个简单的say()方法。HelloWorldImpl.java1234567891011package com.crossoverJie.cxf.impl;import com.crossoverJie.cxf.HelloWorld;import org.springframework.stereotype.Component;import javax.jws.WebService;@Component("helloWorld")@WebServicepublic class HelloWorldImpl implements HelloWorld &#123; public String say(String str) &#123; return "Hello"+str; &#125;&#125; 这里就是对say()方法的简单实现。接下来就是整合Spring了，由于需要使用到CXF的标签，所以我们需要添加额外的命名路径如下： 1234567891011121314151617181920212223242526&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xmlns:jee="http://www.springframework.org/schema/jee" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:jaxws="http://cxf.apache.org/jaxws" xsi:schemaLocation=" http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://cxf.apache.org/jaxws http://cxf.apache.org/schemas/jaxws.xsd"&gt; &lt;import resource="classpath:META-INF/cxf/cxf.xml"/&gt; &lt;import resource="classpath:META-INF/cxf/cxf-servlet.xml"/&gt; &lt;!-- 自动扫描webService --&gt; &lt;context:component-scan base-package="com.crossoverJie.cxf" /&gt; &lt;!-- 定义webservice的发布接口 --&gt; &lt;jaxws:endpoint implementor="#helloWorld" address="/HelloWorld"&lt;/beans&gt; 更加具体的配置可以查看官方给出的文档:http://cxf.apache.org/docs/how-do-i-develop-a-service.html。#helloWorld指的是我们在HelloWorldImpl类中所自定义的名字，/HelloWorld则是我们需要访问的地址。之后我们运行项目输入该地址：http://127.0.0.1:8080/ssm/webservice/HelloWorld?wsdl如果出现如下界面： 则说明我们的webservice发布成功了。接下来只需要通过客户端调用这个接口即可获得返回结果了。 总结以上就是一个简单的webservice入门实例，更多的关于CXF拦截器，客户端调用就没有做过多介绍，后续有时间的话再接着更新。 项目地址：https://github.com/crossoverJie/SSM.git个人博客地址：http://crossoverjie.top。GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IDEA</tag>
        <tag>CXF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(三)Shiro使用详解]]></title>
    <url>%2F2016%2F07%2F15%2FSSM3%2F</url>
    <content type="text"><![CDATA[前言相比有做过企业级开发的童鞋应该都有做过权限安全之类的功能吧，最先开始我采用的是建用户表,角色表,权限表，之后在拦截器中对每一个请求进行拦截，再到数据库中进行查询看当前用户是否有该权限，这样的设计能满足大多数中小型系统的需求。不过这篇所介绍的Shiro能满足之前的所有需求，并且使用简单，安全性高，而且现在越来越的多企业都在使用Shiro，这应该是一个收入的你的技能库。 创建自定义MyRealm类有关Shiro的基础知识我这里就不过多介绍了，直接来干货，到最后会整合Spring来进行权限验证。首先在使用Shiro的时候我们要考虑在什么样的环境下使用： 登录的验证 对指定角色的验证 对URL的验证 基本上我们也就这三个需求，所以同时我们也需要三个方法： findUserByUserName(String username)根据username查询用户，之后Shiro会根据查询出来的User的密码来和提交上来的密码进行比对。 findRoles(String username)根据username查询该用户的所有角色，用于角色验证。 findPermissions(String username)根据username查询他所拥有的权限信息，用于权限判断。 下面我贴一下我的mapper代码(PS:该项目依然是基于之前的SSM，不太清楚整合的请看SSM一)。123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;&lt;mapper namespace="com.crossoverJie.dao.T_userDao" &gt; &lt;resultMap id="BaseResultMap" type="com.crossoverJie.pojo.T_user" &gt; &lt;result property="id" column="id"/&gt; &lt;result property="userName" column="userName"/&gt; &lt;result property="password" column="password"/&gt; &lt;result property="roleId" column="roleId"/&gt; &lt;/resultMap&gt; &lt;sql id="Base_Column_List" &gt; id, username, password,roleId &lt;/sql&gt; &lt;select id="findUserByUsername" parameterType="String" resultMap="BaseResultMap"&gt; select &lt;include refid="Base_Column_List"/&gt; from t_user where userName=#&#123;userName&#125; &lt;/select&gt; &lt;select id="findRoles" parameterType="String" resultType="String"&gt; select r.roleName from t_user u,t_role r where u.roleId=r.id and u.userName=#&#123;userName&#125; &lt;/select&gt; &lt;select id="findPermissions" parameterType="String" resultType="String"&gt; select p.permissionName from t_user u,t_role r,t_permission p where u.roleId=r.id and p.roleId=r.id and u.userName=#&#123;userName&#125; &lt;/select&gt;&lt;/mapper&gt; 很简单只有三个方法，分别对应上面所说的三个方法。对sql稍微熟悉点的童鞋应该都能看懂，不太清楚就拷到数据库中执行一下就行了，数据库的Sql也在我的github上。实体类就比较简单了，就只有四个字段以及get,set方法。我就这里就不贴了，具体可以去github上fork我的源码。 现在就需要创建自定义的MyRealm类，这个还是比较重要的。继承至Shiro的AuthorizingRealm类，用于处理自己的验证逻辑，下面贴一下我的代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.crossoverJie.shiro;import com.crossoverJie.pojo.T_user;import com.crossoverJie.service.T_userService;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.AuthenticationInfo;import org.apache.shiro.authc.AuthenticationToken;import org.apache.shiro.authc.SimpleAuthenticationInfo;import org.apache.shiro.authz.AuthorizationInfo;import org.apache.shiro.authz.SimpleAuthorizationInfo;import org.apache.shiro.realm.AuthorizingRealm;import org.apache.shiro.subject.PrincipalCollection;import javax.annotation.Resource;import java.util.Set;/** * Created with IDEA * Created by $&#123;jie.chen&#125; on 2016/7/14. * Shiro自定义域 */public class MyRealm extends AuthorizingRealm &#123; @Resource private T_userService t_userService; /** * 用于的权限的认证。 * @param principalCollection * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; String username = principalCollection.getPrimaryPrincipal().toString() ; SimpleAuthorizationInfo info = new SimpleAuthorizationInfo() ; Set&lt;String&gt; roleName = t_userService.findRoles(username) ; Set&lt;String&gt; permissions = t_userService.findPermissions(username) ; info.setRoles(roleName); info.setStringPermissions(permissions); return info; &#125; /** * 首先执行这个登录验证 * @param token * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; //获取用户账号 String username = token.getPrincipal().toString() ; T_user user = t_userService.findUserByUsername(username) ; if (user != null)&#123; //将查询到的用户账号和密码存放到 authenticationInfo用于后面的权限判断。第三个参数随便放一个就行了。 AuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo(user.getUserName(),user.getPassword(), "a") ; return authenticationInfo ; &#125;else&#123; return null ; &#125; &#125;&#125; 继承AuthorizingRealm类之后就需要覆写它的两个方法，doGetAuthorizationInfo,doGetAuthenticationInfo，这两个方法的作用我都有写注释，逻辑也比较简单。doGetAuthenticationInfo是用于登录验证的，在登录的时候需要将数据封装到Shiro的一个token中，执行shiro的login()方法，之后只要我们将MyRealm这个类配置到Spring中，登录的时候Shiro就会自动的调用doGetAuthenticationInfo()方法进行验证。哦对了，忘了贴下登录的Controller了：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.crossoverJie.controller;import com.crossoverJie.pojo.T_user;import com.crossoverJie.service.T_userService;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.subject.Subject;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import javax.annotation.Resource;/** * Created with IDEA * Created by $&#123;jie.chen&#125; on 2016/7/14. * 后台Controller */@Controller@RequestMapping("/")public class T_userController &#123; @Resource private T_userService t_userService ; @RequestMapping("/loginAdmin") public String login(T_user user, Model model)&#123; Subject subject = SecurityUtils.getSubject() ; UsernamePasswordToken token = new UsernamePasswordToken(user.getUserName(),user.getPassword()) ; try &#123; subject.login(token); return "admin" ; &#125;catch (Exception e)&#123; //这里将异常打印关闭是因为如果登录失败的话会自动抛异常// e.printStackTrace(); model.addAttribute("error","用户名或密码错误") ; return "../../login" ; &#125; &#125; @RequestMapping("/admin") public String admin()&#123; return "admin"; &#125; @RequestMapping("/student") public String student()&#123; return "admin" ; &#125; @RequestMapping("/teacher") public String teacher()&#123; return "admin" ; &#125;&#125; 主要就是login()方法。逻辑比较简单，只是登录验证的时候不是像之前那样直接查询数据库然后返回是否有用户了，而是调用subject的login()方法,就是我上面提到的，调用login()方法时Shiro会自动调用我们自定义的MyRealm类中的doGetAuthenticationInfo()方法进行验证的，验证逻辑是先根据用户名查询用户，如果查询到的话再将查询到的用户名和密码放到SimpleAuthenticationInfo对象中，Shiro会自动根据用户输入的密码和查询到的密码进行匹配，如果匹配不上就会抛出异常，匹配上之后就会执行doGetAuthorizationInfo()进行相应的权限验证。doGetAuthorizationInfo()方法的处理逻辑也比较简单，根据用户名获取到他所拥有的角色以及权限，然后赋值到SimpleAuthorizationInfo对象中即可，Shiro就会按照我们配置的XX角色对应XX权限来进行判断，这个配置在下面的整合中会讲到。 整合Spring接下来应该是大家比较关系的一步：整合Spring。我是在之前的Spring SpringMVC Mybatis的基础上进行整合的。 web.xml配置首先我们需要在web.xml进行配置Shiro的过滤器。我只贴Shiro部分的，其余的和之前配置是一样的。1234567891011121314&lt;!-- shiro过滤器定义 --&gt;&lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;!-- 该值缺省为false,表示生命周期由SpringApplicationContext管理,设置为true则表示由ServletContainer管理 --&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 配置还是比较简单的，这样会过滤所有的请求。之后我们还需要在Spring中配置一个shiroFilter的bean。 spring-mybatis.xml配置由于这里配置较多，我就全部贴一下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd"&gt; &lt;!-- 自动扫描 --&gt; &lt;context:component-scan base-package="com.crossoverJie" /&gt; &lt;!-- 引入配置文件 --&gt; &lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="location" value="classpath:jdbc.properties" /&gt; &lt;/bean&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 指定连接数据库的驱动 --&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClass&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.user&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="3" /&gt; &lt;property name="minIdle" value="3" /&gt; &lt;property name="maxActive" value="20" /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="60000" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="300000" /&gt; &lt;property name="validationQuery" value="SELECT 'x'" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="testOnBorrow" value="false" /&gt; &lt;property name="testOnReturn" value="false" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="true" /&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20" /&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name="filters" value="stat" /&gt; &lt;/bean&gt; &lt;!-- spring和MyBatis完美整合，不需要mybatis的配置映射文件 --&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name="mapperLocations" value="classpath:mapping/*.xml"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- DAO接口所在包名，Spring会自动查找其下的类 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.crossoverJie.dao" /&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;!-- 配置自定义Realm --&gt; &lt;bean id="myRealm" class="com.crossoverJie.shiro.MyRealm"/&gt; &lt;!-- 安全管理器 --&gt; &lt;bean id="securityManager" class="org.apache.shiro.web.mgt.DefaultWebSecurityManager"&gt; &lt;property name="realm" ref="myRealm"/&gt; &lt;/bean&gt; &lt;!-- Shiro过滤器 核心--&gt; &lt;bean id="shiroFilter" class="org.apache.shiro.spring.web.ShiroFilterFactoryBean"&gt; &lt;!-- Shiro的核心安全接口,这个属性是必须的 --&gt; &lt;property name="securityManager" ref="securityManager"/&gt; &lt;!-- 身份认证失败，则跳转到登录页面的配置 --&gt; &lt;property name="loginUrl" value="/login.jsp"/&gt; &lt;!-- 权限认证失败，则跳转到指定页面 --&gt; &lt;property name="unauthorizedUrl" value="/nopower.jsp"/&gt; &lt;!-- Shiro连接约束配置,即过滤链的定义 --&gt; &lt;property name="filterChainDefinitions"&gt; &lt;value&gt; &lt;!--anon 表示匿名访问，不需要认证以及授权--&gt; /loginAdmin=anon &lt;!--authc表示需要认证 没有进行身份认证是不能进行访问的--&gt; /admin*=authc /student=roles[teacher] /teacher=perms["user:create"] &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 保证实现了Shiro内部lifecycle函数的bean执行 --&gt; &lt;bean id="lifecycleBeanPostProcessor" class="org.apache.shiro.spring.LifecycleBeanPostProcessor"/&gt; &lt;!-- 开启Shiro注解 --&gt; &lt;bean class="org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator" depends-on="lifecycleBeanPostProcessor"/&gt; &lt;bean class="org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor"&gt; &lt;property name="securityManager" ref="securityManager"/&gt; &lt;/bean&gt;&lt;/beans&gt; 在这里我们配置了上文中所提到的自定义myRealm,这样Shiro就可以按照我们自定义的逻辑来进行权限验证了。其余的都比较简单，看注释应该都能明白。着重讲解一下：12345678910111213&lt;property name="filterChainDefinitions"&gt; &lt;value&gt; &lt;!--anon 表示匿名访问，不需要认证以及授权--&gt; /loginAdmin=anon &lt;!--authc表示需要认证 没有进行身份认证是不能进行访问的--&gt; /admin*=authc /student=roles[teacher] /teacher=perms["user:create"] &lt;/value&gt;&lt;/property&gt; /loginAdmin=anon的意思的意思是，发起/loginAdmin这个请求是不需要进行身份认证的，这个请求在这次项目中是一个登录请求，一般对于这样的请求都是不需要身份认证的。 /admin*=authc表示 /admin,/admin1,/admin2这样的请求都是需要进行身份认证的，不然是不能访问的。 /student=roles[teacher]表示访问/student请求的用户必须是teacher角色，不然是不能进行访问的。 /teacher=perms[“user:create”]表示访问/teacher请求是需要当前用户具有user:create权限才能进行访问的。更多相关权限过滤的资料可以访问shiro的官方介绍：传送门 使用Shiro标签库Shiro还有着强大标签库，可以在前端帮我获取信息和做判断。我贴一下我这里登录完成之后显示的界面：12345678910111213141516171819202122232425&lt;%-- Created by IntelliJ IDEA. User: Administrator Date: 2016/7/14 Time: 13:17 To change this template use File | Settings | File Templates.--%&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;%@ taglib prefix="shiro" uri="http://shiro.apache.org/tags" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;后台&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;shiro:hasRole name="admin"&gt; 这是admin角色登录：&lt;shiro:principal&gt;&lt;/shiro:principal&gt;&lt;/shiro:hasRole&gt;&lt;shiro:hasPermission name="user:create"&gt; 有user:create权限信息&lt;/shiro:hasPermission&gt;&lt;br&gt;登录成功&lt;/body&gt;&lt;/html&gt; 要想使用Shiro标签，只需要引入一下标签即可：&lt;%@ taglib prefix=&quot;shiro&quot; uri=&quot;http://shiro.apache.org/tags&quot; %&gt;其实英语稍微好点的童鞋应该都能看懂。下面我大概介绍下一些标签的用法： 具有admin角色才会显示标签内的信息。 获取用户信息。默认调用Subject.getPrincipal()获取，即 Primary Principal。 用户拥有user:create这个权限才回显示标签内的信息。更多的标签可以查看官网：传送门 整体测试 这是我的测试数据。首先来验证一下登录：先输入一个错误的账号和密码： 接下来输入一个正确的： 可以看到我登录的用户是crossoverJie他是有admin的角色，并且拥有user:*(ps:系统数据详见上面的数据库截图)的权限，所以在这里： 123456&lt;shiro:hasRole name="admin"&gt; 这是admin角色登录：&lt;shiro:principal&gt;&lt;/shiro:principal&gt;&lt;/shiro:hasRole&gt;&lt;shiro:hasPermission name="user:create"&gt; 有user:create权限信息&lt;/shiro:hasPermission&gt; 是能显示出标签内的信息，并把用户信息也显示出来了。接着我们来访问一下/student这个请求，因为在Spring的配置文件中： 12345678910111213&lt;property name="filterChainDefinitions"&gt; &lt;value&gt; &lt;!--anon 表示匿名访问，不需要认证以及授权--&gt; /loginAdmin=anon &lt;!--authc表示需要认证 没有进行身份认证是不能进行访问的--&gt; /admin*=authc /student=roles[teacher] /teacher=perms["user:create"] &lt;/value&gt;&lt;/property&gt; 只有teacher角色才能访问/student这个请求的： 果然，Shiro做了安全控制是不能进行访问的。然后我们换aaa用户登录，他正好是teacher角色，看能不能访问/student。 果然是能访问的。因为我在控制器里访问/student返回的是同一个界面所以看到的还是这个界面。 1234@RequestMapping("/teacher")public String teacher()&#123; return "admin" ;&#125; 并且没有显示之前Shiro标签内的内容。其他的我就不测了，大家可以自己在数据库里加一些数据，或者是改下拦截的权限多试试，这样对Shiro的理解就会更加深刻。 MD5加密Shiro还封装了一个我认为非常不错的功能，那就是MD5加密，代码如下： 1234567891011121314151617181920package com.crossoverJie.shiro;import org.apache.shiro.crypto.hash.Md5Hash;/** * Created with IDEA * 基于Shiro的MD5加密 * Created by $&#123;jie.chen&#125; on 2016/7/13. */public class MD5Util &#123; public static String md5(String str,String salt)&#123; return new Md5Hash(str,salt).toString() ; &#125; public static void main(String[] args) &#123; String md5 = md5("abc123","crossoverjie") ; System.out.println(md5); &#125;&#125; 代码非常简单，只需要调用Md5Hash(str,salt)方法即可，这里多了一个参数，第一个参数不用多解释，是需要加密的字符串。第二个参数salt中文翻译叫盐，加密的时候我们传一个字符串进去，只要这个salt不被泄露出去，那原则上加密之后是无法被解密的，在存用户密码的时候可以使用，感觉还是非常屌的。 总结以上就是Shiro实际使用的案例，将的比较初略，但是关于Shiro的核心东西都在里面了。大家可以去我的github上下载源码，只要按照我给的数据库就没有问题，项目跑起来之后试着改下里面的东西可以加深对Shiro的理解。 项目地址：https://github.com/crossoverJie/SSM.git个人博客地址：http://crossoverjie.top。GitHub地址：https://github.com/crossoverJie。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IDEA</tag>
        <tag>Shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(二)Lucene全文检索]]></title>
    <url>%2F2016%2F07%2F06%2FSSM2%2F</url>
    <content type="text"><![CDATA[前言 大家平时肯定都有用过全文检索工具，最常用的百度谷歌就是其中的典型。如果自己能够做一个那是不是想想就逼格满满呢。Apache就为我们提供了这样一个框架，以下就是在实际开发中加入Lucene的一个小Demo。 获取Maven依赖首先看一下实际运行的效果图：这个项目是基于之前使用IDEA搭建的SSM的基础上进行增加的，建议小白先看下一我。上一篇博客，以及共享在Github上的源码。以下是Lucene所需要的依赖：1234567891011121314151617181920212223242526272829303132333435&lt;!--加入lucene--&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;$&#123;lucene.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-queryparser --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt; &lt;version&gt;$&#123;lucene.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-analyzers-common --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt; &lt;version&gt;$&#123;lucene.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--lucene中文分词--&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-analyzers-smartcn --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-analyzers-smartcn&lt;/artifactId&gt; &lt;version&gt;$&#123;lucene.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--lucene高亮--&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-highlighter --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-highlighter&lt;/artifactId&gt; &lt;version&gt;$&#123;lucene.version&#125;&lt;/version&gt; &lt;/dependency&gt; 具体的用途我都写有注释。在IDEA中修改了Pom.xml文件之后只需要点击如图所示的按钮即可重新获取依赖： 编写Lucene工具类这个工具类中的具体代码我就不单独提出来说了，每个关键的地方我都写有注释，不清楚的再讨论。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164package com.crossoverJie.lucene;import com.crossoverJie.pojo.User;import org.apache.lucene.analysis.TokenStream;import org.apache.lucene.analysis.cn.smart.SmartChineseAnalyzer;import org.apache.lucene.document.Document;import org.apache.lucene.document.Field;import org.apache.lucene.document.StringField;import org.apache.lucene.document.TextField;import org.apache.lucene.index.*;import org.apache.lucene.queryparser.classic.QueryParser;import org.apache.lucene.search.*;import org.apache.lucene.search.highlight.*;import org.apache.lucene.store.Directory;import org.apache.lucene.store.FSDirectory;import java.io.StringReader;import java.nio.file.Paths;import java.util.LinkedList;import java.util.List;import com.crossoverJie.util.*;/** * 博客索引类 * @author Administrator * */public class LuceneIndex &#123; private Directory dir=null; /** * 获取IndexWriter实例 * @return * @throws Exception */ private IndexWriter getWriter()throws Exception&#123; /** * 生成的索引我放在了C盘，可以根据自己的需要放在具体位置 */ dir= FSDirectory.open(Paths.get("C://lucene")); SmartChineseAnalyzer analyzer=new SmartChineseAnalyzer(); IndexWriterConfig iwc=new IndexWriterConfig(analyzer); IndexWriter writer=new IndexWriter(dir, iwc); return writer; &#125; /** * 添加博客索引 * @param user */ public void addIndex(User user)throws Exception&#123; IndexWriter writer=getWriter(); Document doc=new Document(); doc.add(new StringField("id",String.valueOf(user.getUserId()), Field.Store.YES)); /** * yes是会将数据存进索引，如果查询结果中需要将记录显示出来就要存进去，如果查询结果 * 只是显示标题之类的就可以不用存，而且内容过长不建议存进去 * 使用TextField类是可以用于查询的。 */ doc.add(new TextField("username", user.getUsername(), Field.Store.YES)); doc.add(new TextField("description",user.getDescription(), Field.Store.YES)); writer.addDocument(doc); writer.close(); &#125; /** * 更新博客索引 * @param user * @throws Exception */ public void updateIndex(User user)throws Exception&#123; IndexWriter writer=getWriter(); Document doc=new Document(); doc.add(new StringField("id",String.valueOf(user.getUserId()), Field.Store.YES)); doc.add(new TextField("username", user.getUsername(), Field.Store.YES)); doc.add(new TextField("description",user.getDescription(), Field.Store.YES)); writer.updateDocument(new Term("id", String.valueOf(user.getUserId())), doc); writer.close(); &#125; /** * 删除指定博客的索引 * @param userId * @throws Exception */ public void deleteIndex(String userId)throws Exception&#123; IndexWriter writer=getWriter(); writer.deleteDocuments(new Term("id", userId)); writer.forceMergeDeletes(); // 强制删除 writer.commit(); writer.close(); &#125; /** * 查询用户 * @param q 查询关键字 * @return * @throws Exception */ public List&lt;User&gt; searchBlog(String q)throws Exception&#123; /** * 注意的是查询索引的位置得是存放索引的位置，不然会找不到。 */ dir= FSDirectory.open(Paths.get("C://lucene")); IndexReader reader = DirectoryReader.open(dir); IndexSearcher is=new IndexSearcher(reader); BooleanQuery.Builder booleanQuery = new BooleanQuery.Builder(); SmartChineseAnalyzer analyzer=new SmartChineseAnalyzer(); /** * username和description就是我们需要进行查找的两个字段 * 同时在存放索引的时候要使用TextField类进行存放。 */ QueryParser parser=new QueryParser("username",analyzer); Query query=parser.parse(q); QueryParser parser2=new QueryParser("description",analyzer); Query query2=parser2.parse(q); booleanQuery.add(query, BooleanClause.Occur.SHOULD); booleanQuery.add(query2, BooleanClause.Occur.SHOULD); TopDocs hits=is.search(booleanQuery.build(), 100); QueryScorer scorer=new QueryScorer(query); Fragmenter fragmenter = new SimpleSpanFragmenter(scorer); /** * 这里可以根据自己的需要来自定义查找关键字高亮时的样式。 */ SimpleHTMLFormatter simpleHTMLFormatter=new SimpleHTMLFormatter("&lt;b&gt;&lt;font color='red'&gt;","&lt;/font&gt;&lt;/b&gt;"); Highlighter highlighter=new Highlighter(simpleHTMLFormatter, scorer); highlighter.setTextFragmenter(fragmenter); List&lt;User&gt; userList=new LinkedList&lt;User&gt;(); for(ScoreDoc scoreDoc:hits.scoreDocs)&#123; Document doc=is.doc(scoreDoc.doc); User user=new User(); user.setUserId(Integer.parseInt(doc.get(("id")))); user.setDescription(doc.get(("description"))); String username=doc.get("username"); String description=doc.get("description"); if(username!=null)&#123; TokenStream tokenStream = analyzer.tokenStream("username", new StringReader(username)); String husername=highlighter.getBestFragment(tokenStream, username); if(StringUtil.isEmpty(husername))&#123; user.setUsername(username); &#125;else&#123; user.setUsername(husername); &#125; &#125; if(description!=null)&#123; TokenStream tokenStream = analyzer.tokenStream("description", new StringReader(description)); String hContent=highlighter.getBestFragment(tokenStream, description); if(StringUtil.isEmpty(hContent))&#123; if(description.length()&lt;=200)&#123; user.setDescription(description); &#125;else&#123; user.setDescription(description.substring(0, 200)); &#125; &#125;else&#123; user.setDescription(hContent); &#125; &#125; userList.add(user); &#125; return userList; &#125;&#125; 查询Controller的编写接下来是查询Controller：123456789101112131415161718192021222324@RequestMapping("/q")public String search(@RequestParam(value = "q", required = false,defaultValue = "") String q, @RequestParam(value = "page", required = false, defaultValue = "1") String page, Model model, HttpServletRequest request) throws Exception &#123; LuceneIndex luceneIndex = new LuceneIndex() ; List&lt;User&gt; userList = luceneIndex.searchBlog(q); /** * 关于查询之后的分页我采用的是每次分页发起的请求都是将所有的数据查询出来， * 具体是第几页再截取对应页数的数据，典型的拿空间换时间的做法，如果各位有什么 * 高招欢迎受教。 */ Integer toIndex = userList.size() &gt;= Integer.parseInt(page) * 5 ? Integer.parseInt(page) * 5 : userList.size(); List&lt;User&gt; newList = userList.subList((Integer.parseInt(page) - 1) * 5, toIndex); model.addAttribute("userList",newList) ; String s = this.genUpAndDownPageCode(Integer.parseInt(page), userList.size(), q, 5, request.getServletContext(). getContextPath()); model.addAttribute("pageHtml",s) ; model.addAttribute("q",q) ; model.addAttribute("resultTotal",userList.size()) ; model.addAttribute("pageTitle","搜索关键字'" + q + "'结果页面") ; return "queryResult";&#125; 其中有用到一个genUpAndDownPageCode()方法来生成分页的Html代码，如下：1234567891011121314151617181920212223242526272829303132/** * 查询之后的分页 * @param page * @param totalNum * @param q * @param pageSize * @param projectContext * @return */private String genUpAndDownPageCode(int page,Integer totalNum,String q,Integer pageSize,String projectContext)&#123; long totalPage=totalNum%pageSize==0?totalNum/pageSize:totalNum/pageSize+1; StringBuffer pageCode=new StringBuffer(); if(totalPage==0)&#123; return ""; &#125;else&#123; pageCode.append("&lt;nav&gt;"); pageCode.append("&lt;ul class='pager' &gt;"); if(page&gt;1)&#123; pageCode.append("&lt;li&gt;&lt;a href='"+projectContext+"/q?page="+(page-1)+"&amp;q="+q+"'&gt;上一页&lt;/a&gt;&lt;/li&gt;"); &#125;else&#123; pageCode.append("&lt;li class='disabled'&gt;&lt;a href='#'&gt;上一页&lt;/a&gt;&lt;/li&gt;"); &#125; if(page&lt;totalPage)&#123; pageCode.append("&lt;li&gt;&lt;a href='"+projectContext+"/q?page="+(page+1)+"&amp;q="+q+"'&gt;下一页&lt;/a&gt;&lt;/li&gt;"); &#125;else&#123; pageCode.append("&lt;li class='disabled'&gt;&lt;a href='#'&gt;下一页&lt;/a&gt;&lt;/li&gt;"); &#125; pageCode.append("&lt;/ul&gt;"); pageCode.append("&lt;/nav&gt;"); &#125; return pageCode.toString();&#125; 代码比较简单，就是根据的页数、总页数来生成分页代码，对了我前端采用的是现在流行的Bootstrap，这个有不会的可以去他官网看看，比较简单易上手。接下来只需要编写显示界面就大功告成了。 显示界面我只贴关键代码，具体的可以去Github上查看。1234567891011121314151617181920212223242526272829303132333435363738394041&lt;c:choose&gt; &lt;c:when test="$&#123;userList.size()==0 &#125;"&gt; &lt;div align="center" style="padding-top: 20px"&gt;&lt;font color="red"&gt;$&#123;q&#125;&lt;/font&gt;未查询到结果，请换个关键字试试！&lt;/div&gt; &lt;/c:when&gt; &lt;c:otherwise&gt; &lt;div align="center" style="padding-top: 20px"&gt; 查询&lt;font color="red"&gt;$&#123;q&#125;&lt;/font&gt;关键字，约$&#123;resultTotal&#125;条记录！ &lt;/div&gt; &lt;c:forEach var="u" items="$&#123;userList &#125;" varStatus="status"&gt; &lt;div class="panel-heading "&gt; &lt;div class="row"&gt; &lt;div class="col-md-6"&gt; &lt;div class="row"&gt; &lt;div class="col-md-12"&gt; &lt;b&gt; &lt;a href="&lt;%=path %&gt;/user/showUser/$&#123;u.userId&#125;"&gt;$&#123;u.username&#125;&lt;/a&gt; &lt;/b&gt; &lt;br/&gt; $&#123;u.description&#125; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="col-md-4 col-md-offset-2"&gt; &lt;p class="text-muted text-right"&gt; $&#123;u.password&#125; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="panel-footer"&gt; &lt;p class="text-right"&gt; &lt;span class="label label-default"&gt; &lt;span class="glyphicon glyphicon-comment" aria-hidden="true"&gt;&lt;/span&gt; $&#123;u.password&#125; &lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;/c:forEach&gt; &lt;/c:otherwise&gt; &lt;/c:choose&gt; 利用JSTL标签即可将数据循环展示出来，关键字就不需要单独做处理了，在后台查询的时候已经做了修改了。 总结关于全文检索的框架不止Lucene还有solr，具体谁好有什么区别我也不太清楚，准备下来花点时间研究下。哦对了，最近又有点想做Android开发了，感觉做点东西能够实实在在的摸得到逼格确实要高些(现在主要在做后端开发)，感兴趣的朋友可以关注下。哦对了，直接运行我代码的朋友要下注意： 首先要将数据库倒到自己的MySQL上 之后在首次运行的时候需要点击重新生成索引按钮生成一遍索引之后才能进行搜索，因为现在的数据是直接存到数据库中的，并没有在新增的时候就增加索引，在实际开发的时候需要在新增数据那里再生成一份索引，就直接调用LuceneIndex类中的addIndex方法传入实体即可，再做更新、删除操作的时候也同样需要对索引做操作。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IDEA</tag>
        <tag>Lucene</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM(一)框架的整合]]></title>
    <url>%2F2016%2F06%2F28%2FSSM1%2F</url>
    <content type="text"><![CDATA[前言最近这几年JetBrains公司开发的IDEA是越来越流行了，甚至Google的官方IDE都是IDEA来定制的，可见IDEA的发展趋势是越来越好，由于博主接触IDEA的时间也不长，所以有关IDEA和Eclipse的区别和优劣势请自行百度了。借此机会我就使用IDEA来整合一下SSM，针对于初学者(初次使用IDEA和JAVAEE初学者)还是有帮助的。 新建SSM项目哦对了，关于IDEA的版本问题强烈建议使用旗舰版，有条件的就购买，没条件的嘛。。天朝你懂的。在欢迎界面点击Create New Project。之后选择Maven(新建JAVAEE项目是需要安装JDK的，这个就不在这里讲解了。)选好之后点击下一步。之后填入GroupID和ArtifactID这里尽量按照Maven的命名规范来即可。之后点击下一步，填入项目名称，这里我建议和之前填写的ArtifactID名称一样即可。点击Finish完成项目的创建。之后尽量不要做其他操作，让IDEA完成索引创建。 完善目录结构首先观察一下IDEA给我们生成的目录结构，这是一个标准的Maven目录。但是其中少了一个webapp目录用于存放jsp、css、js、图片之类的文件。之后还需要完善我们的目录结构，如下图：以上的命名都是我们开发过程中常用的命名规则，不一定按照我这样来，但是最好是有一定的规范。 POM.xmlpom.xml是整个maven的核心配置文件，里面有对项目的描述和项目所需要的依赖。哦对了，在修改pom.xml文件之前我们最好先设置一下该项目的Maven设置(IDEA对每个项目的maven设置和Eclipse不一样，不是设置一次就可了，如果今后还要新建项目那就还需要设置，同时按住ctrl,alt,s是打开设置的快捷键，更多有关IDEA的操作今后会更新相关博文。) IDEA的Maven设置在Eclipse中用过Maven的都应该知道，这里是将项目的Maven换成我们自己安装的Maven，下面两个目录是选择Maven配置文件，不知道是什么原因在Eclipse中选择了配置文件之后会自动的将Maven本地厂库的路径更改为你settings.xml中配置的路径。既然这里没有自动选中那我们就手动修改即可，尽量不要放在C盘，一是用久之后本地厂库占用的空间会比较大，二是万一系统崩溃的话还有可能找回来。 修改pom.xml以下是我的pom.xml文件：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--suppress MavenModelInspection --&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.crossoverJie&lt;/groupId&gt; &lt;artifactId&gt;SSM&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.6&lt;/source&gt; &lt;target&gt;1.6&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;spring.version&gt;4.1.4.RELEASE&lt;/spring.version&gt; &lt;jackson.version&gt;2.5.0&lt;/jackson.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 使用SpringMVC需配置 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 关系型数据库整合时需配置 如hibernate jpa等 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log4j --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql连接 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.34&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.18&lt;/version&gt; &lt;/dependency&gt; &lt;!-- json --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- aop --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- servlet --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;3.0-alpha-1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.4&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 上传文件 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 关于maven的知识点我就不细讲了，毕竟这是一个整合教程。 spring-mvc.xml这个配置文件是springMVC的配置文件：里面的我都写有注释，应该都能看懂。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd"&gt; &lt;!-- 自动扫描该包，使SpringMVC认为包下用了@controller注解的类是控制器 --&gt; &lt;context:component-scan base-package="com.crossoverJie.controller" /&gt; &lt;!--避免IE执行AJAX时，返回JSON出现下载文件 --&gt; &lt;!--&lt;bean id="mappingJacksonHttpMessageConverter" class="org.springframework.http.converter.json.MappingJacksonHttpMessageConverter"&gt; &lt;property name="supportedMediaTypes"&gt; &lt;list&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;--&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- 启动SpringMVC的注解功能，完成请求和注解POJO的映射 --&gt; &lt;!-- 定义跳转的文件的前后缀 ，视图模式配置--&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;!-- 这里的配置我的理解是自动给后面action的方法return的字符串加上前缀和后缀，变成一个 可用的url地址 --&gt; &lt;property name="prefix" value="/WEB-INF/jsp/" /&gt; &lt;property name="suffix" value=".jsp" /&gt; &lt;/bean&gt; &lt;!-- 配置文件上传，如果没有使用文件上传可以不用配置，当然如果不配，那么配置文件中也不必引入上传组件包 --&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;!-- 默认编码 --&gt; &lt;property name="defaultEncoding" value="utf-8" /&gt; &lt;!-- 文件大小最大值 --&gt; &lt;property name="maxUploadSize" value="10485760000" /&gt; &lt;!-- 内存中的最大值 --&gt; &lt;property name="maxInMemorySize" value="40960" /&gt; &lt;/bean&gt; &lt;!-- 配置拦截器 --&gt; &lt;!--&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &amp;lt;!&amp;ndash; &lt;mvc:mapping path="/**"/&gt;拦截所有 &amp;ndash;&amp;gt; &lt;mvc:mapping path="/user/**"/&gt; &lt;mvc:mapping path="/role/**"/&gt; &lt;mvc:mapping path="/function/**"/&gt; &lt;mvc:mapping path="/news/**"/&gt; &lt;mvc:mapping path="/img/**"/&gt; &lt;bean class="com.crossoverJie.intercept.Intercept"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt;--&gt;&lt;/beans&gt; 关于上面拦截器注释掉的那里，配置是没有问题的，因为这是一个整合项目，所以里边也没有用到拦截器，为了防止运行报错所以就先注释掉了。如果后续需要增加拦截器，可以参考这里的配置。 spring-mybatis.xml这个是spring和mybatis的整合配置文件，其中还有Druid连接池的配置。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd"&gt; &lt;!-- 自动扫描 --&gt; &lt;context:component-scan base-package="com.crossoverJie" /&gt; &lt;!-- 引入配置文件 --&gt; &lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="location" value="classpath:jdbc.properties" /&gt; &lt;/bean&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 指定连接数据库的驱动 --&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driverClass&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.user&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="3" /&gt; &lt;property name="minIdle" value="3" /&gt; &lt;property name="maxActive" value="20" /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="60000" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="300000" /&gt; &lt;property name="validationQuery" value="SELECT 'x'" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="testOnBorrow" value="false" /&gt; &lt;property name="testOnReturn" value="false" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="true" /&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20" /&gt; &lt;!-- 配置监控统计拦截的filters，去掉后监控界面sql无法统计 --&gt; &lt;property name="filters" value="stat" /&gt; &lt;/bean&gt; &lt;!-- spring和MyBatis完美整合，不需要mybatis的配置映射文件 --&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name="mapperLocations" value="classpath:mapping/*.xml"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- DAO接口所在包名，Spring会自动查找其下的类 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.crossoverJie.dao" /&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- (事务管理)transaction manager, use JtaTransactionManager for global tx --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt;&lt;/beans&gt; 以上两个就是最重要的配置文件了，只要其中的包名和配置文件中的名字一样就不会出问题。关于xxMpper.xml以及实体类的生成，我们可以借助mybatis-generator自动生成工具来生成，方便快捷。 IDEA配置Tomcat关于Tomcat的下载与安装我这里就不多介绍了。按照下图选择：在name中为这个Tomcat输入一个名字。之后选择你本地Tomcat的目录点击Ok即可。点击apply和保存之后就返回首页即可看到Tomcat的标识。根据需要点击Run和Debug即可运行。 运行结果如下：点击上图的2,3,4可看到不同用户的结果，如果你走到这一步，那么恭喜你整合成功。 总结以上源码都在github上。项目地址：SSM欢迎拍砖。]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>SpringMVC</tag>
        <tag>Mybatis</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日常记录（三）更换Hexo主题]]></title>
    <url>%2F2016%2F06%2F18%2Fnormal-skill3%2F</url>
    <content type="text"><![CDATA[前言 由于博主的喜新厌旧，再经过一段时间对上一个主题的审美疲劳加上我专(zhuang)研(bi)的精神于是就想找一个B格较高的主题。经过一段时间的查找发现NexT这个主题简洁而不失华丽，低调而不失逼格(就不收广告费了)特别适合我，接着就着手开干。 安装NexT主题从Git上克隆主题这里我就不介绍有关Hexo的东西了，默认是知道如何搭建Hexo博客的。还不太清楚的请自行百度。首先将NexT主题先克隆到自己电脑上： cd your-hexo-site git clone https://github.com/iissnan/hexo-theme-next themes/next。安装主题接下来我们只需要将站点下的_config.yml配置文件中的主题配置更换成Next，如下图：其实这样主题就配好了，是不是很简单。 NexT主题配置Hexo配置文件相关配置Next主题的个人头像是在Hexo配置文件中的。NexT同样也支持多说配置，我们只需要将你自己的多说账号也配置到Hexo的配置文件中即可。duoshuo_shortname: your name Next配置文件相关配置NexT主题非常吸引我的一点就是他支持打赏功能，这让我这种穷逼程序猿又看到了生路(多半也没人会给我打赏)，以下一段配置即可在每篇博文下边开启打赏功能。微信也是可以的，但是我找了半天没有找到生成微信支付码的地方。其他的一些配置我觉得都比较简单，看官方的帮助文档也是完全可以的，有问题的我们可以再讨论。 一个绕坑指南我在换完NexT之后发现在首页这里显示的分类和便签的统计都是对的，但是点进去之后就是空白的。我查看了Hexo和NexT的文档发现我写的没有任何问题，之后就懵逼了。。。各位有碰到这个问题的可以往下看。 绕坑之后我仔细的查阅了NexT的文档，发现他所使用的tags和categories文件夹下的index.md的格式是这样的：12345---title: tagsdate: 2016-06-16 02:13:06type: &quot;tags&quot;--- 这和我之前使用的JackMan主题是完全不一样的(有关JackMan主题可以自行查阅)。之后我讲categories文件下的index.md文件也换成这样的格式就没有问题了。如果你和我一样眼神不好的话建议配副眼镜。 总结其实以上的很多东西都是在NexT官方文档里查得到的，接下来我会尝试提一点pull request来更加深入的了解Hexo。]]></content>
      <categories>
        <category>日常记录</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日常记录（二）SpringMvc导出Excel]]></title>
    <url>%2F2016%2F06%2F14%2Fnormal-skill2%2F</url>
    <content type="text"><![CDATA[前言 相信很多朋友在实际工作中都会要将数据导出成Excel的需求，通常这样的做法有两种。一是采用JXL来生成Excel，之后保存到服务器，然后在生成页面之后下载该文件。二是使用POI来生成Excel，之后使用Stream的方式输出到前台直接下载(ps:当然也可以生成到服务器中再下载。)。这里我们讨论第二种。至于两种方式的优缺点请自行百度。 Struts2的方式通常我会将已经生成好的HSSFWorkbook放到一个InputStream中，然后再到xml配置文件中将返回结果更改为stream的方式。如下：12345678private void responseData(HSSFWorkbook wb) throws IOException &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); wb.write(baos); baos.flush(); byte[] aa = baos.toByteArray(); excelStream = new ByteArrayInputStream(aa, 0, aa.length); baos.close();&#125; 配置文件：1234567&lt;action name="exportXxx" class="xxxAction" method="exportXxx"&gt; &lt;result name="exportSuccess" type="stream"&gt; &lt;param name="inputName"&gt;excelStream&lt;/param&gt; &lt;param name="contentType"&gt;application/vnd.ms-excel&lt;/param&gt; &lt;param name="contentDisposition"&gt;attachment;filename="Undefined.xls"&lt;/param&gt; &lt;/result&gt;&lt;/action&gt; 这样即可达到点击链接即可直接下载文件的目的。 SpringMVC的方式先贴代码：123456789101112131415@RequestMapping("/exportXxx.action")public void exportXxx(HttpServletRequest request, HttpServletResponse response, @RequestParam(value="scheduleId", defaultValue="0")int scheduleId)&#123; HSSFWorkbook wb = createExcel(scheduleId) ; try &#123; response.setHeader("Content-Disposition", "attachment; filename=appointmentUser.xls"); response.setContentType("application/vnd.ms-excel; charset=utf-8") ; OutputStream out = response.getOutputStream() ; wb.write(out) ; out.flush(); out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 其实springMVC和Struts2的原理上是一样的，只是Struts2是才去配置文件的方式。首先是使用createExcel()这个方法来生成Excel并返回，最后利用rresponse即可向前台输出Excel，这种方法是通用的，也可以试用与Servlet、Struts2等。我们只需要在response的头信息中设置相应的输出信息即可。 总结不管是使用Struts2，还是使用SpringMVC究其根本都是使用的response，所以只要我们把response理解透了不管是下载图片、world、Excel还是其他什么文件都是一样的。]]></content>
      <categories>
        <category>日常记录</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>poi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日常记录（一）MySQL被锁解决方案]]></title>
    <url>%2F2016%2F06%2F05%2Fnormal-skill1%2F</url>
    <content type="text"><![CDATA[前言 由于前段时间为了让部署在Linux中的项目访问另一台服务器的MySQL，经过各种折腾就把root用户给弄出问题了，导致死活登不上PS:Linux中的项目还是没有连上。。(这是后话了。)。经过各种查阅资料终于找到解决方法了。 报错如下：Access denied for user &#39;root&#39;@&#39;localhost&#39; (using password:YES) 关闭MySQL服务，修改MySQL初始文件打开MySQL目录下的my-default.ini文件，如图：在最后一行加入skip-grant-tables之后保存。然后重启MySQL服务。 用命令行登录MySQL修改ROOT账号密码用命令行登录MySQL输入mysql -uroot -p,不用输入密码，直接敲回车即可进入。如下图：之后执行以下语句修改ROOT用户密码： use mysql; update user set password=PASSWORD(&quot;你的密码&quot;) where user=&#39;root&#39;; 还原my-default.ini文件最后还原配置文件，之后重启MySQL服务即可正常登录了。]]></content>
      <categories>
        <category>日常记录</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程（二）有返回值的多线程]]></title>
    <url>%2F2016%2F05%2F27%2Fjava-thread2%2F</url>
    <content type="text"><![CDATA[前言之前我们使用多线程要么是继承Thread类，要么是实现Runnable接口，然后重写一下run()方法即可。但是只有的话如果有死锁、对共享资源的访问和随时监控线程状态就不行了，于是在Java5之后就有了Callable接口。 简单的实现有返回值的线程代码如下：CallableFuture类1234567891011121314151617181920212223242526272829303132333435package top.crosssoverjie.study.Thread;import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;public class CallableFuture &#123; public static void main(String[] args) &#123; //创建一个线程池 ExecutorService pool = Executors.newFixedThreadPool(3) ; //创建三个有返回值的任务 CallableTest2 c1 = new CallableTest2("线程1") ; CallableTest2 c2 = new CallableTest2("线程2") ; CallableTest2 c3 = new CallableTest2("线程3") ; Future f1 = pool.submit(c1) ; Future f2 = pool.submit(c2) ; Future f3 = pool.submit(c3) ; try &#123; System.out.println(f1.get().toString()); System.out.println(f2.get().toString()); System.out.println(f3.get().toString()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125;finally&#123; pool.shutdown(); &#125; &#125;&#125; ·CallableTest2·类：123456789101112131415161718package top.crosssoverjie.study.Thread;import java.util.concurrent.Callable;public class CallableTest2 implements Callable &#123; private String name ; public CallableTest2(String name) &#123; this.name = name; &#125; @Override public Object call() throws Exception &#123; return name+"返回了东西"; &#125; &#125; 运行结果：123线程1返回了东西线程2返回了东西线程3返回了东西 总结以上就是一个简单的例子，需要了解更多详情可以去看那几个类的API。]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Callable</tag>
        <tag>ExecutorService</tag>
        <tag>Future</tag>
        <tag>Executors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让百度和google收录我们的网站]]></title>
    <url>%2F2016%2F05%2F19%2Fbaidu-google%2F</url>
    <content type="text"><![CDATA[前言花了几天时间终于把这个看似高大上的博客搞好了，但是发现只能通过在地址栏输入地址进行访问，这很明显和我装X装到底的性格，于是乎在查阅了嘟爷的博客，和我各种百度终于搞出来了。 让谷歌收录让谷歌收录还是比较简单，首先我们肯定是要翻墙的(这个就不仔细说了，具体百度。)由于我这里突然登不上google账号了，所以下次补充截图。同体来说就是以下步骤： 下载google的html验证文件放到网站的根目录，使google能够访问得到。 在谷歌站长工具里加上自己的站点地图。 创建站点地图站点地图是一种文件，可以通过该文件列出您网站上的网页，从而将您网站内容的组织架构告知Google和其他搜索引擎，以便更加智能的抓取你的网站信息。首先我们要为Hexo安装谷歌和百度的插件(博主是用Hexo来搭建的博客)，如下：123npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save 在博客的根目录中的_config.yml文件中加入以下内容：之后部署上去之后如果在地址栏后面加上站点地图如下的话表示部署成功： 让百度收录有三种方式可以让百度收录我们的网站。第一种：主动推送我用Java写了一个小程序，可以手工的自己推送地址给百度。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package top.crossoverjie.post;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.io.PrintWriter;import java.net.URL;import java.net.URLConnection;public class Post &#123; public static void main(String[] args) &#123; String url = "http://data.zz.baidu.com/urls?site=crossoverjie.top&amp;token=1002EzhDReuy34dq";// 网站的服务器连接 String[] param = &#123; // 需要推送的网址// "http://crossoverjie.top/tags",// "http://crossoverjie.top/categories", //"http://crossoverjie.top/about/" "http://crossoverjie.top/2016/05/14/java-thread1" &#125;; String json = Post(url, param);// 执行推送方法 System.out.println("结果是" + json); // 打印推送结果 &#125; /** * 百度链接实时推送 * * @param PostUrl * @param Parameters * @return */ public static String Post(String PostUrl, String[] Parameters) &#123; if (null == PostUrl || null == Parameters || Parameters.length == 0) &#123; return null; &#125; String result = ""; PrintWriter out = null; BufferedReader in = null; try &#123; // 建立URL之间的连接 URLConnection conn = new URL(PostUrl).openConnection(); // 设置通用的请求属性 conn.setRequestProperty("Host", "data.zz.baidu.com"); conn.setRequestProperty("User-Agent", "curl/7.12.1"); conn.setRequestProperty("Content-Length", "83"); conn.setRequestProperty("Content-Type", "text/plain"); // 发送POST请求必须设置如下两行 conn.setDoInput(true); conn.setDoOutput(true); // 获取conn对应的输出流 out = new PrintWriter(conn.getOutputStream()); // 发送请求参数 String param = ""; for (String s : Parameters) &#123; param += s + "\n"; &#125; out.print(param.trim()); // 进行输出流的缓冲 out.flush(); // 通过BufferedReader输入流来读取Url的响应 in = new BufferedReader( new InputStreamReader(conn.getInputStream())); String line; while ( (line = in.readLine()) != null) &#123; result += line; &#125; &#125; catch (Exception e) &#123; System.out.println("发送post请求出现异常！" + e); e.printStackTrace(); &#125; finally &#123; try &#123; if (out != null) &#123; out.close(); &#125; if (in != null) &#123; in.close(); &#125; &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; &#125; return result; &#125;&#125; 运行之后结果如下：1结果是&#123;"remain":499,"success":1&#125; remain表示还有多少可以推送，我这里表示还有499条。success表示成功推送了多少条链接，我这里表示成功推送了一条链接。 第二种是主动推送，可以按照百度的教程进行配置： 第三种就是配置站点地图了，按照之前将的将站点地图安装到项目中，参照我的配置即可：如果能像我这个一样状态正常，能获取到URL数量就表示成功了。 总结在整个过程中不是我黑百度，百度的效率真是太低了。我头一天在google提交上去第二天就能收到了，百度是我提交了大概一周多才给我收录进去，这当然肯定也和我的内容有关系。]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
      <tags>
        <tag>baidu</tag>
        <tag>google</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程（一）多线程基础]]></title>
    <url>%2F2016%2F05%2F14%2Fjava-thread1%2F</url>
    <content type="text"><![CDATA[前言本文主要讲解java多线程的基础，以及一些常用方法。关于线程同步、ExecutorService框架我会放到后续的文章进行讲解。 进程与线程的区别进程进程简单的来说就是在内存中运行的应用程序，一个进程可以启动多个线程。比如在windows中一个运行EXE文件就是一个进程。 线程同一个线程中的进程共用相同的地址空间，同时共享进程所拥有的内存和其他资源。 线程Demo-继承Thread类首先我们我们继承java.lang.Thread类来创建线程。12345678910111213141516171819202122232425262728293031package top.crosssoverjie.study.Thread;public class TestThread &#123; public static void main(String[] args) &#123; System.out.println("主线程ID是：" + Thread.currentThread().getId()); MyThread my = new MyThread("线程1"); my.start() ; MyThread my2 = new MyThread("线程2") ; /** * 这里直接调用my2的run()方法。 */ my2.run() ; &#125;&#125;class MyThread extends Thread &#123; private String name; public MyThread(String name) &#123; this.name = name; &#125; @Override public void run() &#123; System.out.println("名字：" + name + "的线程ID是=" + Thread.currentThread().getId()); &#125;&#125; 输出结果:123主线程ID是：1名字：线程2的线程ID是=1名字：线程1的线程ID是=9 由输出结果我们可以得出以下结论： my和my2的线程ID不相同，my2和主线程ID相同。说明直接调用run()方法不会创建新的线程，而是在主线程中直接调用的run()方法,和普通的方法调用没有区别。 虽然my的start()方法是在my2的run()方法之前调用，但是却是后输出内容，说明新建的线程并不会影响主线程的执行。 线程Demo-实现Runnable接口除了继承java.lang.Thread类之外，我们还可以实现java.lang.Runnable接口来创建线程。12345678910111213141516171819202122232425262728293031package top.crosssoverjie.study.Thread;public class TestRunnable &#123; public static void main(String[] args) &#123; System.out.println("主线程的线程ID是"+Thread.currentThread().getId()); MyThread2 my = new MyThread2("线程1") ; Thread t = new Thread(my) ; t.start() ; MyThread2 my2 = new MyThread2("线程2") ; Thread t2 = new Thread(my2) ; /** * 方法调用，并不会创建线程，依然是主线程 */ t2.run() ; &#125;&#125;class MyThread2 implements Runnable&#123; private String name ; public MyThread2(String name)&#123; this.name = name ; &#125; @Override public void run() &#123; System.out.println("线程"+name+"的线程ID是"+Thread.currentThread().getId()); &#125; &#125; 输出结果:123主线程的线程ID是1线程线程2的线程ID是1线程线程1的线程ID是9 notes: 实现Runnable的方式需要将实现Runnable接口的类作为参数传递给Thread，然后通过Thread类调用Start()方法来创建线程。 这两种方式都可以来创建线程，至于选择哪一种要看自己的需求。直接继承Thread类的话代码要简洁一些，但是由于java只支持单继承，所以如果要继承其他类的同时需要实现线程那就只能实现Runnable接口了，这里更推荐实现Runnable接口。 实际上如果我们查看Thread类的源码我们会发现Thread是实现了Runnable接口的： 线程中常用的方法 序号 方法 介绍 1 public void start() 使该线程执行，java虚拟机会调用该线程的run()方法。 2 public final void setName(String name) 修改线程名称。 3 public final void setPriority(int privority) 修改线程的优先级。 4 public final void setDaemon(false on) 将该线程标记为守护线程或用户线程，当正在运行线程都是守护线程时，java虚拟机退出，该方法必须在启动线程前调用。 5 public final void join(long mills) 等待该线程的终止时间最长为mills毫秒。 6 public void interrupt() 中断线程。 7 public static boolean isAlive() 测试线程是否处于活动状态。如果该线程已经启动尚未终止，则为活动状态。 8 public static void yield() 暂停当前线程执行的对象，并执行其他线程。 9 public static void sleep(long mills) 在指定毫秒数内，让当前执行的线程休眠(暂停)。 10 public static Thread currentThread() 返回当前线程的引用。 方法详解- public static void sleep(long mills)1234567891011121314151617181920212223242526272829303132333435package top.crosssoverjie.study.Thread;public class TestSleep &#123; private int i = 10 ; private Object ob = new Object() ; public static void main(String[] args) &#123; TestSleep t = new TestSleep() ; MyThread3 thread1 = t.new MyThread3() ; MyThread3 thread2 = t.new MyThread3() ; thread1.start() ; thread2.start() ; &#125; class MyThread3 extends Thread&#123; @Override public void run() &#123; synchronized (ob) &#123; i++ ; System.out.println("i的值："+i); System.out.println("线程："+Thread.currentThread().getName()+"进入休眠状态"); try &#123; Thread.currentThread().sleep(1000) ; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println("线程："+Thread.currentThread().getName()+"休眠结束"); i++; System.out.println("i的值&gt;："+i); &#125; &#125; &#125; &#125; 输出结果：12345678i的值：11线程：Thread-0进入休眠状态线程：Thread-0休眠结束i的值&gt;：12i的值：13线程：Thread-1进入休眠状态线程：Thread-1休眠结束i的值&gt;：14 由输出结果我们可以得出： 当Thread0进入休眠状态时，Thread1并没有继续执行，而是等待Thread0休眠结束释放了对象锁，Thread1才继续执行。当调用sleep()方法时，必须捕获异常或者向上层抛出异常。当线程休眠时间满时，并不一定会马上执行，因为此时有可能CPU正在执行其他的任务，所以调用了sleep()方法相当于线程进入了阻塞状态。 方法详解- public static void yield()123456789101112131415161718192021package top.crosssoverjie.study.Thread;public class Testyield &#123; public static void main(String[] args) &#123; MyThread4 my = new MyThread4() ; my.start() ; &#125;&#125;class MyThread4 extends Thread&#123; @Override public void run() &#123; long open = System.currentTimeMillis(); int count= 0 ; for(int i=0 ;i&lt;1000000;i++)&#123; count= count+(i+1);// Thread.yield() ; &#125; long end = System.currentTimeMillis(); System.out.println("用时："+(end-open)+"毫秒"); &#125;&#125; 输出结果:用时：1毫秒如果将 Thread.yield()注释取消掉，输出结果:用时：116毫秒 调用yield()方法是为了让当前线程交出CPU权限，让CPU去执行其他线程。它和sleep()方法类似同样是不会释放锁。但是yield()不能控制具体的交出CUP的时间。并且它只能让相同优先级的线程获得CPU执行时间的机会。 调用yield()方法不会让线程进入阻塞状态，而是进入就绪状态，它只需要等待重新获取CPU的时间，这一点和sleep()方法是不一样的。 方法详解- public final void join()在很多情况下我们需要在子线程中执行大量的耗时任务，但是我们主线程又必须得等待子线程执行完毕之后才能结束，这就需要用到 join()方法了。join()方法的作用是等待线程对象销毁，如果子线程执行了这个方法，那么主线程就要等待子线程执行完毕之后才会销毁，请看下面这个例子：123456789101112131415161718192021222324252627package top.crosssoverjie.study.Thread;public class Testjoin &#123; public static void main(String[] args) throws InterruptedException &#123; new MyThread5("t1").start() ; for (int i = 0; i &lt; 10; i++) &#123; if(i == 5)&#123; MyThread5 my =new MyThread5("t2") ; my.start() ; my.join() ; &#125; System.out.println("main当前线程："+Thread.currentThread().getName()+" "+i); &#125; &#125;&#125;class MyThread5 extends Thread&#123; public MyThread5(String name)&#123; super(name) ; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println("当前线程："+Thread.currentThread().getName()+" "+i); &#125; &#125;&#125; 输出结果：1234567891011121314151617181920main当前线程：main 0当前线程：t1 0当前线程：t1 1main当前线程：main 1当前线程：t1 2main当前线程：main 2当前线程：t1 3main当前线程：main 3当前线程：t1 4main当前线程：main 4当前线程：t2 0当前线程：t2 1当前线程：t2 2当前线程：t2 3当前线程：t2 4main当前线程：main 5main当前线程：main 6main当前线程：main 7main当前线程：main 8main当前线程：main 9 如果我们把join()方法注释掉之后：1234567891011121314151617181920main当前线程：main 0当前线程：t1 0main当前线程：main 1当前线程：t1 1main当前线程：main 2当前线程：t1 2main当前线程：main 3当前线程：t1 3main当前线程：main 4当前线程：t1 4main当前线程：main 5main当前线程：main 6main当前线程：main 7main当前线程：main 8main当前线程：main 9当前线程：t2 0当前线程：t2 1当前线程：t2 2当前线程：t2 3当前线程：t2 4 由上我们可以得出以下结论： 在使用了join()方法之后主线程会等待子线程结束之后才会结束。 方法详解- setDaemon(boolean on),getDaemon()用来设置是否为守护线程和判断是否为守护线程。notes： 守护线程依赖于创建他的线程，而用户线程则不需要。如果在main()方法中创建了一个守护线程，那么当main方法执行完毕之后守护线程也会关闭。而用户线程则不会，在JVM中垃圾收集器的线程就是守护线程。 优雅的终止线程有三种方法可以终止线程，如下： 使用退出标识，使线程正常的退出，也就是当run()方法完成后线程终止。 使用stop()方法强行关闭，这个方法现在已经被废弃，不推荐使用 使用interrupt()方法终止线程。 具体的实现代码我将在下一篇博文中将到。。 线程的优先级在操作系统中线程是分优先级的，优先级高的线程CPU将会提供更多的资源，在java中我们可以通过setPriority(int newPriority)方法来更改线程的优先级。在java中分为1~10这个十个优先级，设置不在这个范围内的优先级将会抛出IllegalArgumentException异常。java中有三个预设好的优先级： public final static int MIN_PRIORITY = 1; public final static int NORM_PRIORITY = 5; public final static int MAX_PRIORITY = 10; 参考 如何终止线程 java多线程学习 java多线程思维图 总结以上就是我总结的java多线程基础知识，后续会补充线程关闭、线程状态、线程同步和有返回结果的多线程。]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
        <tag>Runnable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java笔记（一）Java的反射机制]]></title>
    <url>%2F2016%2F05%2F10%2Fjava-reflect%2F</url>
    <content type="text"><![CDATA[前言java反射机制指的是在java运行过程中，对于任意的类都可以知道他的所有属性以及方法，对于任意一个对象都可以任意的调用他的属性和方法，这种动态获取对象信息和动态调用对象方法的功能称为java反射机制，但是反射使用不当会造成很高的成本。 简单实例 反射获取类名称123456789101112131415161718package top.crosssoverjie.study;public class Reflect &#123; public static void main(String[] args) &#123; Class&lt;Reflect&gt; c1 = Reflect.class; System.out.println(c1.getName()); Reflect r1 = new Reflect() ; Class&lt;Reflect&gt; c2 = (Class&lt;Reflect&gt;) r1.getClass() ; System.out.println(c2.getName()); try &#123; Class&lt;Reflect&gt; c3 = (Class&lt;Reflect&gt;) Class.forName("top.crosssoverjie.study.Reflect"); System.out.println(c3.getName()); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出结果： 123top.crosssoverjie.study.Reflecttop.crosssoverjie.study.Reflecttop.crosssoverjie.study.Reflect 以上的 c1,c2,c3是完全一样的，他们都有一个统一的名称：叫做Reflect类的类类型。 反射的用处获取成员方法12public Method getDeclaredMethod(String name,Class&lt;?&gt;...parameterTypes)//得到该类的所有方法，但是不包括父类的方法。public Method getMethod(String name,Class&lt;?&gt;...parameterTypes)//获得该类的所有public方法，包括父类的。 通过反射获取成员方法调用的实例:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package top.crosssoverjie.study;import java.lang.reflect.Method;public class Person &#123; private String name="crossover" ; private String msg ; public Person(String name, String msg) &#123; this.name = name; this.msg = msg; System.out.println(name+"的描述是"+msg); &#125; public Person() &#123; super(); &#125; public void say(String name ,String msg)&#123; System.out.println(name+"说："+msg); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; public static void main(String[] args) &#123; try &#123; //首先获取类类型 Class c1 = Class.forName("top.crosssoverjie.study.Person") ; //通过newInstance()方法生成一个实例 Object o1 = c1.newInstance() ; //获取该类的say方法 Method m1 = c1.getMethod("say", String.class,String.class) ; //通过invoke方法调用该方法// m1.invoke(o1, "张三","你好啊") ; Method[] methods = c1.getDeclaredMethods() ;// for(Method m : methods)&#123;// System.out.println(m.getName());// &#125; Method[] methods2 = c1.getMethods() ; for (Method method : methods2) &#123; System.out.println(method.getName()); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出结果：1张三说：你好啊 所以我们只要知道类的全限定名就可以任意的调用里面的方法。 1234Method[] methods = c1.getDeclaredMethods() ;for(Method m : methods)&#123; System.out.println(m.getName());&#125; 输出结果：123456maingetNamesetNamesaygetMsgsetMsg 使用的还是之前那个Person类，所以这里只写了关键代码。这里输出的是Person的所有public方法。 如果我们调用getMethods()方法会是什么结果呢？1234Method[] methods2 = c1.getMethods() ;for (Method method : methods2) &#123; System.out.println(method.getName());&#125; 输出结果:123456789101112131415maingetNamesetNamesaygetMsgsetMsgwaitwaitwaithashCodegetClassequalstoStringnotifynotifyAll 这时我们会发现这里输出的结果会比刚才多得多，这时因为getMethods()方法返回的是包括父类的所有方法。 获取成员变量我们还可以通过反射来获取类包括父类的成员变量，主要方法如下：12public Field getDeclaredFiled(String name)//获得该类所有的成员变量，但不包括父类的。public Filed getFiled(String name)//获得该类的所有的public变量，包括其父类的。 还是按照之前例子中的Person类举例，他具有两个成员变量：12private String name="crossover" ;private String msg ; 我们可以通过以下方法来获取其中的成员变量：12Class c1 = Class.forName("top.crosssoverjie.study.Person") ;Field field = c1.getDeclaredField("name");//获取该类所有的成员属性 通过以下例子可以获取指定对象上此field的值：123456789101112131415161718192021222324252627282930313233343536package top.crosssoverjie.study;import java.io.File;import java.lang.reflect.Field;public class Reflect &#123; public static void main(String[] args) &#123; try &#123; Class c1 = Class.forName("top.crosssoverjie.study.Person"); Field field = c1.getDeclaredField("name") ; Object o1 = c1.newInstance() ; /** * 由于Person类中的name变量是private修饰的， * 所以需要手动开启允许访问，是public修饰的就不需要设置了 */ field.setAccessible(true); Object name = field.get(o1) ; System.out.println(name); &#125; catch (Exception e) &#123; e.printStackTrace() ; &#125;// Class&lt;Reflect&gt; c1 = Reflect.class;// System.out.println(c1.getName());// // Reflect r1 = new Reflect() ;// Class&lt;Reflect&gt; c2 = (Class&lt;Reflect&gt;) r1.getClass() ;// System.out.println(c2.getName());// // try &#123;// Class&lt;Reflect&gt; c3 = (Class&lt;Reflect&gt;) Class.forName("top.crosssoverjie.study.Reflect");// System.out.println(c3.getName());// &#125; catch (ClassNotFoundException e) &#123;// e.printStackTrace();// &#125; &#125;&#125; 输出结果：1crossover 我们也可以通过方法getDeclaredFieds()方法来获取所有的成员变量，返回是是一个Field[]数组，只需要遍历这个数组即可获所有的成员变量。例子如下： 1234Field[] fields = c1.getDeclaredFields() ;for(Field f :fields)&#123; System.out.println(f.getName());&#125; 输出结果如下：12namemsg 获取构造方法可以通过以下两个方法来获取构造方法：12public Constructor getDeclaredConstructor(Class&lt;?&gt;...parameterTypes)//获取该类的所有构造方法，不包括父类的。public Constructor getConstructor(Class&lt;?&gt;...parameterTypes)//获取该类的所有public修饰的构造方法，包括父类的。 在之前的Person类中有以下的构造方法：1234public Person(String name, String msg) &#123; this.name = name; this.msg = msg;&#125; 我们可以通过以下方法来获取Person类的构造方法：1Constructor dc1 = c1.getDeclaredConstructor(String.class,String.class) ; 具体代码如下：123Constructor dc1 = c1.getDeclaredConstructor(String.class,String.class) ;dc1.setAccessible(true);dc1.newInstance("小明","很帅") ; dc1.newInstance(&quot;小明&quot;,&quot;很帅&quot;);方法调用了Person类中的：12345public Person(String name, String msg) &#123; this.name = name; this.msg = msg; System.out.println(name+"的描述是"+msg);&#125; 这个构造方法，如果不传参数的话，那么调用的就是无参的构造方法。输出结果为:1小明的描述是很帅 通过反射了解集合泛型的本质通过以下例子程序可以看出：1234567891011121314151617181920212223242526272829303132333435363738394041package top.crosssoverjie.study;import java.lang.reflect.Method;import java.util.ArrayList;import java.util.List;public class GenericEssence &#123; public static void main(String[] args) &#123; //声明两个list，一个有泛型，一个没有泛型 List list1 = new ArrayList() ; List&lt;String&gt; list2 = new ArrayList&lt;String&gt;() ; list2.add("你好") ;// list2.add(11) ;加上泛型之后在编译期间只能添加String，不然会报错。 System.out.println("list2的长度是："+list2.size()); Class c1 = list1.getClass(); Class c2 = list2.getClass() ; System.out.print("c1,c2是否相等:"); System.out.println(c1==c2); try &#123; //通过反射绕过编译器动态调用add方法，可能否加入非String类型的元素 Method method = c2.getDeclaredMethod("add", Object.class) ; method.invoke(list2, 123) ;//在这里加入int类型，在上面如果加入int会出现编译报错。 //list2的长度增加了，说明添加成功了 System.out.println("现在list2的长度是:"+list2.size()); /** * 所以可以看出，泛型只是在编译期间起作用，在经过编译进入运行期间是不起作用的。 * 就算是不是泛型要求的类型也是可以插入的。 */ &#125; catch (Exception e) &#123; e.printStackTrace() ; &#125; &#125;&#125; 所以可以看出，泛型只是在编译期间起作用，在经过编译进入运行期间是不起作用的。就算是不是泛型要求的类型也是可以插入的。 反射知识点 总结 泛型的应用比较多： spring的IOC/DI。 JDBC中的中的加载驱动 参考 java中的反射机制 反射机制是什么]]></content>
      <categories>
        <category>Java笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Reflect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一次总结]]></title>
    <url>%2F2016%2F05%2F07%2F%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[前言 昨天到今天一共花了差不多两天的时间终于把博客搭好了。还买了一个域名，现在就迫不及待的想把这段内容写下来。 感谢 首先非常感谢 嘟爷的帮忙，没有这些资料我可能还得自己研究好一段时间。 过程 我是前天无意间在微博上看到嘟爷的一篇博文，就仔细看了下，发现写的非常好，然后就将他所有的博文大致的浏览了一下。 我很早以前就打算搭一个博客，但是百度了一下发现还是挺麻烦的，加上最近也比较忙所有一直也就没有做，直到看到这篇博文才顺利的搭起了这个博客。中途遇到不少问题也都顺利解决了，真是学到了不少的东西。 熟练了Markdown语法。 真正使用了编辑神器 Sublime。 使用阿里云解析了github和coding里的Pages服务。 hexo和常用的主题配置。 我的配置 Hexo配置 JackMan配置imglogo: enable: true ## display image logo true/false. src: img/logo.gif ## `.svg` and `.png` are recommended,please put image into the theme folder `/jacman/source/img`. favicon: img/favicon.ico ## size:32px*32px,`.ico` is recommended,please put image into the theme folder `/jacman/source/img`. apple_icon: img/jacman.jpg ## size:114px*114px,please put image into the theme folder `/jacman/source/img`. author_img: img/author.jpg ## size:220px*220px.display author avatar picture.if don&apos;t want to display,please don&apos;t set this. banner_img: #img/banner.jpg ## size:1920px*200px+. Banner Picture ### Theme Color theme_color: theme: &apos;#2ca6cb&apos; ##the defaut theme color is blue # 代码高亮主题 # available: default | night highlight_theme: night #### index post is expanding or not index: expand: false ## default is unexpanding,so you can only see the short description of each post. excerpt_link: Read More close_aside: false #close sidebar in post page if true mathjax: false #enable mathjax if true ### Creative Commons License Support, see http://creativecommons.org/ ### you can choose: by , by-nc , by-nc-nd , by-nc-sa , by-nd , by-sa , zero creative_commons: none 结束语以上。。我做这个博客的初衷一是为了记录我的整个程序猿生涯的故事，二是希望能有大神能在过程中指出我的错误，能让我的水平更进一步。]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown小计]]></title>
    <url>%2F2016%2F05%2F06%2FMarkdown%E5%B0%8F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[# 标题 表示标题 一个#号代表一级标题，以此类推。 * 无序列表 无序列表 &gt; 引用 引用 [http://www.baidu.com](http://www.baidu.com &quot;百度&quot;) 百度 ![艾弗森](http://i.imgur.com/TLnZ2S6.jpg)插入图片]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux（一）常用命令]]></title>
    <url>%2F2016%2F04%2F10%2FLinux-normal%2F</url>
    <content type="text"><![CDATA[前言 由于现在JAVA开发的很多应用都是部署到Linux系统上的，因此了解和掌握一些Linux的常用命令是非常有必要的，以下就是在Java开发过程中一些常用的命令。 常用命令 查找文件find / -name log.txt根据名称查找在 /目录下的 log.txt文件。 find .-name &quot;*.xml&quot;递归查找所有的xml文件。 find .-name &quot;*.xml&quot;|xargs grep &quot;hello&quot;递归查找所有包含hello的xml文件。 ls -l grep &#39;jar&#39;查找当前目录中的所有jar文件。 检查一个文件是否运行ps –ef|grep tomecate检查所有有关tomcat的进程。 终止线程kill -9 19979终止线程号为19979的线程 查看文件，包括隐藏文件。ls -al 查看当前工作目录。pwd 复制文件包括其子文件到指定目录cp -r source target复制source文件到target目录中。 创建一个目录mkdir new创建一个new的目录 删除目录(前提是此目录是空目录)rmdir source删除source目录。 删除文件 包括其子文件rm -rf file删除file文件和其中的子文件。-r表示向下递归，不管有多少目录一律删除-f表示强制删除，不做任何提示。 移动文件mv /temp/movefile /target 切换用户su -username 查看ipifconfig注意是 ifconfig 不是windows中的ipconfig 总结以上就是在Linux下开发Java应用常用的Linux命令，如有遗漏请在评论处补充，我将不定期添加。]]></content>
      <categories>
        <category>Linux笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人简历]]></title>
    <url>%2F1994%2F08%2F08%2Fmyresume%2F</url>
    <content type="text"><![CDATA[个人信息 陈杰/男/1994 工作年限：3年 技术博客：https://crossoverjie.top Github：http://github.com/crossoverjie 期望职位：Java 高级工程师 联系方式 手机：18523985794 Email：crossoverJie@gmail.com QQ/微信号：731756881 / chycjj 工作经历亚信科技 （ 2017年05月 ~ 至今 ）IOP 智能营销平台项目描述：根据用户DNA数据、当前位置等信息合理的推送相应的营销活动给用户。主要负责： 短信群发渠道的整个流程。 短信网关:保证 1000W+ 的用户数据安全有效的通过短信网关进行短信下发。 51 营业厅项目描述: 基于云端的进销存系统。主要负责： 支付模块。 财务模块。 线上地址 : https://www.51yyt.com.cn/ 其他项目请求防重组件项目描述 : 对于某些业务要求每次请求保证唯一，如果每个接口都做校验操作的话耦合太高也不利于维护。基于此自定义了 annotation ,通过 Spring 的 AOP 只要给相应的接口加上该注解即可实现请求去重。 开源地址: Spring 版: https://github.com/crossoverJie/SSM-REQUEST-CHECK SpringBoot 版: https://github.com/crossoverJie/springboot-cloud 猪八戒网络有限公司 （ 2016年05月 ~ 2017年05月 ）八戒认证项目描述：为整个猪八戒网提供实名认证服务，主推人脸识别认证。期望打造成一个权威的第三方实名认证平台。分为以下几个模块： Web端人脸识别认证。 移动端人脸识别认证(IOS,Android)。 国内境外企业审核认证。 国内港澳台个人审核认证。 主要负责： 八戒认证核心服务开发。 新老系统数据迁移。 整个主站所依赖的实名查询接口。 线上地址 : https://do.renzheng.zbj.com/fe/page/index 其他项目Dubbo 接口 实现 HTTP 访问组件项目描述 : 由于 Dubbo 接口通常是内部应用之间进行调用，当我们想要排除掉语言的特有性的话最好还是提供一个 HTTP 接口。基于此开发了一个组件可以在不修改原有 Dubbo 接口的前提下实现 HTTP 访问，这在某些特有环境下进行调试是非常方便的。 开源地址 : https://github.com/crossoverJie/SSM-DUBBO-HTTP 重庆驰骅科技 （ 2014年11月 ~ 2016年05月 ）长安马自达内部审计系统 项目描述：该项目为长安马自达财务部门内部使用的一个审计系统，用于升级整个长马公司的风险和管理工作。主要负责： 编写项目过程中的各个里程碑文档。 系统数据库设计。 制定并分配开发任务。 资源共享、系统指南、系统管理、风险管理模块代码的实现。 长安汽车设计成本管控系统项目描述：该项目为重庆长安公司使用成本管控系统，对整个汽车生产所产生的成本进行预估与管理 主要负责： 零部件参数准确率、及时率的开发。 开源项目和作品开源项目 SSM：从 0 构建一套分布式系统。(1.2K star) springboot-cloud：基于 SpringBoot + SpringCloud 搭建的微服务项目 技术文章 基于dubbo的分布式架构 MQ应用 译 你可以用GitHub做的12件 Cool 事情 技能清单以下均为我熟练使用的技能 主力语言：Java 框架：Spring/SpringMVC/Mybatis/SpringBoot/SpringCloud/Dubbo 中间件：Kafka/Zookeeper/配置中心/调度中心 数据库相关：MySQL/Oracle 版本管理、文档和自动化部署工具：Svn/Git/Jenkins 单元测试：Junit/Jacoco/coveralls 服务器 : Linux常用操作，基本的 Shell 脚本编写 致谢感谢您花时间阅读我的简历，期待能有机会和您共事。]]></content>
      <categories>
        <category>resume</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
</search>
